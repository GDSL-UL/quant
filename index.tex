% Options for packages loaded elsewhere
% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrreprt}
\usepackage{xcolor}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{5}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother

\ifLuaTeX
  \usepackage{luacolor}
  \usepackage[soul]{lua-ul}
\else
  \usepackage{soul}
\fi




\setlength{\emergencystretch}{3em} % prevent overfull lines

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}



 


\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Human Geography through Merseyside - Quantitative Block: Seeing the world through numbers},
  pdfauthor={Zi Ye and Ron Mahabir},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{Human Geography through Merseyside - Quantitative Block: Seeing
the world through numbers}
\author{Zi Ye and Ron Mahabir}
\date{2026-02-26}
\begin{document}
\maketitle

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}

\bookmarksetup{startatroot}

\chapter*{Welcome}\label{welcome}
\addcontentsline{toc}{chapter}{Welcome}

\markboth{Welcome}{Welcome}

This is the website for ``Human Geography through Merseyside -
Quantitative Block: Seeing the world through numbers'' (module
\textbf{ENVS162}) at the University of Liverpool. This block of the
module is designed and delivered by Dr.~Zi Ye and Dr.~Ron Mahabir from
the Geographic Data Science Lab at the University of Liverpool. The
module seeks to provide hands-on experience and training in introductory
statistics for human geographers.

The website is \textbf{free to use} and is licensed under the
\href{https://creativecommons.org/licenses/by-nc-nd/4.0/}{Attribution-NonCommercial-NoDerivatives
4.0 International}. A compilation of this web course is hosted as a
GitHub repository that you can access:

\begin{itemize}
\tightlist
\item
  As an \href{https://gdsl-ul.github.io/quant}{html website}.
\item
  As a \href{https://github.com/GDSL-UL/quant}{GitHub repository}.
\end{itemize}

\section*{Contact}\label{contact}
\addcontentsline{toc}{section}{Contact}

\markright{Contact}

\begin{quote}
Zi Ye - zi.ye {[}at{]} liverpool.ac.uk Lecturer in Geographic
Information Science Office 107, Roxby Building, University of Liverpool
- 74 Bedford St S, Liverpool, L69 7ZT, United Kingdom.
\end{quote}

\begin{quote}
Ron Mahabir - Ron.Mahabir {[}at{]} liverpool.ac.uk Lecturer in
Geographic Data Science Office 4xx, Roxby Building, University of
Liverpool - 74 Bedford St S, Liverpool, L69 7ZT, United Kingdom.
\end{quote}

\bookmarksetup{startatroot}

\chapter*{Overview}\label{overview}
\addcontentsline{toc}{chapter}{Overview}

\markboth{Overview}{Overview}

\section*{Aim and Learning
Objectives}\label{aim-and-learning-objectives}
\addcontentsline{toc}{section}{Aim and Learning Objectives}

\markright{Aim and Learning Objectives}

This sub-module aims to provide training and skills on a set of basic
quantitative skills for data collection, analysis, and interpretation
and to enable you to link conceptual ideas with real world examples.
\textbf{This block serves as the foundation for ENVS225 Explore the
Social World, Year 2 BA field class and, optionally, for Year 3
dissertation.}

\textbf{Background}

Data and research are key pillars of the global economy and society
today. We need rigorous approaches to collecting and analysing both the
statistics that can tell us `how much' and if there are observable
relationships between phenomena; and the information gives us a nuanced
understanding of cultural contexts and human dynamics. Quantitative
skills enable us to explore and measure socio-economic activities and
processes at large scales, while qualitative skills enable understanding
of social, cultural, and political contexts and diverse lived
experiences. Rather than being in opposition, qualitative and
quantitative research can complement one another in the investigation of
today's pressing research questions.

To these ends, this block will help you develop your quantitative
skills, as critical tools. This course will help you understand what
quantitative statistical researchers use and develop a set of research
techniques that can be used in your field classes and dissertations.

\textbf{Learning objectives:}

\begin{itemize}
\tightlist
\item
  Understand how to explore a dataset, containing a number of
  observations described by a set of variables.
\item
  Demonstrate an understanding in the application and interpretation of
  commonly used quantitative research methods.
\item
  Ability to work with quantitative data to understand real-world social
  phenomenian and patterns.
\end{itemize}

\section*{Module Structure}\label{module-structure}
\addcontentsline{toc}{section}{Module Structure}

\markright{Module Structure}

\textbf{Staff:} Dr Zi Ye and Dr Ron Mahabir

\textbf{Where and When}

\textbf{Week 1 - 5 Lecture:} \textbf{Tuesday} \textbf{(12am -- 1pm)}
\textbf{@} Mathematical Sciences, Proudman Lecture Theatre

\textbf{Week 1 - 6 Practical PC session: Friday (9 -- 11 am)} \textbf{@}
Central Teaching Lab: PC Teaching Centre

Lectures will introduce and explain the fundamentals of quantitative
methods, with the opportunity to apply the method introduced in the labs
later in the week.

The computer practical sessions, will give you the chance to use and
apply quantitative methods to real-world data. These are primarily
self-directed sessions, but with support on hand if you get stuck.
Support and training in R will be provided through these sessions.
Weekly sessions will be driven by empirical research questions.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.0887}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.5081}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2984}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.0887}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Week
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Topic
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Format
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Staff
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & Introduction

Getting Started in RStudio: Knowing Merseyside & Lecture

Computer Lab Practical & ZY/RM \\
2 & Exploratory Data Analysis: UK Election & Lecture and Computer Lab
Practical & ZY \\
3 & Sampling and data manipulation: Happiness around the world & Lecture
and Computer Lab Practical & ZY \\
4 & Correlation, data reliability and the issue of scale: Health &
Lecture and Computer Lab Practical & RM \\
5 & How robust are my findings & Lecture and Computer Lab Practical &
RM \\
6 & Online Assessment & Computer Lab & RM/ZY \\
\end{longtable}

\section*{Software and Data}\label{software-and-data}
\addcontentsline{toc}{section}{Software and Data}

\markright{Software and Data}

For quantitative training sessions, ensure you have installed and/or
have access to \textbf{RStudio}. To run the analysis and reproduce the
code in R, you need the following software installed on your machine:

\begin{itemize}
\tightlist
\item
  R-4.2.2 (or later)
\item
  RStudio 2022.12.0-353 (or later)
\end{itemize}

To install and update:

\begin{itemize}
\tightlist
\item
  R, download the appropriate version from
  \href{https://cran.r-project.org/}{The Comprehensive R Archive Network
  (CRAN)}.
\item
  RStudio, download the appropriate version from
  \href{https://posit.co/download/rstudio-desktop/}{here}.
\end{itemize}

\textbf{This software is already installed on University Machines. But
you will need it to run the analysis on your personal devices.}

\textbf{Data}

Example datasets could be accessed through
\href{https://canvas.liverpool.ac.uk/courses/85565/modules}{ENVS 162
Canvas module} every week.

\bookmarksetup{startatroot}

\chapter*{Assessment}\label{assessment}
\addcontentsline{toc}{chapter}{Assessment}

\markboth{Assessment}{Assessment}

\textbf{Week 6 Computer-based `open book' multiple-choice exam}

\begin{itemize}
\item
  The online assessment will be released at \textbf{4pm on Thursday 5th
  March} and should be c\textbf{ompleted by 4pm on Friday 6th March.}
\item
  \textbf{Also available 06/03/2025 9:00 -- 11:00 CTL PC Teaching Centre
  (1st Floor CTL)}
\item
  Should take less \textbf{90 minute}s; c.~20 questions; 24 hours to
  complete
\item
  Questions and answers randomised for each student (anti-cheating
  measure)
\item
  Some questions of factual recall, more requiring data analysis to find
  answers
\end{itemize}

\textbf{\emph{Preparation for assessment}}

\begin{itemize}
\item
  Weekly lecture \& weekly computer practical `clinic sessions'
\item
  Weekly holding hands formative tasks at the last 20 mins of the
  practical session
\item
  Week 5 mock online test
\end{itemize}

\bookmarksetup{startatroot}

\chapter{Lab: Getting Started in RStudio - Knowing
Merseyside}\label{lab-getting-started-in-rstudio---knowing-merseyside}

\section{\texorpdfstring{\textbf{Overview}}{Overview}}\label{overview-1}

This practical intend to prepare students who have limited experiences
with R and RStudio. The content are adapted based on

\begin{itemize}
\item
  Brunsdon, Chris, and Lex Comber. 2018. \emph{An Introduction to r for
  Spatial Analysis and Mapping (2e)}. Sage.
\item
  Comber, Lex, and Chris Brunsdon. 2021. \emph{Geographical Data Science
  and Spatial Data Analysis: An Introduction in r}. Sage.
\end{itemize}

\section{\texorpdfstring{\textbf{Getting set up with
RStudio}}{Getting set up with RStudio}}\label{getting-set-up-with-rstudio}

\subsection{\texorpdfstring{\textbf{Install R and RStudio (if
necessary)}}{Install R and RStudio (if necessary)}}\label{install-r-and-rstudio-if-necessary}

R is a free, open-source programming language used for statistical
analysis, data visualization, and data science

RStudio is a free front-end to R, designed to make using R easier

All of the PCs in the University PC Teaching Centre used for this class
come with R and RStudio pre-installed, as do the PCs in many other
University PC Teaching Centres.

However, you may wish to install R and RStudio on your own computer, or
on a University PC that lacks them.

\textbf{University computers}: Use the \emph{Install University
Applications} app on the computer to install the latest version of
RStudio (this will also install the latest version of R)

\textbf{Your own computer}: R and RStudio can be downloaded from the
CRAN website and installed your own computer - see below for details.
\ul{\textbf{A key point is that you should install R before you install
RStudio.}}

The simplest way to get R installed on your computer is to go the
download pages on the R website - a quick search for `download R' should
take you there, but if not you could try:

\begin{itemize}
\item
  Windows: \url{https://cran.r-project.org/bin/windows/base/}
\item
  Mac: \url{https://cran.r-project.org/bin/macosx/}
\item
  Linux: \url{http://cran.r-project.org/bin/linux/}
\end{itemize}

The Windows and Mac version come with installer packages and are easy to
install whilst the Linux binaries require use of a command terminal.

RStudio can be downloaded from
\url{https://www.rstudio.com/products/rstudio/download/} and the free
version of RStudio Desktop is more than sufficient for this module and
all the other things you will to do at degree level.

If you experience any problems installing R or RStudio on your own
computer, bring it to one of the class lab sessions where we will be
able to provide advice.

\subsection{File management}\label{file-management}

Before you start installing software or downloading data, create a
folder on your M-Drive (if working on a University networked machine) or
locally if working on your own device -- name this `ENVS162' and within
this create a sub-folder for each practical session. For this session,
create a sub-folder called~\texttt{Week1}~in your~\texttt{ENVS162}
folder on your M-Drive. Take care to ensure you do not delete any work
you do complete in the practical sessions. It is imperative that you
practice good file management!

\subsection{\texorpdfstring{\textbf{Open
RStudio}}{Open RStudio}}\label{open-rstudio}

RStudio provides an interface to the different things that R can do via
the 4 panes: the Console where code is entered (bottom left), a Source
pane with R scripts (top left), the variables in the working Environment
(top right), Files, Plots, Help etc (bottom right) - see the RStudio
environment in Figure below.

In the figure above of the RStudio interface, a new script has been
opened, a line of code had been written and then run in the console. The
code assigns a value of 100 to \texttt{x}. The file has been saved into
the current working environment. You are expected to define a similar
set up for each practical as you work through the code. Note that
\textbf{in the script}, anything that follows a \texttt{\#} is a comment
and ignored by R.

Users can set up their personal preferences for how they like their
RStudio interface. Similar to straight R, there are very few pull-down
menus in R, and therefore you will type lines of code into your script
and run these in what is termed a \emph{command line interface} (the
console). Like all command line interfaces, the learning curve is steep
but the interaction with the software is more detailed which allows
greater flexibility and precision in the specification of commands.

Beyond this there are further choices to be made. Commands can be
entered in two forms: directly into the \emph{R console} window or as a
series of commands into a script window. We strongly advise that all
code should be \textbf{written in a script} - (a \texttt{.R} file) and
then \textbf{run from the script}. - To run code in a script, place the
cursor on the line of code and then run by pressing the `Run' icon at
the top left of the script pane, or by pressing \textbf{Ctrl Enter} (PC)
(or \textbf{Cmd Enter} on a Mac).

\pandocbounded{\includegraphics[keepaspectratio]{labs/images/clipboard-1359090391.png}}

\subsection{Ways of working}\label{ways-of-working}

The first set of consideration relate to \emph{how} you should work in
R/RStudio. The key things to remember are:

\begin{itemize}
\item
  R is a learning curve if you have never done anything like this
  before. It can be scary. It can be intimidating. But once you have a
  bit of familiarity with how things work, it is incredibly powerful.
\item
  You will be working from practical worksheets which will have all the
  code you need. Your job is to try to \textbf{understand} what the code
  is doing and \textbf{not} to remember the code. Comments in your code
  really help.
\item
  To help you do this, the very strong suggestion is use the R scripts
  that are provided, and that you add your own comments to help you
  understand what is going on when you return to them. Comments are
  prefaced by a hash (\texttt{\#}) that is ignored by R. Then you can
  save your code (with comments), run it and return to it later and
  modify at your leisure.
\end{itemize}

The module places a strong emphasis placed on learning by doing, which
means that you encouraged to unpick the code that you are given, adapt
it and play with it. It is not about remembering or being able to recall
each function used but about understanding what is being done. If you
can remember what you did previously (i.e.~the operations you undertook)
and understand what you did, you will be able to return to your code the
next time you want to do something similar. To help you with this you
should:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Always run your code from an R script\ldots{} \textbf{always}! These
  are provided for each practical;
\item
  Annotate you scripts with comments. These are prefixed by a hash
  (\texttt{\#}) in the code;
\item
  Save your R script to your folder.
\end{enumerate}

In Summary:

\begin{itemize}
\item
  You should always use a script (a text file containing code) for your
  code which can be saved and then re-run at a later date.
\item
  You can write your own code into a script, copy and paste code into it
  or use an existing script (for example as provided for each of the
  R/RStudio practicals in this module).
\item
  To open a new R script go to File \textgreater{} New File
  \textgreater{} R Script to open a new R file, and save it with a
  sensible name.
\item
  To load an existing script file go to File \textgreater{} Open File
  and then navigate to your file. Or, if you have recently opened the
  file, go to File \textgreater{} Recent Files \textgreater.
\item
  It is good practice to set the working directory at the beginning of
  your R session. This can be done via the menu in RStudio Session
  \textgreater{} Set Working Directory \textgreater{} \ldots. This
  points the R session to the folder you choose and will ensure that any
  files you wish to read, write or save are placed in this directory.
\item
  To run code in a script, place the cursor on the line of code and then
  run by pressing the `Run' icon at the top left of the script pane, or
  by pressing Ctrl Enter (PC) or Cmd Enter (Mac).
\end{itemize}

\subsection{Your first R code}\label{your-first-r-code}

In this section you will undertake a few generic operations. You will:

\begin{itemize}
\item
  undertake \textbf{assignment}: the allocation of values to an R
  object.
\item
  use assignment to create a \textbf{vector} of elements and a
  \textbf{matrix} of elements.
\item
  undertake \textbf{operations} on R objects.
\item
  apply some \textbf{functions} to R objects (functions nearly always
  return a value).
\item
  access some of R in-built data to examine a data table (or
  \texttt{data.frame} which is like an Excel spreadsheet).
\item
  do some basic \textbf{plotting}, including scatter plots and
  histograms.
\item
  create data summaries.
\end{itemize}

On the way you will also be introduced to \textbf{indexing}.

First, you should \textbf{create a new R script} (see above) and save it
as \texttt{week1.R} in the working directory you are using for this
practical. This should be the \texttt{Week1} sub-directory you created
in the \texttt{ENVS162} folder. Note that you should create a separate
folder for each week's practical.

\subsubsection{Assignment}\label{assignment}

The command line prompt in the Console window, the
\texttt{\textgreater{}}, is an invitation to start typing in your
commands.

Write the following into your script: \texttt{3+5} and run it. Recall
that code is run done by either by pressing the Run icon at the top left
of the script pane, or by pressing \textbf{Ctrl Enter} (PC) or
\textbf{Cmd Enter} (Mac).

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{3}\SpecialCharTok{+}\DecValTok{5}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 8
\end{verbatim}

Here the result is 8. The \texttt{{[}1{]}} that precedes the output it
formally indicates, \emph{first requested element will follow}. In this
case there is just one element. The \texttt{\textgreater{}} indicates
that R is ready for another command.

Now type the following in to your script and run it:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y }\OtherTok{\textless{}{-}} \DecValTok{3}\SpecialCharTok{+}\DecValTok{5}
\NormalTok{y}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 8
\end{verbatim}

Here the value of the \texttt{3+5} has been \textbf{\emph{assigned}} to
\texttt{y}. The syntax \texttt{y\ \textless{}-\ 3+5} can be read as
\texttt{y} \textbf{\emph{gets}} \texttt{3+5}. When \texttt{y} is invoked
its value is returned (8).

For the purposes of this module, in R the equals sign (\texttt{=}) is
the same as \texttt{\textless{}-}, a left diamond bracket
\texttt{\textless{}} followed by a minus sign \texttt{-}. This too is
interpreted by R as \textbf{\emph{is assigned to}} or
\textbf{\emph{gets}} when the code is read \textbf{right to left}.

Now copy and paste the following into your R script and run both lines:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{7}\NormalTok{,}\DecValTok{8}\NormalTok{), }\AttributeTok{nrow =} \DecValTok{4}\NormalTok{)}
\NormalTok{y }\OtherTok{=} \FunctionTok{matrix}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{8}\NormalTok{, }\AttributeTok{nrow =} \DecValTok{4}\NormalTok{, }\AttributeTok{byrow =}\NormalTok{ T)}
\end{Highlighting}
\end{Shaded}

You should see the \texttt{x} appear with the \texttt{y} in the
Environment pane. \texttt{y} has now been overwritten with a new
assignment. If you click on the icon next to them, you will get a
`spreadsheet' view of the data you have created.

Of course you can also enter the following in the console and see what
is returned:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1] [,2]
[1,]    1    5
[2,]    2    6
[3,]    3    7
[4,]    4    8
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1] [,2]
[1,]    1    2
[2,]    3    4
[3,]    5    6
[4,]    7    8
\end{verbatim}

\textbf{Note} In the code snippets above you have used
\texttt{parentheses} - round brackets. Different kinds of brackets are
used in different ways in R. Parentheses are used with
\textbf{functions}, and contain the \textbf{arguments} that are passed
to the function, separated by commas (\texttt{,}).

In this case the functions are \texttt{c()} and \texttt{matrix()}. The
function \texttt{c()} combines or concatenates elements into a vector,
and \texttt{matrix()} creates a matrix of elements in a tabular format.

In the line of code
\texttt{x\ =\ matrix(c(1,2,3,4,5,6,7,8),\ nrow\ =\ 4)}, the arguments
passed to the \texttt{matrix()} function are the vector of values
\texttt{c(1,2,3,4,5,6,7,8)} and \texttt{nrow\ =\ 4}. Other kinds of
brackets are used in different ways as you will see later.

One final thing to note is that the matrix is \texttt{y} is has the
numbers 1 to 8, but this is specified by \texttt{1:8}. Try entering
\texttt{3:65}, \texttt{19:11}, and \texttt{1.5:5} to see how the colon
(\texttt{:}) works in this context.

\subsubsection{Operations}\label{operations}

Now you can undertake \emph{operations} on R objects and apply
\emph{functions} to them. Write the following code into your script and
then run it:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# x is a matrix}
\NormalTok{x}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1] [,2]
[1,]    1    5
[2,]    2    6
[3,]    3    7
[4,]    4    8
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# multiplication}
\NormalTok{x}\SpecialCharTok{*}\DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1] [,2]
[1,]    2   10
[2,]    4   12
[3,]    6   14
[4,]    8   16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# sum of x}
\FunctionTok{sum}\NormalTok{(x)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 36
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# mean of x}
\FunctionTok{mean}\NormalTok{(x)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 4.5
\end{verbatim}

Operations can be undertaken directly using mathematical notation like
\texttt{*} for multiplication or using functions like \texttt{max} to
find the maximum value in an R object.

\subsubsection{Functions}\label{functions}

Functions are always followed by parenthesis (round brackets)
\texttt{(\ )}. These are different from square and curly brackets
\texttt{{[}\ {]}} and \texttt{\{\ \}}. Functions always return
something, a result if you like, and have the generic form:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# don\textquotesingle{}t run this or write this into your script!}
\NormalTok{result }\OtherTok{=} \ControlFlowTok{function}\NormalTok{(value or R object, other parameters)}
\end{Highlighting}
\end{Shaded}

Do not run or enter this code in your script - it is an example!

\subsubsection{Data Tables}\label{data-tables}

Here we will load a data table in \texttt{data.frame} (like a
spreadsheet) in R/RStudio. R has number of in-built datasets that we can
use the code below loads one of these:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data}\NormalTok{(mtcars)}
\FunctionTok{class}\NormalTok{(mtcars)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "data.frame"
\end{verbatim}

Have a look at what is loaded by listing the objects in the current R
session

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ls}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "mtcars" "x"      "y"     
\end{verbatim}

You should see the \texttt{mtcars} object. You can examine this data in
a number of ways

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# the structure of mtcars}
\FunctionTok{str}\NormalTok{(mtcars)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
'data.frame':   32 obs. of  11 variables:
 $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...
 $ cyl : num  6 6 4 6 8 6 8 4 4 6 ...
 $ disp: num  160 160 108 258 360 ...
 $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...
 $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...
 $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...
 $ qsec: num  16.5 17 18.6 19.4 17 ...
 $ vs  : num  0 0 1 1 0 1 0 1 1 1 ...
 $ am  : num  1 1 1 0 0 0 0 0 0 0 ...
 $ gear: num  4 4 4 3 3 3 3 4 4 4 ...
 $ carb: num  4 4 1 1 2 1 4 2 2 4 ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# the first six rows (or head) of mtcars}
\FunctionTok{head}\NormalTok{(mtcars)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
                   mpg cyl disp  hp drat    wt  qsec vs am gear carb
Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4
Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4
Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1
Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1
Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2
Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1
\end{verbatim}

The \texttt{mtcars} object is a \texttt{data.frame}, a kind of data
table, and it has a number of attributes which are all numeric. The code
below prints it all out to the console:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mtcars}
\end{Highlighting}
\end{Shaded}

Data frames are `flat' in that they typically have a rectangular layout
like a spreadsheet, with rows typically relating to observations
(individuals, areas, people, houses, etc) and columns relating to their
properties or attributes (height, age, etc). The columns in data frames
can be of different types: vectors of numbers, factors (classes) or text
strings. In matrices all of the columns have to be off the same type.
Data frames are central to what we will do in R.

\subsubsection{Plotting the data: `Hello
World!'}\label{plotting-the-data-hello-world}

The code below creates a plot of 2 variables counts in the data:
\texttt{mpg} and \texttt{disp}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(disp }\SpecialCharTok{\textasciitilde{}}\NormalTok{ mpg,  }\AttributeTok{data =}\NormalTok{ mtcars, }\AttributeTok{pch=}\DecValTok{16}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/01.GettingStartedinRStudio_files/figure-pdf/unnamed-chunk-12-1.pdf}}

The option \texttt{pch=16} sets the plotting character to a solid black
dot. More plot characters are available - examine the help for
\texttt{points()} to see these (For any command, if you are the first
time use it, you can always ask R to explain to you by using ? as help)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{?points}
\end{Highlighting}
\end{Shaded}

This plot can be improved greatly. We can specify more informative axis
labels, change size of the text and of the plotting symbol, and so on.

We can also specify the same plot by passing named variables to the
\texttt{plot} function directly as well as other parameters, as in the
figure. Notice how the syntax for this is different to the \texttt{plot}
function above, and the different \textbf{parameters} that are passed to
the \texttt{plot()} function:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(}\AttributeTok{x =}\NormalTok{ mtcars}\SpecialCharTok{$}\NormalTok{mpg, }\AttributeTok{y =}\NormalTok{ mtcars}\SpecialCharTok{$}\NormalTok{disp,   }\AttributeTok{pch =} \DecValTok{1}\NormalTok{, }\AttributeTok{col =} \StringTok{"dodgerblue"}\NormalTok{, }
     \AttributeTok{cex =} \FloatTok{1.5}\NormalTok{, }\AttributeTok{xlab =} \StringTok{"Miles per Gallon"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Displacement"}\NormalTok{, }
     \AttributeTok{main =} \StringTok{"Hello World!"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/01.GettingStartedinRStudio_files/figure-pdf/unnamed-chunk-14-1.pdf}}

Notice how the dollar sign (\texttt{\$}) is used to access variables in
the \texttt{mtcars} data table compared to the first plot command, which
specified \texttt{data\ =\ mtcars}.

\subsubsection{Data summaries and
indexing}\label{data-summaries-and-indexing}

We may for example require information on variables in \texttt{mtcars}.
The \texttt{summary} function is very useful:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(mtcars)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
      mpg             cyl             disp             hp       
 Min.   :10.40   Min.   :4.000   Min.   : 71.1   Min.   : 52.0  
 1st Qu.:15.43   1st Qu.:4.000   1st Qu.:120.8   1st Qu.: 96.5  
 Median :19.20   Median :6.000   Median :196.3   Median :123.0  
 Mean   :20.09   Mean   :6.188   Mean   :230.7   Mean   :146.7  
 3rd Qu.:22.80   3rd Qu.:8.000   3rd Qu.:326.0   3rd Qu.:180.0  
 Max.   :33.90   Max.   :8.000   Max.   :472.0   Max.   :335.0  
      drat             wt             qsec             vs        
 Min.   :2.760   Min.   :1.513   Min.   :14.50   Min.   :0.0000  
 1st Qu.:3.080   1st Qu.:2.581   1st Qu.:16.89   1st Qu.:0.0000  
 Median :3.695   Median :3.325   Median :17.71   Median :0.0000  
 Mean   :3.597   Mean   :3.217   Mean   :17.85   Mean   :0.4375  
 3rd Qu.:3.920   3rd Qu.:3.610   3rd Qu.:18.90   3rd Qu.:1.0000  
 Max.   :4.930   Max.   :5.424   Max.   :22.90   Max.   :1.0000  
       am              gear            carb      
 Min.   :0.0000   Min.   :3.000   Min.   :1.000  
 1st Qu.:0.0000   1st Qu.:3.000   1st Qu.:2.000  
 Median :0.0000   Median :4.000   Median :2.000  
 Mean   :0.4062   Mean   :3.688   Mean   :2.812  
 3rd Qu.:1.0000   3rd Qu.:4.000   3rd Qu.:4.000  
 Max.   :1.0000   Max.   :5.000   Max.   :8.000  
\end{verbatim}

This shows different summaries of the individual attributes in
\texttt{mtcars}.

The main R graphics function is \texttt{plot()}. In addition to
\texttt{plot()} there are functions for adding points and lines to
existing graphs, for placing text at specified positions, for specifying
tick marks and tick labels, for labelling axes, and so on.

There are various other alternative helpful forms of graphical summary.
A helpful graphical summary for the \texttt{mtcars} data frame is the
scatterplot matrix.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# return the names of the mtcars variables}
\FunctionTok{names}\NormalTok{(mtcars)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] "mpg"  "cyl"  "disp" "hp"   "drat" "wt"   "qsec" "vs"   "am"   "gear"
[11] "carb"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# return the 3rd to 7th names}
\FunctionTok{names}\NormalTok{(mtcars)[}\FunctionTok{c}\NormalTok{(}\DecValTok{3}\SpecialCharTok{:}\DecValTok{7}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "disp" "hp"   "drat" "wt"   "qsec"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# check what this does}
\FunctionTok{c}\NormalTok{(}\DecValTok{3}\SpecialCharTok{:}\DecValTok{7}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 3 4 5 6 7
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# plot the 3rd to 7th variables in mtcars}
\FunctionTok{plot}\NormalTok{(mtcars[, }\FunctionTok{c}\NormalTok{(}\DecValTok{3}\SpecialCharTok{:}\DecValTok{7}\NormalTok{)], }\AttributeTok{cex =} \FloatTok{0.5}\NormalTok{, }
     \AttributeTok{col =} \StringTok{"red"}\NormalTok{, }\AttributeTok{upper.panel=}\NormalTok{panel.smooth)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/01.GettingStartedinRStudio_files/figure-pdf/unnamed-chunk-19-1.pdf}}

The results show the correlations between the variables in the
\texttt{mtcars} data frame, and the trend of their relationship is
included with the \texttt{upper.panel=panel.smooth} parameter passed to
\texttt{plot}.

There are number of things to notice here (as well as the figure). In
particular note the use of the vector \texttt{c(2:7)} to subset the
columns of \texttt{mtcars}:

\begin{itemize}
\item
  In the second line, this is was used to subset the vector of column
  names created by \texttt{names(mtcars)}.
\item
  In the third line, it was printed out. Notice how \texttt{3:7} printed
  out all the number between 3 and 7 - very useful.
\item
  For the plot, the vector was passed to the second argument, after the
  comma, in the square brackets \texttt{{[},{]}} to indicate which
  columns were to be plotted.
\end{itemize}

The referencing in this way (or \emph{indexing}) is \textbf{very
important}: the individual rows and columns of 2 dimensional data
structures like data frames, matrices, tibbles etc can be accessed by
passing references to them in the square brackets.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 1st row}
\NormalTok{mtcars[}\DecValTok{1}\NormalTok{,]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
          mpg cyl disp  hp drat   wt  qsec vs am gear carb
Mazda RX4  21   6  160 110  3.9 2.62 16.46  0  1    4    4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 3rd column}
\NormalTok{mtcars[,}\DecValTok{3}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] 160.0 160.0 108.0 258.0 360.0 225.0 360.0 146.7 140.8 167.6 167.6 275.8
[13] 275.8 275.8 472.0 460.0 440.0  78.7  75.7  71.1 120.1 318.0 304.0 350.0
[25] 400.0  79.0 120.3  95.1 351.0 145.0 301.0 121.0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# a selection of rows}
\NormalTok{mtcars[}\FunctionTok{c}\NormalTok{(}\DecValTok{3}\SpecialCharTok{:}\DecValTok{5}\NormalTok{,}\DecValTok{8}\NormalTok{),]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
                   mpg cyl  disp  hp drat    wt  qsec vs am gear carb
Datsun 710        22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1
Hornet 4 Drive    21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1
Hornet Sportabout 18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2
Merc 240D         24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2
\end{verbatim}

Such indexing could of course have been assigned to a R object and used
to do the subsetting:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{=} \FunctionTok{c}\NormalTok{(}\DecValTok{3}\SpecialCharTok{:}\DecValTok{7}\NormalTok{)}
\FunctionTok{names}\NormalTok{(mtcars)[x]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "disp" "hp"   "drat" "wt"   "qsec"
\end{verbatim}

Thus indexing allows specific rows and columns to be extracted from the
data as required.

\textbf{Note} You have encountered a second type of brackets, square
brackets \texttt{{[}\ {]}}. These are used to reference or
\textbf{index} positions in a vector or a data table.

Consider the object \texttt{x} above. It contains a vector of values,
\texttt{3,4,5,6,7}. Entering \texttt{x{[}1{]}} would extract the first
element of \texttt{x}, in this case 3. Similarly \texttt{x{[}4{]}} would
return the 4th element and \texttt{x{[}c(1,4){]}} would return the 1st
and 4th elements of \texttt{x}.

However, in the examples above that index the 2-dimensional
\texttt{mtcars} object, the square brackets are used to index
\textbf{row} and \textbf{column} positions. The syntax for this is
\texttt{{[}rows,\ columns{]}}. We will be using such indexing throughout
this module.

You can ask R to return you specific rows and columns by different ways:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mtcars[}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{9}\NormalTok{), }\DecValTok{3}\SpecialCharTok{:}\DecValTok{7}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
               disp  hp drat    wt  qsec
Mazda RX4 Wag 160.0 110 3.90 2.875 17.02
Merc 230      140.8  95 3.92 3.150 22.90
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mtcars[}\DecValTok{3}\SpecialCharTok{:}\DecValTok{6}\NormalTok{, }\FunctionTok{c}\NormalTok{(}\StringTok{"disp"}\NormalTok{,}\StringTok{"hp"}\NormalTok{,}\StringTok{"qsec"}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
                  disp  hp  qsec
Datsun 710         108  93 18.61
Hornet 4 Drive     258 110 19.44
Hornet Sportabout  360 175 17.02
Valiant            225 105 20.22
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mtcars [, }\FunctionTok{c}\NormalTok{(}\StringTok{"wt"}\NormalTok{,}\StringTok{"gear"}\NormalTok{,}\StringTok{"cyl"}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
                       wt gear cyl
Mazda RX4           2.620    4   6
Mazda RX4 Wag       2.875    4   6
Datsun 710          2.320    4   4
Hornet 4 Drive      3.215    3   6
Hornet Sportabout   3.440    3   8
Valiant             3.460    3   6
Duster 360          3.570    3   8
Merc 240D           3.190    4   4
Merc 230            3.150    4   4
Merc 280            3.440    4   6
Merc 280C           3.440    4   6
Merc 450SE          4.070    3   8
Merc 450SL          3.730    3   8
Merc 450SLC         3.780    3   8
Cadillac Fleetwood  5.250    3   8
Lincoln Continental 5.424    3   8
Chrysler Imperial   5.345    3   8
Fiat 128            2.200    4   4
Honda Civic         1.615    4   4
Toyota Corolla      1.835    4   4
Toyota Corona       2.465    3   4
Dodge Challenger    3.520    3   8
AMC Javelin         3.435    3   8
Camaro Z28          3.840    3   8
Pontiac Firebird    3.845    3   8
Fiat X1-9           1.935    4   4
Porsche 914-2       2.140    5   4
Lotus Europa        1.513    5   4
Ford Pantera L      3.170    5   8
Ferrari Dino        2.770    5   6
Maserati Bora       3.570    5   8
Volvo 142E          2.780    4   4
\end{verbatim}

\subsubsection{Packages}\label{packages}

The \texttt{base} installation of R includes many functions and
commands. However, more often we are interested in using some particular
functionality, encoded into \textbf{packages} contributed by the R
developer community. Installing packages for the first time can be done
at the command line in the R console using the \texttt{install.packages}
command as in the example below to install the \texttt{tmap} library or
via the RStudio menu via \textbf{Tools \textgreater{} Install Packages}.

When you install these packages it is strongly suggested you also
install the \emph{dependencies}. These are other packages that are
required by the package that is being installed. This can be done by
selecting check the box in the menu or including \texttt{dep=TRUE} in
the command line as below (don't run this yet!):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# don\textquotesingle{}t run this!}
\FunctionTok{install.packages}\NormalTok{(}\StringTok{"tidyverse"}\NormalTok{, }\AttributeTok{dep =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

You may have to set a \textbf{mirror} site from which the packages will
be downloaded to your computer. Generally you should pick one that is
nearby to you.

Further descriptions of packages, their installation and their data
structures will be given as needed in the practicals. There are
literally 1000s of packages that have been contributed to the R project
by various researchers and organisations. These can be located by name
at
\url{http://cran.r-project.org/web/packages/available_packages_by_name.html}
if you know the package you wish to use. It is also possible to search
the CRAN website to find packages to perform particular tasks at
\url{http://www.r-project.org/search.html}. Additionally many packages
include user guides and vignettes as well as a PDF document describing
the package and listed at the top of the index page of the help files
for the package.

As well as \texttt{tidyverse} you should install the \texttt{sf} package
and dependencies. So we have 2 packages to install:

\begin{itemize}
\item
  \texttt{sf} for spatial data and spatial objects
\item
  \texttt{tidyverse} for lots of lovely data science things - see
  \href{https://www.tidyverse.org/}{https://www.tidyverse.org}
\end{itemize}

You could do this in one go and this will take a bit of time:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{install.packages}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"sf"}\NormalTok{, }\StringTok{"tidyverse"}\NormalTok{), }\AttributeTok{dep =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Remember: you will only have to install a package once!! So when the
above code has run in your script you should comment it out. For example
you might want to include something like the below in your R script.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# packages only need to be loaded once}
\CommentTok{\# install.packages(c("sf", "tidyverse"), dep = TRUE)}
\end{Highlighting}
\end{Shaded}

Once the package has been installed on your computer then the package
can be called using the \texttt{library()} function into each of your R
sessions as below.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(sf)}
\end{Highlighting}
\end{Shaded}

\section{Knowing Merseyside}\label{knowing-merseyside}

\subsection{Merseyside districts}\label{merseyside-districts}

Now we use these basic R command and newly installed packages to start
our initial exploration by using some existing secondary dataset from
the Census 2021.

In R we normally read in tabular dataset from .csv format. In your
\href{https://canvas.liverpool.ac.uk/courses/85565}{ENVS162 Canvas page}
find Week 1 -\textgreater{} Practical 1 Dataset, download the four
datasets to your current working folder on your M drive (ENVS162 - Week
1). You may first identify one \texttt{.csv} dataset:
\textbf{merseyside.csv}. You can open them in excel to have a look, but
here we are using R instead of Excel to load and examine them.

\subsubsection{Loading tabular data}\label{loading-tabular-data}

The survey data can be loaded into RStudio using the \texttt{read.csv}
function.

However, you will need to tell R where to get the data from. The easiest
way to do this is to use the menu if the R script file is open. Go to
\textbf{Session \textgreater{} Set Working Directory \textgreater{} To
Source File Location} to set the working directory to the location where
your \texttt{week1.R} script is saved. When you do this you will see
line of code print out in the Console (bottom left pane) similar to
\texttt{setwd("SomeFilePath")}. You can copy this line of code to your
script and paste into the line above the line calling the
\texttt{read.csv} function.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# use read.csv to load a CSV file}
\CommentTok{\# this is assignment to an object called \textasciigrave{}df\textasciigrave{}}
\NormalTok{df }\OtherTok{=} \FunctionTok{read.csv}\NormalTok{(}\AttributeTok{file =} \StringTok{"merseyside.csv"}\NormalTok{, }\AttributeTok{stringsAsFactors =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The \texttt{stringsAsFactors\ =\ TRUE} parameter tells R to read any
character or text variables as classes or categories and not as just
text.

You could inspect the help for the \texttt{read.csv} function to see the
different parameters and their default values:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{help}\NormalTok{(read.csv)}
\CommentTok{\# or }
\NormalTok{?read.csv}
\end{Highlighting}
\end{Shaded}

Functions always return something and in this case \texttt{read.csv()}
function has returned a tabular R object with 5 records and 12 fields.
This has been \emph{assigned to} \texttt{df}.

Finally in this section, lets have a look at the data. This can be done
in a number of ways.

\begin{itemize}
\item
  you could look at the \texttt{df} object by entering \texttt{df} in
  the Console. However this is not particular helpful as it simply
  prints out everything that is in \texttt{df} to the Console.
\item
  you could click on the \texttt{df} object in the Environment pane and
  this shows the structure of the attributes in different fields.
\item
  you could click on the little grid-like icon next \texttt{df} in the
  Environment pane to get a \texttt{View} of the data and remember to
  close the tab that opens!.
\item
  or you could use some code as in the examples below.
\end{itemize}

First, let's have a look at the internal structure of the data using the
\texttt{str} function:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{str}\NormalTok{(df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
'data.frame':   5 obs. of  12 variables:
 $ LAD21CD           : Factor w/ 5 levels "E08000011","E08000012",..: 1 2 3 4 5
 $ District          : Factor w/ 5 levels "Knowsley","Liverpool",..: 1 2 4 3 5
 $ Population        : int  154519 486089 183248 279234 320196
 $ Households        : int  66073 207491 81011 123075 143253
 $ Working_population: int  69495 205749 82622 124596 139500
 $ Students          : int  7050 59628 7582 12636 14642
 $ Unemployed        : int  3852 13894 4076 6143 6542
 $ Age_over_65       : int  26242 74322 37642 64763 70391
 $ Disability        : int  34990 105962 40829 61134 73088
 $ No_central_heating: int  1020 4822 1003 1965 2125
 $ Overcrowding      : int  1892 7352 1888 2700 2355
 $ Working_from_home : int  14880 53721 18973 34750 37299
\end{verbatim}

There is other ways to get info about the number of rows and columns:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{nrow}\NormalTok{(df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ncol}\NormalTok{(df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 12
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#or both row and col}
\FunctionTok{dim}\NormalTok{(df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1]  5 12
\end{verbatim}

The~\texttt{head}~function does this by printing out the first six
records of the data table and you may need to scroll up and down in the
Console pane to see all of what is returned.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    LAD21CD   District Population Households Working_population Students
1 E08000011   Knowsley     154519      66073              69495     7050
2 E08000012  Liverpool     486089     207491             205749    59628
3 E08000013 St. Helens     183248      81011              82622     7582
4 E08000014     Sefton     279234     123075             124596    12636
5 E08000015     Wirral     320196     143253             139500    14642
  Unemployed Age_over_65 Disability No_central_heating Overcrowding
1       3852       26242      34990               1020         1892
2      13894       74322     105962               4822         7352
3       4076       37642      40829               1003         1888
4       6143       64763      61134               1965         2700
5       6542       70391      73088               2125         2355
  Working_from_home
1             14880
2             53721
3             18973
4             34750
5             37299
\end{verbatim}

Another way to explore the data is through
the~\texttt{summary}~function:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
      LAD21CD        District   Population       Households    
 E08000011:1   Knowsley  :1   Min.   :154519   Min.   : 66073  
 E08000012:1   Liverpool :1   1st Qu.:183248   1st Qu.: 81011  
 E08000013:1   Sefton    :1   Median :279234   Median :123075  
 E08000014:1   St. Helens:1   Mean   :284657   Mean   :124181  
 E08000015:1   Wirral    :1   3rd Qu.:320196   3rd Qu.:143253  
                              Max.   :486089   Max.   :207491  
 Working_population    Students       Unemployed     Age_over_65   
 Min.   : 69495     Min.   : 7050   Min.   : 3852   Min.   :26242  
 1st Qu.: 82622     1st Qu.: 7582   1st Qu.: 4076   1st Qu.:37642  
 Median :124596     Median :12636   Median : 6143   Median :64763  
 Mean   :124392     Mean   :20308   Mean   : 6901   Mean   :54672  
 3rd Qu.:139500     3rd Qu.:14642   3rd Qu.: 6542   3rd Qu.:70391  
 Max.   :205749     Max.   :59628   Max.   :13894   Max.   :74322  
   Disability     No_central_heating  Overcrowding  Working_from_home
 Min.   : 34990   Min.   :1003       Min.   :1888   Min.   :14880    
 1st Qu.: 40829   1st Qu.:1020       1st Qu.:1892   1st Qu.:18973    
 Median : 61134   Median :1965       Median :2355   Median :34750    
 Mean   : 63201   Mean   :2187       Mean   :3237   Mean   :31925    
 3rd Qu.: 73088   3rd Qu.:2125       3rd Qu.:2700   3rd Qu.:37299    
 Max.   :105962   Max.   :4822       Max.   :7352   Max.   :53721    
\end{verbatim}

Finally in this section, we come back to the dollar sign (\texttt{\$}).
This is used to refer to or \emph{extract} an individual named field or
variable in an R object, like \texttt{df}.

The code below prints out the Population attribute and generates a
summary of its values:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# extract an individual variable}
\NormalTok{df}\SpecialCharTok{$}\NormalTok{Population}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 154519 486089 183248 279234 320196
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# generate a summary of an individual variable}
\FunctionTok{summary}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{Population)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 154519  183248  279234  284657  320196  486089 
\end{verbatim}

And of course we can use such operations to~\emph{assign}~the result to
new R objects. The code below extracts three variables from~\texttt{df},
assigns them to~\texttt{x},~\texttt{y}~and~\texttt{z}, and then uses
the~\texttt{data.frame}~function to convert these into a
new~\texttt{data.frame}~object called~\texttt{my\_df}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# extract three variables, assigning them to temporary R objects}
\NormalTok{x }\OtherTok{=}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{District}
\NormalTok{y }\OtherTok{=}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{Working\_population}
\NormalTok{z }\OtherTok{=}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{Students}
\CommentTok{\# create a data.frame from these, naming the new variables}
\NormalTok{my\_df }\OtherTok{=} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{district =}\NormalTok{ x,}\AttributeTok{worker =}\NormalTok{ y,}\AttributeTok{student =}\NormalTok{ z)}
\end{Highlighting}
\end{Shaded}

You should have a look at what you have created:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(my\_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    district worker student
1   Knowsley  69495    7050
2  Liverpool 205749   59628
3 St. Helens  82622    7582
4     Sefton 124596   12636
5     Wirral 139500   14642
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(my\_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
       district     worker          student     
 Knowsley  :1   Min.   : 69495   Min.   : 7050  
 Liverpool :1   1st Qu.: 82622   1st Qu.: 7582  
 Sefton    :1   Median :124596   Median :12636  
 St. Helens:1   Mean   :124392   Mean   :20308  
 Wirral    :1   3rd Qu.:139500   3rd Qu.:14642  
                Max.   :205749   Max.   :59628  
\end{verbatim}

The temporary R objects can be removed from the Environment using
the~\texttt{rm}~function and a~\emph{combine}~vector
function,~\texttt{c()}~that you encountered in Week 19, that takes a
vector of object names (hence they are in quotes) as its arguments.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rm}\NormalTok{(}\AttributeTok{list =} \FunctionTok{c}\NormalTok{(}\StringTok{"x"}\NormalTok{,}\StringTok{"y"}\NormalTok{,}\StringTok{"z"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Basic data manipulation}\label{basic-data-manipulation}

Now we can do some basic data manipulation to know Merseyside more from
the data perspective.

What is the total population in Merseyside?

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sum}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{Population)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1423286
\end{verbatim}

What is the total number of full-time students in Merseyside?

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sum}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{Students)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 101538
\end{verbatim}

Then, we can calculate the total number of workers that working from
home:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sum}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{Working\_from\_home)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 159623
\end{verbatim}

What is the proportion of working population actually work from home in
Merseyside? Yes, we need to use a division calculation of the total
number of working from home vs.~all the working population. R can do it
by:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sum}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{Working\_from\_home) }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{Working\_population)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.2566443
\end{verbatim}

So the answer is 25.7\% for the whole Merseyside - but which district
has the highest proportion and which as the lowest? You may have your
own guessing. But let R do the calculation:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df}\SpecialCharTok{$}\NormalTok{Prop.WFH }\OtherTok{=}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{Working\_from\_home }\SpecialCharTok{/}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{Working\_population }\SpecialCharTok{*} \DecValTok{100} \CommentTok{\#add a new column called Prop.WFH}
\NormalTok{df }\CommentTok{\#print out the df}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    LAD21CD   District Population Households Working_population Students
1 E08000011   Knowsley     154519      66073              69495     7050
2 E08000012  Liverpool     486089     207491             205749    59628
3 E08000013 St. Helens     183248      81011              82622     7582
4 E08000014     Sefton     279234     123075             124596    12636
5 E08000015     Wirral     320196     143253             139500    14642
  Unemployed Age_over_65 Disability No_central_heating Overcrowding
1       3852       26242      34990               1020         1892
2      13894       74322     105962               4822         7352
3       4076       37642      40829               1003         1888
4       6143       64763      61134               1965         2700
5       6542       70391      73088               2125         2355
  Working_from_home Prop.WFH
1             14880 21.41161
2             53721 26.10997
3             18973 22.96362
4             34750 27.89014
5             37299 26.73763
\end{verbatim}

Here we ask R to add a new column named \texttt{Prop.WFH} which is the
working from home proportion that calculated by the number of working
from home people in each district divided by the total working
population in that district. The \texttt{*\ 100} convert the rate in the
percentage number. R will automatically do it row-by-row. We then print
out the \texttt{df}, you may find at the very right end of the tabular,
there is a new column called \texttt{Prop.WFH}.

For a very small dataframe like this, we can also using View() to open a
new tab to review the data, where each column can be sorted from largest
to smallest or vice versa. Try viewing it and find the newly created
column \texttt{Prop.WFH}. Click on the column name, you should see it is
sorted from highest to lowest, and click again, the ranking is reversed.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{View}\NormalTok{(df)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Your first map for
Merseyside}\label{your-first-map-for-merseyside}

Now let's try to do our first map in R and allow yourself know more
about Merseyside.

We will use the library sf and tmap to help us at here. Run the install
codes if you haven't install them. Remember: you will only have to
install a package once!!

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{install.packages}\NormalTok{(}\StringTok{"tmap"}\NormalTok{,}\AttributeTok{dep =}\ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Check the package version of tmap, as here we need to use tmap over 4.0
version.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{packageVersion}\NormalTok{(}\StringTok{"tmap"}\NormalTok{) }\CommentTok{\# the version should over 4.0}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] '4.2'
\end{verbatim}

When they have been installed, we can start using them

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(sf)}
\FunctionTok{library}\NormalTok{(tmap)}
\end{Highlighting}
\end{Shaded}

You may find in Week 1 data, we have another file named
\emph{merseyside\_districts.gpkg}. A GeoPackage (GPKG) is a file-based
format designed for storing geographic data. It supports the efficient
storage and exchange of spatial datasets and can be readily used across
GIS software such as QGIS and ArcGIS, as well as in programming
environments including R and Python.

We first read it in by using the \texttt{st\_read()} command in library
sf.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sf }\OtherTok{\textless{}{-}} \FunctionTok{st\_read}\NormalTok{(}\StringTok{"merseyside\_districts.gpkg"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Reading layer `lad_may_2025_uk_bgc_v2_4306843991635065087__lad_may_2025_uk_bgc_v2' from data source `C:\Users\jsmith\OneDrive - George Mason University - O365 Production\Documents\quant\labs\merseyside_districts.gpkg' 
  using driver `GPKG'
Simple feature collection with 5 features and 8 fields
Geometry type: MULTIPOLYGON
Dimension:     XY
Bounding box:  xmin: 318351.7 ymin: 377515.4 xmax: 361796.3 ymax: 422866.5
Projected CRS: OSGB36 / British National Grid
\end{verbatim}

The fastest way to map it is the \texttt{qtm()} function.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{qtm}\NormalTok{(sf)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/01.GettingStartedinRStudio_files/figure-pdf/unnamed-chunk-49-1.pdf}}

You can also add the district names on the map - which column in the sf
contains district name? Use \texttt{names(sf)} to check for it.

Yes, the column should be \texttt{LAD25NM}. Now let's ask \texttt{qtm()}
to also show the district names.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{qtm}\NormalTok{(sf,}\AttributeTok{text=}\StringTok{"LAD25NM"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/01.GettingStartedinRStudio_files/figure-pdf/unnamed-chunk-50-1.pdf}}

But what if we want to make some meaningful maps, rather than just the
boundaries of these five districts of Merseyside?

\subsubsection{Link tabular data to geographical
boundaries}\label{link-tabular-data-to-geographical-boundaries}

Recall that in our \texttt{df}, we have 14 columns, containing different
information about the districts. We can get all their names by using
\texttt{names()}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{names}\NormalTok{(df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] "LAD21CD"            "District"           "Population"        
 [4] "Households"         "Working_population" "Students"          
 [7] "Unemployed"         "Age_over_65"        "Disability"        
[10] "No_central_heating" "Overcrowding"       "Working_from_home" 
[13] "Prop.WFH"          
\end{verbatim}

We can do the same thing for our geographical dataset \texttt{sf} to see
what it includes:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{names}\NormalTok{(sf)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "LAD25CD"  "LAD25NM"  "LAD25NMW" "BNG_E"    "BNG_N"    "LONG"     "LAT"     
[8] "GlobalID" "geom"    
\end{verbatim}

We can also show the whole \texttt{sf} as

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sf}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Simple feature collection with 5 features and 8 fields
Geometry type: MULTIPOLYGON
Dimension:     XY
Bounding box:  xmin: 318351.7 ymin: 377515.4 xmax: 361796.3 ymax: 422866.5
Projected CRS: OSGB36 / British National Grid
    LAD25CD    LAD25NM LAD25NMW  BNG_E  BNG_N      LONG      LAT
1 E08000011   Knowsley          344762 393778 -2.832979 53.43789
2 E08000012  Liverpool          339359 390556 -2.913680 53.40833
3 E08000013 St. Helens          353413 395992 -2.703093 53.45862
4 E08000014     Sefton          334282 398835 -2.991771 53.48213
5 E08000015     Wirral          329109 386965 -3.067034 53.37478
                                GlobalID                           geom
1 {B4196BFE-EE90-4C31-ABD5-C7E743AE2F9B} MULTIPOLYGON (((341447.1 40...
2 {4FB47E7A-EF4E-4B9E-BF75-D4FC059CDE61} MULTIPOLYGON (((338860.9 39...
3 {943F0C6B-EB30-4C00-A42B-F6B3AEC3EFEE} MULTIPOLYGON (((349111.4 40...
4 {C6FD073B-CBEB-4E78-934A-A8FD11A20F0A} MULTIPOLYGON (((336374.5 42...
5 {88E9328B-371C-469C-91F1-3479C77D6950} MULTIPOLYGON (((331364.9 39...
\end{verbatim}

Now we see that sf includes also the five districts, but also other
geographical information. You may notice that although different column
names, the first two columns of both df and sf are the district code and
district name. This means what potentially we can link this two dataset
together - appendix the df to sf to enrich the attributes of our
geographical dataset.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{merseyside }\OtherTok{\textless{}{-}} \FunctionTok{left\_join}\NormalTok{(sf, df,}\AttributeTok{by=}\FunctionTok{c}\NormalTok{(}\StringTok{"LAD25NM"}\OtherTok{=}\StringTok{"District"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

let's check out the new \texttt{sf2} by \texttt{View()} it:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{View}\NormalTok{(merseyside)}
\end{Highlighting}
\end{Shaded}

In the open tab, we see all the \texttt{df} columns are now also
attached to the \texttt{sf}, linking by the district names.

\subsubsection{Choropleth map of Merseyside
districts}\label{choropleth-map-of-merseyside-districts}

Now, we can use those new columns we attached from \texttt{df} to
\texttt{sf2} to make some meaningful choropleth maps! Here we make use
of the mapping functions in tmap (Remember to run \texttt{library(tmap)}
if you haven't) to do the work for us.

\texttt{tmap} has a basic syntax (again, do not run this code - its is
simply showing the syntax of \texttt{tmap}):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# don\textquotesingle{}t run this or write this into your script!}
\FunctionTok{tm\_shape}\NormalTok{(}\AttributeTok{data =} \SpecialCharTok{\textless{}}\NormalTok{data}\SpecialCharTok{\textgreater{}}\NormalTok{)}\SpecialCharTok{+}
\NormalTok{  tm\_}\SpecialCharTok{\textless{}}\ControlFlowTok{function}\SpecialCharTok{\textgreater{}}\NormalTok{(}\SpecialCharTok{\textless{}}\NormalTok{variable to be mapped}\SpecialCharTok{\textgreater{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

For example, to map the boundaries of \texttt{merseyside}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tm\_shape}\NormalTok{(merseyside) }\SpecialCharTok{+} 
  \FunctionTok{tm\_borders}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/01.GettingStartedinRStudio_files/figure-pdf/unnamed-chunk-57-1.pdf}}

To add label of district:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tm\_shape}\NormalTok{(merseyside) }\SpecialCharTok{+} 
  \FunctionTok{tm\_borders}\NormalTok{() }\SpecialCharTok{+} 
  \FunctionTok{tm\_text}\NormalTok{(}\StringTok{"LAD25NM"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/01.GettingStartedinRStudio_files/figure-pdf/unnamed-chunk-58-1.pdf}}

You might assume the quick mapping function \texttt{qtm()} can achieve
the same result, but \texttt{tmap} provides far more flexibility when it
comes to aesthetic customization. The easiest way to illustrate
\texttt{tmap} is through some examples.

Let's start with a simple choropleth map, by using \texttt{tmap} to show
the distribution of a continuous variable in different elements of the
spatial data (here are the data Merseyside districts are polygons).

The code below maps `\texttt{Students}' as in the Merseyside districts,
and shows the district names of each polygon from `\texttt{LAD25NM}'
columns. The map below indicates that Liverpool has the highest number
of full-time students while Knowsley and St.Helens have the least.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tm\_shape}\NormalTok{(merseyside) }\SpecialCharTok{+} 
  \FunctionTok{tm\_polygons}\NormalTok{(}\AttributeTok{fill =} \StringTok{"Students"}\NormalTok{) }\SpecialCharTok{+}   \CommentTok{\# Variable to map }
  \FunctionTok{tm\_text}\NormalTok{(}\StringTok{"LAD25NM"}\NormalTok{)                 }\CommentTok{\# Variable to label}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/01.GettingStartedinRStudio_files/figure-pdf/unnamed-chunk-59-1.pdf}}

By default tmap picks a shading scheme, the class breaks and places a
legend somewhere. All of these can be changed. The code below allocates
the tmap plot to \texttt{map1} (Map 1), change the legend title as
``Number of students in Merseyside districts'', and then prints it:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{map1  }\OtherTok{=} \FunctionTok{tm\_shape}\NormalTok{(merseyside) }\SpecialCharTok{+} 
  \FunctionTok{tm\_polygons}\NormalTok{(}\AttributeTok{fill=}\StringTok{"Students"}\NormalTok{,}
              \AttributeTok{fill.scale =} \FunctionTok{tm\_scale}\NormalTok{(}\AttributeTok{values =} \StringTok{"Greens"}\NormalTok{), }\CommentTok{\# change palette to greens}
              \AttributeTok{fill.legend =} \FunctionTok{tm\_legend}\NormalTok{(}\AttributeTok{title =} \StringTok{"Number of students in Merseyside districts"}\NormalTok{)}
\NormalTok{              ) }\SpecialCharTok{+}\CommentTok{\# Legend title}
  \FunctionTok{tm\_text}\NormalTok{(}\StringTok{"LAD25NM"}\NormalTok{,}\AttributeTok{size=}\FloatTok{0.8}\NormalTok{) }\CommentTok{\#size down the label slightly}
\NormalTok{map1}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/01.GettingStartedinRStudio_files/figure-pdf/unnamed-chunk-60-1.pdf}}

And of course many other elements included either by running the code
snippet defining \texttt{map1} above with additional lines or by simply
adding them as in the code below:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{map1 }\SpecialCharTok{+} 
  \FunctionTok{tm\_scalebar}\NormalTok{(}\AttributeTok{position =} \FunctionTok{c}\NormalTok{(}\StringTok{"right"}\NormalTok{, }\StringTok{"bottom"}\NormalTok{)) }\SpecialCharTok{+} 
  \FunctionTok{tm\_compass}\NormalTok{(}\AttributeTok{position =} \FunctionTok{c}\NormalTok{(}\StringTok{"left"}\NormalTok{, }\StringTok{"top"}\NormalTok{))  }\CommentTok{\# Use "top", "center", or "bottom"}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/01.GettingStartedinRStudio_files/figure-pdf/unnamed-chunk-61-1.pdf}}

We can also create new variable to the dataset and then map it. The
below code chunk first creates a new column,
``\texttt{NoCentralHeating\_rate}'', by dividing the number of
households without access to central heating by the total number of
households in each district; it then uses \texttt{tmap} to make a map of
the proportion of households without central heating across districts in
Merseyside:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{merseyside}\SpecialCharTok{$}\NormalTok{NoCentralHeating\_rate }\OtherTok{=}\NormalTok{ merseyside}\SpecialCharTok{$}\NormalTok{No\_central\_heating }\SpecialCharTok{/}\NormalTok{ merseyside}\SpecialCharTok{$}\NormalTok{Households }\SpecialCharTok{*} \DecValTok{100}

\NormalTok{map2 }\OtherTok{=} \FunctionTok{tm\_shape}\NormalTok{(merseyside) }\SpecialCharTok{+} 
  \FunctionTok{tm\_polygons}\NormalTok{(}\AttributeTok{fill=}\StringTok{"NoCentralHeating\_rate"}\NormalTok{,}
              \AttributeTok{fill.scale =} \FunctionTok{tm\_scale}\NormalTok{(}\AttributeTok{values =} \StringTok{"Reds"}\NormalTok{, }\AttributeTok{style =} \StringTok{"jenks"}\NormalTok{), }\CommentTok{\#use jenks classification rather than equal}
              \AttributeTok{fill.legend =} \FunctionTok{tm\_legend}\NormalTok{(}\AttributeTok{title =} \StringTok{"\% No Central Heating"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{tm\_text}\NormalTok{(}\StringTok{"LAD25NM"}\NormalTok{,}\AttributeTok{size=}\FloatTok{0.8}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{tm\_scalebar}\NormalTok{(}\AttributeTok{position =} \FunctionTok{c}\NormalTok{(}\StringTok{"right"}\NormalTok{, }\StringTok{"bottom"}\NormalTok{)) }\SpecialCharTok{+}  \CommentTok{\# Add a scale bar at the top{-}right corner}
  \FunctionTok{tm\_compass}\NormalTok{(}\AttributeTok{position =} \FunctionTok{c}\NormalTok{(}\StringTok{"left"}\NormalTok{, }\StringTok{"top"}\NormalTok{))  }\CommentTok{\# Add a compass rose at the top{-}right corner}
\NormalTok{map2}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/01.GettingStartedinRStudio_files/figure-pdf/unnamed-chunk-62-1.pdf}}

\subsection{Merseyside neighbourhoods}\label{merseyside-neighbourhoods}

Now let's read in the neighbourhood-level datasets, which include a
\texttt{.csv} file of local statistics and the corresponding
geographical boundaries.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lsoa\_df }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"merseyside\_lsoa.csv"}\NormalTok{)}
\NormalTok{lsoa\_sf }\OtherTok{\textless{}{-}} \FunctionTok{st\_read}\NormalTok{(}\StringTok{"LSOA\_boundaries.gpkg"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Reading layer `merseyside_LSOA' from data source 
  `C:\Users\jsmith\OneDrive - George Mason University - O365 Production\Documents\quant\labs\LSOA_boundaries.gpkg' 
  using driver `GPKG'
Simple feature collection with 923 features and 4 fields
Geometry type: MULTIPOLYGON
Dimension:     XY
Bounding box:  xmin: -3.200368 ymin: 53.2963 xmax: -2.576743 ymax: 53.6982
Geodetic CRS:  WGS 84
\end{verbatim}

First, we take a look at the \texttt{.csv} dataset, which as been read
into R as \texttt{lsoa\_df}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{View}\NormalTok{(lsoa\_df)}
\end{Highlighting}
\end{Shaded}

or check the structure of the dataset:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{str}\NormalTok{(lsoa\_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
'data.frame':   923 obs. of  11 variables:
 $ LSOA21CD          : chr  "E01006416" "E01006418" "E01006434" "E01006435" ...
 $ Population        : int  1520 1315 1519 1524 1150 1654 1450 1581 1421 1373 ...
 $ Households        : int  678 567 652 663 490 695 592 622 809 618 ...
 $ Working_population: int  588 547 660 581 546 766 558 570 524 481 ...
 $ Students          : int  59 64 69 82 51 66 65 89 52 72 ...
 $ Unemployed        : num  3.57 2.74 5.11 3.43 1.62 ...
 $ Age_over_65       : num  14.8 17.5 11.7 19.9 26.3 ...
 $ Disability        : num  27.1 30 23.4 29 20.5 ...
 $ No_central_heating: int  16 14 16 7 3 8 9 9 12 9 ...
 $ Overcrowding      : int  24 24 35 28 13 21 29 23 31 22 ...
 $ Working_from_home : int  91 84 102 96 165 171 101 64 66 48 ...
\end{verbatim}

So now, you know how many LSOAs in Merseyside? Yes, there are 923 LSOAs.
As we introduced in the Week 1 lecture, LSOA means Super Output Area
Lower Area and is commonly used in the Census statistics. Each LSOA
represents 1,000 to 3,000 people or 400 to 1,200 households in England
and Wales.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dim}\NormalTok{(lsoa\_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 923  11
\end{verbatim}

Use the quick mapping function \texttt{qtm()} to quickly inspect the
geographical boundary dataset \texttt{lsoa\_sf} .

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{qtm}\NormalTok{(lsoa\_sf)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/01.GettingStartedinRStudio_files/figure-pdf/unnamed-chunk-67-1.pdf}}

check how many LSOAs in the boundary dataset - there should also be 923.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{nrow}\NormalTok{(lsoa\_sf)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 923
\end{verbatim}

To familiarise yourself with the structures of both datasets, we can use
the \texttt{names()} command

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{names}\NormalTok{(lsoa\_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] "LSOA21CD"           "Population"         "Households"        
 [4] "Working_population" "Students"           "Unemployed"        
 [7] "Age_over_65"        "Disability"         "No_central_heating"
[10] "Overcrowding"       "Working_from_home" 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{names}\NormalTok{(lsoa\_sf)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "LSOA21CD" "LSOA21NM" "LAD23CD"  "LAD23NM"  "geom"    
\end{verbatim}

You may find that both dataset are recorded at the LSOA level, with
\texttt{LSOA21CD} as the key column. As we did with the district-level
dataset, we can use \texttt{left\_join()} to join these two dataset by
their sharing field - \texttt{LSOA21CD}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lsoa }\OtherTok{\textless{}{-}} \FunctionTok{left\_join}\NormalTok{(lsoa\_sf,lsoa\_df,}\AttributeTok{by=}\StringTok{"LSOA21CD"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Now let's check the columns of new dataframe \texttt{lsoa}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{names}\NormalTok{(lsoa)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] "LSOA21CD"           "LSOA21NM"           "LAD23CD"           
 [4] "LAD23NM"            "Population"         "Households"        
 [7] "Working_population" "Students"           "Unemployed"        
[10] "Age_over_65"        "Disability"         "No_central_heating"
[13] "Overcrowding"       "Working_from_home"  "geom"              
\end{verbatim}

Or open a new tab to view the newly created dataset \texttt{lsoa} by

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{View}\NormalTok{(lsoa)}
\end{Highlighting}
\end{Shaded}

We can see that some columns contain counts, such as the number of
residential population, number of households, number of working
population, and number of students. Other columns are expressed as
percentages, including unemployment, population aged 65 and over,
disability, households without central heating, overcrowded households,
and people working from home.

\subsubsection{Making maps across LSOAs in
Merseyside}\label{making-maps-across-lsoas-in-merseyside}

Using the \texttt{Unemployed} column, we can create a map of the
unemployment rate across neighbourhoods in Merseyside. Instead of using
the default equal-interval breaks, this time we will use a jenks
classification with six categories.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{map3 }\OtherTok{=} \FunctionTok{tm\_shape}\NormalTok{(lsoa) }\SpecialCharTok{+}
  \FunctionTok{tm\_fill}\NormalTok{(}
    \AttributeTok{fill =} \StringTok{"Unemployed"}\NormalTok{,}
    \AttributeTok{fill.scale =} \FunctionTok{tm\_scale}\NormalTok{(}\AttributeTok{values =} \StringTok{"GnBu"}\NormalTok{, }
                          \AttributeTok{style =} \StringTok{"jenks"}\NormalTok{, }
                          \AttributeTok{n =} \DecValTok{6}\NormalTok{), }\CommentTok{\#use jenks classification of 6 categories}
    \AttributeTok{fill.legend =} \FunctionTok{tm\_legend}\NormalTok{(}\AttributeTok{title =} \StringTok{"\% Unemployed"}\NormalTok{)}
\NormalTok{    ) }\SpecialCharTok{+}
  \FunctionTok{tm\_layout}\NormalTok{(}\AttributeTok{legend.position =} \FunctionTok{c}\NormalTok{(}\StringTok{"right"}\NormalTok{, }\StringTok{"top"}\NormalTok{))}
\NormalTok{map3}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/01.GettingStartedinRStudio_files/figure-pdf/unnamed-chunk-73-1.pdf}}

The above code uses
\texttt{tm\_layout(legend.position\ =\ c("right",\ "top"))} to move the
legend inside the map frame, positioning it at the right-top corner.

Replace \texttt{tm\_fill()} to \texttt{tm\_polygons()} to see how the
map changes?

\texttt{tm\_polygons()} is a condense version of
\texttt{tm\_fill()\ +\ tm\_border()}. Here if you want show all the LSOA
borders, use \texttt{tm\_polygons()} instead of \texttt{tm\_fill()}.

\subsubsection{Overlapping tmap objects}\label{overlapping-tmap-objects}

\texttt{tmap} also supports adding or overlaying other data, such as
boundaries. Because these are additional spatial data layers, they needs
to be added with \texttt{tm\_shape()} followed by the usual function.

Remember we use the code chunk to make the district boundaries of
Merseyside? This time let's change the aesthetic by using grey color as
the border color and increase the line width, then we save it also as a
\texttt{tmap} object called map\_district:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{map\_district }\OtherTok{=} \FunctionTok{tm\_shape}\NormalTok{(merseyside) }\SpecialCharTok{+} 
  \FunctionTok{tm\_borders}\NormalTok{(}\AttributeTok{col =} \StringTok{"grey50"}\NormalTok{,}\AttributeTok{lwd=}\FloatTok{1.5}\NormalTok{) }\SpecialCharTok{+} \CommentTok{\#border color as grey, line width as 1.5}
  \FunctionTok{tm\_text}\NormalTok{(}\StringTok{"LAD25NM"}\NormalTok{,}\AttributeTok{size =} \FloatTok{0.8}\NormalTok{)}
\NormalTok{map\_district}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/01.GettingStartedinRStudio_files/figure-pdf/unnamed-chunk-74-1.pdf}}

To display both \texttt{tmap} layers together, we can proceed as
follows:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{map3 }\SpecialCharTok{+}\NormalTok{ map\_district}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/01.GettingStartedinRStudio_files/figure-pdf/unnamed-chunk-75-1.pdf}}

Now, let's move to making some more maps - this time showing the
proportion of disability across neighbourhoods in Merseyside. Referring
back to the columns in \texttt{lsoa}, this time we use the
\texttt{Disability} variable. The code below applies a jenks
classification and use a different color palette \texttt{Purples}. Also
the map frame is removed by \texttt{frame\ =\ FALSE}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tm\_shape}\NormalTok{(lsoa) }\SpecialCharTok{+} 
  \FunctionTok{tm\_fill}\NormalTok{(}\AttributeTok{fill =} \StringTok{"Disability"}\NormalTok{,}
          \AttributeTok{fill.scale =} \FunctionTok{tm\_scale}\NormalTok{(}\AttributeTok{values=}\StringTok{"Purples"}\NormalTok{, }
                                \AttributeTok{style =} \StringTok{"jenks"}\NormalTok{,}
                                \AttributeTok{n=}\DecValTok{5}\NormalTok{),}
          \AttributeTok{fill.legend =} \FunctionTok{tm\_legend}\NormalTok{(}\AttributeTok{title =} \StringTok{"\% Disability"}\NormalTok{)}
\NormalTok{          ) }\SpecialCharTok{+}
  \FunctionTok{tm\_layout}\NormalTok{(}\AttributeTok{main.title =} \StringTok{"Merseyside"}\NormalTok{,}\CommentTok{\#add a main title}
            \AttributeTok{legend.position =} \FunctionTok{c}\NormalTok{(}\StringTok{"right"}\NormalTok{, }\StringTok{"top"}\NormalTok{),}
            \AttributeTok{frame =} \ConstantTok{FALSE}\NormalTok{)}\SpecialCharTok{+}
\NormalTok{  map\_district}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/01.GettingStartedinRStudio_files/figure-pdf/unnamed-chunk-76-1.pdf}}

\subsubsection{Create new variables to make
maps}\label{create-new-variables-to-make-maps}

Similarly, we can make maps from new columns we made ourselves. For
example, we can calculate the percentage of student by adding a new
column to the dataframe:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lsoa}\SpecialCharTok{$}\NormalTok{student.perc }\OtherTok{=}\NormalTok{ lsoa}\SpecialCharTok{$}\NormalTok{Students }\SpecialCharTok{/}\NormalTok{ lsoa}\SpecialCharTok{$}\NormalTok{Population }\SpecialCharTok{*} \DecValTok{100}
\end{Highlighting}
\end{Shaded}

To make a map to visualisation the spatial distribution of student
percentage. The code below uses \texttt{n=6} to increase the
classification categories to 6 rather than default 5.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tm\_shape}\NormalTok{(lsoa) }\SpecialCharTok{+} 
  \FunctionTok{tm\_fill}\NormalTok{(}\AttributeTok{fill =} \StringTok{"student.perc"}\NormalTok{,}
          \AttributeTok{fill.scale =} \FunctionTok{tm\_scale}\NormalTok{(}\AttributeTok{values=}\StringTok{"Blues"}\NormalTok{,}
                                \AttributeTok{style =} \StringTok{"jenks"}\NormalTok{,}
                                \AttributeTok{n=}\DecValTok{6}\NormalTok{),}
          \AttributeTok{fill.legend =} \FunctionTok{tm\_legend}\NormalTok{(}\AttributeTok{title =} \StringTok{"\% of Student"}\NormalTok{,}
                                  \AttributeTok{title.size =} \FloatTok{0.8}\NormalTok{) }\CommentTok{\#legend title change smaller font}
\NormalTok{          ) }\SpecialCharTok{+}
  \FunctionTok{tm\_layout}\NormalTok{(}\AttributeTok{main.title =} \StringTok{"Merseyside"}\NormalTok{,}
            \AttributeTok{frame =} \ConstantTok{FALSE}\NormalTok{,}
            \AttributeTok{legend.position =} \FunctionTok{c}\NormalTok{(}\StringTok{"right"}\NormalTok{, }\StringTok{"top"}\NormalTok{))}\SpecialCharTok{+}
\NormalTok{  map\_district}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/01.GettingStartedinRStudio_files/figure-pdf/unnamed-chunk-78-1.pdf}}

To change the palette, RColorBrewer provides different palette choices:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{RColorBrewer}\SpecialCharTok{::}\FunctionTok{display.brewer.all}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics[width=0.8\linewidth,height=\textheight,keepaspectratio]{labs/01.GettingStartedinRStudio_files/figure-pdf/unnamed-chunk-79-1.pdf}

\subsubsection{In a nutshell}\label{in-a-nutshell}

If we want to make a map to show the rate of no central heating
households in all the neighbourhoods in Merseyside, we need to create a
new variable \texttt{no.central.heating.perc} as the result of dividing
households without central heating by total households in each LSOA. The
code below combines all the cartographic elements together:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lsoa}\SpecialCharTok{$}\NormalTok{no.central.heating.perc }\OtherTok{=}\NormalTok{ lsoa}\SpecialCharTok{$}\NormalTok{No\_central\_heating }\SpecialCharTok{/}\NormalTok{ lsoa}\SpecialCharTok{$}\NormalTok{Households }\SpecialCharTok{*} \DecValTok{100}

\FunctionTok{tm\_shape}\NormalTok{(lsoa) }\SpecialCharTok{+} 
  \FunctionTok{tm\_fill}\NormalTok{(}\AttributeTok{fill =} \StringTok{"no.central.heating.perc"}\NormalTok{,}
          \AttributeTok{fill.scale =} \FunctionTok{tm\_scale}\NormalTok{(}\AttributeTok{values=}\StringTok{"YlOrRd"}\NormalTok{,}
                                \AttributeTok{style =} \StringTok{"jenks"}\NormalTok{,}\AttributeTok{n=}\DecValTok{6}\NormalTok{),}
          \AttributeTok{fill.legend =} \FunctionTok{tm\_legend}\NormalTok{(}\AttributeTok{title =} \StringTok{"\% of no central heating households"}\NormalTok{, }
                                  \AttributeTok{title.size =} \FloatTok{0.8}\NormalTok{)}
\NormalTok{        ) }\SpecialCharTok{+}
  \FunctionTok{tm\_layout}\NormalTok{(}\AttributeTok{main.title =} \StringTok{"Merseyside"}\NormalTok{,}
            \AttributeTok{main.title.size=}\FloatTok{1.2}\NormalTok{,}
            \AttributeTok{frame =} \ConstantTok{FALSE}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{tm\_compass}\NormalTok{(}\AttributeTok{position =} \FunctionTok{c}\NormalTok{(}\StringTok{"right"}\NormalTok{, }\StringTok{"top"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{tm\_scalebar}\NormalTok{(}\AttributeTok{position =} \FunctionTok{c}\NormalTok{(}\StringTok{"right"}\NormalTok{, }\StringTok{"bottom"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{tm\_shape}\NormalTok{(merseyside) }\SpecialCharTok{+}               \CommentTok{\# Add another spatial layer (Merseyside boundary)}
  \FunctionTok{tm\_borders}\NormalTok{(}\AttributeTok{col =} \StringTok{"black"}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{1}\NormalTok{) }\SpecialCharTok{+}  \CommentTok{\# Draw the boundaries with black lines of width 1}
  \FunctionTok{tm\_text}\NormalTok{(}\StringTok{"LAD25NM"}\NormalTok{,}\AttributeTok{col =} \StringTok{"blue"}\NormalTok{,}\AttributeTok{size =} \FloatTok{0.8}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/01.GettingStartedinRStudio_files/figure-pdf/unnamed-chunk-80-1.pdf}}

\section{Summary}\label{summary}

The aim of this session has been to familiarise you with the R
environment if you have not used R before. If you have but not for a
while, then hopefully this has acted as a refresher. Some key things to
take away are:

\begin{itemize}
\item
  R is a learning curve, and like driving the more your practice the
  better you become.
\item
  Your job is to try to \textbf{understand} what the code is doing and
  \textbf{not} to remember the code.
\item
  To help with this, you should add your own comments to the script to
  help you understand what is going on when you return to them. Comments
  are prefaced by a hash (\texttt{\#}) that is ignored by R.
\item
  Always set your working directory to the sub-folder containing your R
  script.
\item
  Always run your code from an R script\ldots{} \textbf{always}!
\end{itemize}

\subsection{References}\label{references}

Brunsdon, Chris, and Lex Comber. 2018. \emph{An Introduction to r for
Spatial Analysis and Mapping (2e)}. Sage.

Comber, Lex, and Chris Brunsdon. 2021. \emph{Geographical Data Science
and Spatial Data Analysis: An Introduction in r}. Sage.

Harris, Richard. 2016. \emph{Quantitative Geography: The Basics}. Sage.

Other good on-line \emph{get started in R} guides include:

\begin{itemize}
\item
  The Owen guide (only up to page 28) :
  \url{https://cran.r-project.org/doc/contrib/Owen-TheRGuide.pdf}
\item
  An Introduction to R -
  \url{https://cran.r-project.org/doc/contrib/Lam-IntroductionToR_LHL.pdf}
\item
  R for beginners
  \url{https://cran.r-project.org/doc/contrib/Paradis-rdebuts_en.pdf}
\end{itemize}

\section{Formative Tasks}\label{formative-tasks}

\textbf{Task 1} From the district level dataset ``merseyside.csv'',
extract household information for the Liverool and Wirral districts. The
variables to be included are ``Households'', ``No\_central\_heating''
and ``Overcrowding''.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"merseyside.csv"}\NormalTok{)  }
\NormalTok{df[}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{5}\NormalTok{),}\FunctionTok{c}\NormalTok{(}\StringTok{"District"}\NormalTok{,}\StringTok{"Households"}\NormalTok{,}\StringTok{"No\_central\_heating"}\NormalTok{,}\StringTok{"Overcrowding"}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   District Households No_central_heating Overcrowding
2 Liverpool     207491               4822         7352
5    Wirral     143253               2125         2355
\end{verbatim}

\textbf{Task 2} Use the dataset ``merseyside\_lsoa.csv'', plot the
\texttt{Disability} against \texttt{Age\_over\_65} from the data frame.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lsoa\_df }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"merseyside\_lsoa.csv"}\NormalTok{) }
\FunctionTok{plot}\NormalTok{(Disability}\SpecialCharTok{\textasciitilde{}}\NormalTok{Age\_over\_65, }\AttributeTok{data =}\NormalTok{ lsoa\_df) }
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/01.GettingStartedinRStudio_files/figure-pdf/unnamed-chunk-82-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# or }
\FunctionTok{plot}\NormalTok{(lsoa\_df}\SpecialCharTok{$}\NormalTok{Disability, lsoa\_df}\SpecialCharTok{$}\NormalTok{Age\_over\_65)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/01.GettingStartedinRStudio_files/figure-pdf/unnamed-chunk-82-2.pdf}}

\textbf{Task 3} Use the district level dataset, how many households in
total in Merseyside?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"merseyside.csv"}\NormalTok{)}
\FunctionTok{sum}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{Households)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 620903
\end{verbatim}

\textbf{Task 4} Use the district level dataset, what is the overall
proportion of the ageing population (age over 65) in Merseyside?

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sum}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{Age\_over\_65)}\SpecialCharTok{/}\FunctionTok{sum}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{Population)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.1920626
\end{verbatim}

\textbf{Task 5} Use the LSOA level dataset, what is the average
proportion of the ageing population (age over 65) across all the
neighbourhoods of Merseyside?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df}\SpecialCharTok{$}\NormalTok{ageing\_rate }\OtherTok{=}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{Age\_over\_65 }\SpecialCharTok{/}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{Population }\SpecialCharTok{*} \DecValTok{100}
\FunctionTok{mean}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{ageing\_rate)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 19.59824
\end{verbatim}

\textbf{Task 6} Create a map showing the spatial distribution of the
proportion of ageing population (age over 65) over LSOAs in Merseyside?
(use Jenks classification of 7 categories).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lsoa}\SpecialCharTok{$}\NormalTok{ageing\_rate }\OtherTok{=}\NormalTok{ lsoa}\SpecialCharTok{$}\NormalTok{Age\_over\_65 }\SpecialCharTok{/}\NormalTok{ lsoa}\SpecialCharTok{$}\NormalTok{Population }\SpecialCharTok{*} \DecValTok{100}

\FunctionTok{tm\_shape}\NormalTok{(lsoa) }\SpecialCharTok{+} 
  \FunctionTok{tm\_fill}\NormalTok{(}\AttributeTok{fill =} \StringTok{"ageing\_rate"}\NormalTok{,}
          \AttributeTok{fill.scale =} \FunctionTok{tm\_scale}\NormalTok{(}\AttributeTok{values=}\StringTok{"PuRd"}\NormalTok{,}\AttributeTok{style =} \StringTok{"jenks"}\NormalTok{,}\AttributeTok{n=}\DecValTok{7}\NormalTok{),}
          \AttributeTok{fill.legend =} \FunctionTok{tm\_legend}\NormalTok{(}\AttributeTok{title =} \StringTok{"\% Age over 65"}\NormalTok{, }\AttributeTok{title.size =} \FloatTok{0.8}\NormalTok{)}
\NormalTok{        ) }\SpecialCharTok{+}
  \FunctionTok{tm\_layout}\NormalTok{(}\AttributeTok{main.title =} \StringTok{"Merseyside"}\NormalTok{,}
            \AttributeTok{main.title.size=}\FloatTok{1.2}\NormalTok{,}
            \AttributeTok{frame =} \ConstantTok{FALSE}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{tm\_compass}\NormalTok{(}\AttributeTok{position =} \FunctionTok{c}\NormalTok{(}\StringTok{"right"}\NormalTok{, }\StringTok{"top"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{tm\_scalebar}\NormalTok{(}\AttributeTok{position =} \FunctionTok{c}\NormalTok{(}\StringTok{"right"}\NormalTok{, }\StringTok{"bottom"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{tm\_shape}\NormalTok{(merseyside) }\SpecialCharTok{+}               \CommentTok{\# Add another spatial layer (Merseyside boundary)}
  \FunctionTok{tm\_borders}\NormalTok{(}\AttributeTok{col =} \StringTok{"black"}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{1}\NormalTok{) }\SpecialCharTok{+}  \CommentTok{\# Draw the boundaries with black lines of width 1}
  \FunctionTok{tm\_text}\NormalTok{(}\StringTok{"LAD25NM"}\NormalTok{,}\AttributeTok{col =} \StringTok{"blue"}\NormalTok{,}\AttributeTok{size =} \FloatTok{0.8}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/01.GettingStartedinRStudio_files/figure-pdf/unnamed-chunk-86-1.pdf}}

\bookmarksetup{startatroot}

\chapter{Lab: Exploratory Data Analysis - UK
Election}\label{lab-exploratory-data-analysis---uk-election}

\section{\texorpdfstring{\textbf{Overview}}{Overview}}\label{overview-2}

This week's practical session will draw upon the UK 2024 constituency
election dataset. We will revisit some libraries and functions we have
used last week, but also learn to do our first exploratory data analysis
by foundmental R coding. We will do:

\begin{itemize}
\item
  Loading and examining tabular data (like spreadsheets) and
  geographical data into R (same as Week 1)
\item
  Exploratory Data Analysis (or EDA) of numeric variables and
  categorical variables
\item
  Using histogram, boxplot, barplot to understand the distribution of
  variables
\item
  Variable interactions, particularly cross-tabulation and between-group
  comparison
\end{itemize}

You may wish to recap this week's lecture:
\href{https://canvas.liverpool.ac.uk/courses/85565/files/folder/Stats\%20Block/Week\%202?preview=13571700}{Lecture
02.pptx}

\section{Clear the decks}\label{clear-the-decks}

\begin{itemize}
\item
  For this Week 2 session, create a sub-folder called~\texttt{Week2}~in
  your~\texttt{ENVS162} folder on your M-Drive.
\item
  Open RStudio
\item
  Open a new R Script for your Week 2 work, rename it as Week2.R and
  save it in your newly created Week 2 folder, under M drive
  -\textgreater{} ENVS162 folder. This is exactly the step we did in
  Week 1, and we will do this every week to Week 5.
\item
  Check whether there is any previous left dataframes in your RStudio in
  the upper-right side Environment pane. You can always use the
  \pandocbounded{\includegraphics[keepaspectratio]{labs/images/clipboard-4263234033.png}}
  to clear all the dataframes in your environment and make it all clean.
  For the same aim, you can run the below code:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rm}\NormalTok{(}\AttributeTok{list =} \FunctionTok{ls}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

This command will clear RStudio's memory, removing any data objects that
you have previously created.

\section{Open libraries}\label{open-libraries}

In Week 1 we have installed essential R package \texttt{tidyverse},
\texttt{sf}, and \texttt{tmap}. Remember if any package has been
installed, then we don't need to re-install them. Instead, we use
library() command to import and use them.

As ever, when you start a new session in RStudio, you need to load the
packages you wish to use into memory. Similarly, there
are~\texttt{tidyverse},~\texttt{tmap} and~\texttt{sf}~packages we've
used last week.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(sf)}
\FunctionTok{library}\NormalTok{(tmap)}
\end{Highlighting}
\end{Shaded}

If R returns \ul{Error: there is no package called `***'}. Then it means
that the package `***' has not been installed in the PC you current use.
Therefore you need to install them first. Switch back to Week 1
instruction - Getting set up with RStudio - Your first R code - Package
part to refresh yourself how to do this.

\section{Parliamentary Constituency
Data}\label{parliamentary-constituency-data}

\subsection{Load the dataset}\label{load-the-dataset}

In 2024 the UK held a general election. Download the file
\textbf{\emph{uk\_constituencies\_2024.csv}} from our
\href{https://canvas.liverpool.ac.uk/courses/85565}{Canvas module page
Week 2}. Save the dataset in your M drive - ENVS162 - Week 2 folder,
alongside the Week 2. R script. Read in the dataset exactly in the same
way as we did in Week 1 - insert the below code line and run it:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pc\_data }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"uk\_constituencies\_2024.csv"}\NormalTok{,}\AttributeTok{stringsAsFactors =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The datasheet captures a range of information relating to this election,
and to the nature of each parliamentary constituency. By using
\texttt{read.csv()} command, we use R to store the dataset in a
dataframe called \texttt{pc\_data} (short for Parliamentary Constituency
data).

The \texttt{pc\_data} dataset should appear in your RStudio Environment
Pane on the upper right part, indicating that it has now been loaded
into memory, and is available for analysis.

\textbf{For your information only}, the \texttt{pc\_data} dataset has
been assembled by combining information from the following sources.

\begin{itemize}
\item
  \emph{HoC-GE2024-results-by-constituency.xlsx}

  \emph{Source}: Cracknell et al (2024) General election 2024 results,
  \emph{Research Briefing}, House of Commons Library.
  https://commonslibrary.parliament.uk/research-briefings/cbp-10009/
\item
  \emph{Demographic-data-for-new-parliamentary-constituencies-May-2024.xlsx}

  \emph{Source}: House of Commons Demographic data for Constituencies
  https://commonslibrary.parliament.uk/data-for-new-parliamentary-constituencies/
\item
  \emph{NatCen Constituency Data\_20 June 2024.xlsx}

  \emph{Source}: National Centre for Social Research (2024)
  Parliamentary constituency look-up,
  https://natcen.ac.uk/constituency-look-up (date accessed: 07-02-2025)
\item
  \emph{nomis\_2025\_01\_14\_101749.xlsx}

  \emph{Source}: Income data from Annual Survey of Hours and Earnings
  (ASHE), collecgted by the Office for National Statistics.
  https://www.nomisweb.co.uk/datasets/asher
\end{itemize}

\subsection{Familiar with the dataset and variable
types}\label{familiar-with-the-dataset-and-variable-types}

In the \texttt{pc\_data} dataset each row represents a different UK
Parliamentary Constituency. Use the \texttt{View()} command to
familiarise yourself with the variables contained in the dataset.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{View}\NormalTok{(pc\_data)}
\end{Highlighting}
\end{Shaded}

Use the \texttt{nrow(\ )} or \texttt{dim()} command to find out how many
Parliamentary Constituencies (and therefore MPs) there are in the UK.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{nrow}\NormalTok{(pc\_data)}

\FunctionTok{dim}\NormalTok{(pc\_data)}
\end{Highlighting}
\end{Shaded}

Whenever we try to understand the variables in one dataset, the first
question to ask ourselves is: ``are they \emph{continuous} or
\emph{categorical} ?''

Continuous variables are numeric measures of some quantity, such as a
count or percentage or a precise value. E.g. number of valid votes; \%
of persons unemployed etc.

In contrast, categorical variables simply group observations into
categories or ranges. E.g. name of the winning party; age group etc.

Explore the structure of the data table using the~\texttt{str}~function
and have examined it by \texttt{head}~functions.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{str}\NormalTok{(pc\_data)}

\FunctionTok{head}\NormalTok{(pc\_data)}
\end{Highlighting}
\end{Shaded}

We can see that we have numeric data in integers (\texttt{int}) form
(these are counts or whole numbers) and continuous (\texttt{num}) form,
and the character variables (text) have been converted to
\texttt{factors}. For each of these data types we can generate numeric
and visual summaries and we can also see how they interact with each
other.

The \texttt{pc\_data} dataset contains three basic sets of information
about each Parliamentary Constituency:

\begin{itemize}
\item
  \textbf{constituency identifiers} - \emph{gss\_code} and
  \emph{pc\_name}
\item
  \textbf{population information} for each constituency, ranging from
  the total population and number of households through to the \% in
  various categories to information about local house prices, salaries
  and crime rates
\item
  \textbf{2024 election results} ranging from the winning MP and party
  through to the size of the electorate and vote turnout, and the share
  of votes received by each party
\end{itemize}

\subsection{Exploratory Data Analysis
(EDA)}\label{exploratory-data-analysis-eda}

\subsubsection{Numeric variables}\label{numeric-variables}

You can use the \texttt{pc\_data} dataset to extract some headline
results from the 2024 General Election. Starting with the simplest case,
the distribution of a single numeric variable whether continuous or
count based can be examined numerically using the \texttt{summary}
function.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#valid votes in constituency}
\FunctionTok{summary}\NormalTok{(pc\_data}\SpecialCharTok{$}\NormalTok{valid\_votes)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  13528   40397   44628   44322   48607   57744 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# percentage of White British in constituency}
\FunctionTok{summary}\NormalTok{(pc\_data}\SpecialCharTok{$}\NormalTok{pct\_White\_British)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  8.937  71.534  86.208  78.006  92.843  98.664 
\end{verbatim}

A visual approach is more intuitive. The code below plots histograms of
the two variables, using the \texttt{hist} function. The logic
under-pinning a histogram is that a continuous variable (in this case
\texttt{valid\_votes} and \texttt{pct\_White\_British}) is temporarily
regrouped into categories, using an equal-interval approach. The number
of observations (in this case, constituencies) that fall into each
equal-interval category then determine the height of each column in the
histogram.The comments after each line shall inform you what the
\texttt{main} and \texttt{xlab} in the function mean:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# histograms}
\FunctionTok{hist}\NormalTok{(pc\_data}\SpecialCharTok{$}\NormalTok{valid\_votes, }
     \AttributeTok{main =} \StringTok{"Valid votes in constituency"}\NormalTok{, }\CommentTok{\#change chart title}
     \AttributeTok{xlab =} \StringTok{"Votes"}\NormalTok{)     }\CommentTok{\#change x axis label              }
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/02.ExploratoryDataAnalysis_files/figure-pdf/unnamed-chunk-9-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{hist}\NormalTok{(pc\_data}\SpecialCharTok{$}\NormalTok{pct\_White\_British, }
     \AttributeTok{main =} \StringTok{"Histogram of \% White British in constituency"}\NormalTok{, }
     \AttributeTok{xlab =} \StringTok{"Percentage"}\NormalTok{, }
     \AttributeTok{col =} \StringTok{"dodgerblue"}\NormalTok{)   }\CommentTok{\#change bar color to dodgerblue}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/02.ExploratoryDataAnalysis_files/figure-pdf/unnamed-chunk-10-1.pdf}}

You may noticed that \texttt{valid\_votes} has a relatively normal,
bell-shaped distribution whereas the \texttt{pct\_White\_British}
variable is left skewed (negatively) distribution.

We can examine the how these distributions relate to central tendencies
(mean, median) and spread, using standard deviations for means and the
IQR (Inter-Quartile Range) for medians.

From the numeric summary above, the mean
of~\texttt{pc\_data\$valid\_votes} is 44,322. We can determine the
spread around this value by calculating the standard deviation for our
sample , as is returned by the~\texttt{sd}~function in R:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sd}\NormalTok{(pc\_data}\SpecialCharTok{$}\NormalTok{valid\_votes)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 5697.665
\end{verbatim}

For a normal distribution, about 68\% of observations lie within 1
standard deviation of the mean, and about 95\% lie within 2 standard
deviations of the mean. So this suggest that 68\% of the valid votes are
within 5,698 votes of the mean of 44,322 votes, i.e.~38,624 (44322-5698)
and 50020 (44322+5698).

We can augment the histogram of the \texttt{valid\_votes} variable with
this information, requesting R to increase the intervals to 50, and
using the \texttt{abline} function to add lines to create the figure
below:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# histogram}
\FunctionTok{hist}\NormalTok{(pc\_data}\SpecialCharTok{$}\NormalTok{valid\_votes, }\AttributeTok{col=}\StringTok{"forestgreen"}\NormalTok{, }\AttributeTok{main=}\StringTok{"Valid votes (with mean and std dev)"}\NormalTok{, }
     \AttributeTok{breaks =} \DecValTok{50}\NormalTok{, }\AttributeTok{xlab=}\StringTok{"Votes"}\NormalTok{)}
\CommentTok{\# calculate and add the mean}
\NormalTok{mean\_val }\OtherTok{=} \FunctionTok{mean}\NormalTok{(pc\_data}\SpecialCharTok{$}\NormalTok{valid\_votes)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{v =}\NormalTok{ mean\_val, }\AttributeTok{col =} \StringTok{"orange"}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{3}\NormalTok{)}
\CommentTok{\# calculate and add the standard deviation lines around the mean}
\NormalTok{sdev }\OtherTok{=} \FunctionTok{sd}\NormalTok{(pc\_data}\SpecialCharTok{$}\NormalTok{valid\_votes)}
\CommentTok{\# minus 1 sd}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{v =}\NormalTok{ mean\_val}\SpecialCharTok{{-}}\NormalTok{sdev, }\AttributeTok{col =} \StringTok{"red"}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{3}\NormalTok{, }\AttributeTok{lty =} \DecValTok{2}\NormalTok{)}
\CommentTok{\# plus 1 sd}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{v =}\NormalTok{ mean\_val}\SpecialCharTok{+}\NormalTok{sdev, }\AttributeTok{col =} \StringTok{"red"}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{3}\NormalTok{, }\AttributeTok{lty =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/02.ExploratoryDataAnalysis_files/figure-pdf/unnamed-chunk-12-1.pdf}}

This histogram show the variable \texttt{valid\_votes} with the orange
solid line as the mean, and dashed red line as the standard deviation.
Note that in the call to \texttt{abline} above, note the specification
of different line types (lty) and line widths (\texttt{lwd}). Later on,
you could explore these as described here.

We can also use density curve to present the variable distribution:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(}\FunctionTok{density}\NormalTok{(pc\_data}\SpecialCharTok{$}\NormalTok{valid\_votes), }
     \AttributeTok{main =} \StringTok{"Valid votes"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/02.ExploratoryDataAnalysis_files/figure-pdf/unnamed-chunk-13-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(}\FunctionTok{density}\NormalTok{(pc\_data}\SpecialCharTok{$}\NormalTok{pct\_White\_British), }
     \AttributeTok{main =} \StringTok{"\% of White British in Constituency"}\NormalTok{, }
     \AttributeTok{col=}\StringTok{"salmon"}\NormalTok{, }
     \AttributeTok{lwd=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/02.ExploratoryDataAnalysis_files/figure-pdf/unnamed-chunk-14-1.pdf}}

Boxplots show the same information but here we can see a bit more of the
nature of the distribution.

Recap Week 2 lecture, the dark line shows the median, the box represents
the interquartile range (from the 1st to the 3rd quartile), the whiskers
extend to the most extreme non-outlying values, and the dots indicate
outliers.

\includegraphics[width=9.38542in,height=\textheight,keepaspectratio]{labs/images/clipboard-2399852177.png}

Now let's check out the boxplots of these two variables:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{boxplot}\NormalTok{(pc\_data}\SpecialCharTok{$}\NormalTok{valid\_votes,}
        \AttributeTok{horizontal=}\ConstantTok{TRUE}\NormalTok{, }
        \AttributeTok{main =} \StringTok{"Valid votes"}\NormalTok{, }
        \AttributeTok{xlab=}\StringTok{\textquotesingle{}Votes\textquotesingle{}}\NormalTok{, }
        \AttributeTok{col =} \StringTok{"gold"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/02.ExploratoryDataAnalysis_files/figure-pdf/unnamed-chunk-15-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{boxplot}\NormalTok{(pc\_data}\SpecialCharTok{$}\NormalTok{pct\_White\_British,}
        \AttributeTok{horizontal=}\ConstantTok{TRUE}\NormalTok{, }
        \AttributeTok{main =} \StringTok{"\% of White British"}\NormalTok{, }
        \AttributeTok{xlab=}\StringTok{\textquotesingle{}Percentage\textquotesingle{}}\NormalTok{, }
        \AttributeTok{col =} \StringTok{"hotpink"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/02.ExploratoryDataAnalysis_files/figure-pdf/unnamed-chunk-16-1.pdf}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Is the median line in the centre of the box? If the median line is not
  in the middle of the box, it means the data are skewed, with greater
  spread on one side of the median.

  \begin{itemize}
  \item
    Median closer to the bottom of the box -\textgreater{} right-skewed
    (positively skewed) -\textgreater{} some big values pulling up
  \item
    Median closer to the top of the box -\textgreater{} left-skewed
    (negatively skewed) -\textgreater{} some small values dragging down
  \end{itemize}
\item
  Are the~whiskers~the~same length? This indicates skewness in the
  distribution. The data have a longer tail on the side of the longer
  whisker, meaning values are more spread out in that direction.
\item
  Are there any~outliers? Who has more? Outliers clustered on one side
  indicate that extreme observations occur predominantly in one tail of
  the distribution. More outliers indicates the variable hs more extreme
  or unusual values, possibly a heavier-tailed distribution. But this
  doesn't mean the variable is bad or more variable overall.
\item
  The size of the boxes? The box represents the interquartile range
  (IQR), which is the middle 50\% of the data as we call them typical. A
  larger box indicates greater variability in the middle 50\% of the
  variable; a smaller box suggests that values are more tightly
  clustered around the median.
\end{enumerate}

Now, you should be able to compare how the two kinds of distribution are
shown in the the boxplots with a trained eye: The
\texttt{pct\_White\_British} variable is left-skewed, indicating that
more values are spread towards lower percentages of White British in the
constituency. The box is also larger than that of \texttt{valid\_votes},
which suggests greater variability in the central 50\% of the data. In
addition, the longer lower whisker and the presence of more outliers on
the lower end further reinforce the left-skewed distribution.

In summary, numeric variable distributions, of counts and continuous
data, should be investigated as an initial step in any data analysis.
There are a number of metrics and graphical functions (tools) for doing
this
including~\texttt{summary()},~\texttt{hist()}~\texttt{plot(density())}
and~\texttt{boxplot()}.

\subsubsection{Categorical variables}\label{categorical-variables}

Some of the character variables could be considered
as~\textbf{categorical}, representing a grouping or classification of
some kind, as described above. In these cases we are interested in the
count or frequency of each class in the classification, which we can
examine numerically or graphically.

The simplest way to examine classes is to put them into a table of
counts. The~\texttt{table}~function is very useful and in the code below
it is applied to one of the categorical variables in the survey data:

So firstly we use the \texttt{table()} command to find the number of MPs
elected to each Party. {[}Hint: use the \emph{first\_party} variable{]}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{table}\NormalTok{(pc\_data}\SpecialCharTok{$}\NormalTok{first\_party)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

       Alliance    Conservative             DUP           Green     Independent 
              1             121               5               4               6 
         Labour        Lib Dems     Plaid Cymru          Reform            SDLP 
            411              72               4               5               2 
      Sinn Fein             SNP         Speaker Ulster Unionist  Unionist Voice 
              7               9               1               1               1 
\end{verbatim}

These can be made a bit more tabular in format with
the~\texttt{data.frame}~function, which takes
the~\texttt{table}~operation as its input:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data.frame}\NormalTok{(}\FunctionTok{table}\NormalTok{(pc\_data}\SpecialCharTok{$}\NormalTok{first\_party))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
              Var1 Freq
1         Alliance    1
2     Conservative  121
3              DUP    5
4            Green    4
5      Independent    6
6           Labour  411
7         Lib Dems   72
8      Plaid Cymru    4
9           Reform    5
10            SDLP    2
11       Sinn Fein    7
12             SNP    9
13         Speaker    1
14 Ulster Unionist    1
15  Unionist Voice    1
\end{verbatim}

However, if we not only care about the count of MPs but also the
proportion? Then we can make a good use of our tidyverse library to run
the following code line.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pc\_data }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{count}\NormalTok{(first\_party) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{pct =} \FunctionTok{round}\NormalTok{(n }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(n) }\SpecialCharTok{*} \DecValTok{100}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
       first_party   n  pct
1         Alliance   1  0.2
2     Conservative 121 18.6
3              DUP   5  0.8
4            Green   4  0.6
5      Independent   6  0.9
6           Labour 411 63.2
7         Lib Dems  72 11.1
8      Plaid Cymru   4  0.6
9           Reform   5  0.8
10            SDLP   2  0.3
11       Sinn Fein   7  1.1
12             SNP   9  1.4
13         Speaker   1  0.2
14 Ulster Unionist   1  0.2
15  Unionist Voice   1  0.2
\end{verbatim}

Here you are using two very useful functions in the library
\texttt{tidyverse}.

First, the \texttt{count()} calculate the frequency of different
categories in the \texttt{first\_party} and use a new column
\textbf{\texttt{n}} to store the frequencies - it actually do the same
thing as above code, but better in presenting as a table;

Second, the \texttt{mutate()} function to assist use create a new column
\texttt{pct}and fill in the value by the calculation
\texttt{pct\ =\ n\ /\ sum(n)\ *\ 100}.

The \texttt{\%\textgreater{}\%} is used to link these two commands:
\texttt{count()} and \texttt{mutate()}. You can insert
\texttt{\%\textgreater{}\%} in your R script by using
\texttt{ctrl\ +\ shift\ +\ M} for Windows and
\texttt{Cmd\ +\ Shift\ +\ M} on Mac.

Therefore, when you run the code, you will see a table showing as three
column: first part name, a new column automatically named as \texttt{n}
by R after the \texttt{count()} function, and count of the party MPs,
and a new column called \texttt{pct} and with values calculated by
\texttt{n\ /\ sum(n)\ *\ 100}. We use \texttt{round()} function to keep
only 1 digits for the \texttt{pct}.

We can also improve the code to make a better table presentation. You
may find the comment text after each code line would be useful to
understand what R has done to the \emph{pc\_data}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#Calculate the frequency and percentage of different categories for "first\_party"}
\NormalTok{pc\_data }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{count}\NormalTok{(first\_party) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{pct =} \FunctionTok{round}\NormalTok{(n }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(n) }\SpecialCharTok{*} \DecValTok{100}\NormalTok{,}\DecValTok{1}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{arrange}\NormalTok{(}\FunctionTok{desc}\NormalTok{(n)) }\SpecialCharTok{\%\textgreater{}\%}   \CommentTok{\#sort the table by number of MPs from more to less}
  \FunctionTok{setNames}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"First Party"}\NormalTok{, }\StringTok{"Number of MPs"}\NormalTok{, }\StringTok{"\% of MPs"}\NormalTok{))  }\CommentTok{\#rename table column names}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
       First Party Number of MPs % of MPs
1           Labour           411     63.2
2     Conservative           121     18.6
3         Lib Dems            72     11.1
4              SNP             9      1.4
5        Sinn Fein             7      1.1
6      Independent             6      0.9
7              DUP             5      0.8
8           Reform             5      0.8
9            Green             4      0.6
10     Plaid Cymru             4      0.6
11            SDLP             2      0.3
12        Alliance             1      0.2
13         Speaker             1      0.2
14 Ulster Unionist             1      0.2
15  Unionist Voice             1      0.2
\end{verbatim}

In this code chuck, we requested four command to the dataframe pc\_data,
and linked them with \texttt{\%\textgreater{}\%} :

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \texttt{count()} function to summarises the data by counting the
  number of observations in each group;
\item
  \texttt{mutate()} function to create a new column named ``pct'' as we
  did above;
\item
  \texttt{arrange()} function sorts the rows, \texttt{desc(n)} function
  decending the norder of \texttt{n}, together they order the category
  with the highest counts first;
\item
  \texttt{setNames()} function renames the results.
\end{enumerate}

Similarly, we can use the categorical variable \texttt{crime\_rate} in
the \texttt{pc\_data} dataset to understand the crime status of all the
constituencies:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#Calculate the frequency and percentage of different categories for "crime\_rate"}
\NormalTok{pc\_data }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{count}\NormalTok{(crime\_rate) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{pct =} \FunctionTok{round}\NormalTok{(n }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(n)}\SpecialCharTok{*}\DecValTok{100}\NormalTok{, }\DecValTok{1}\NormalTok{))  }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{arrange}\NormalTok{(}\FunctionTok{desc}\NormalTok{(n)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{setNames}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"Crime rate"}\NormalTok{, }\StringTok{"Number of Constituency"}\NormalTok{, }\StringTok{"\% of Constituency"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   Crime rate Number of Constituency % of Constituency
1 Much higher                    118              18.2
2      Higher                    115              17.7
3     Average                    114              17.5
4       Lower                    114              17.5
5  Much lower                    114              17.5
6        <NA>                     75              11.5
\end{verbatim}

What you have learnt from the result table? It seems that there is a
quite equally distribution across the five categories of crime rate,
although there are 11.5\% of the constituency are missing their crime
rates.

Categorical data can be visualised using bar plots of the tabularised
data. The code below does this by creating a table, changing the names
of the table and passing that to the~\texttt{barplot}~function:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#calculate the frequency of first party and save the result in table \textquotesingle{}tab\textquotesingle{}, present tab as a barplot}
\NormalTok{tab }\OtherTok{=} \FunctionTok{table}\NormalTok{(pc\_data}\SpecialCharTok{$}\NormalTok{first\_party)}
\FunctionTok{barplot}\NormalTok{(tab)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/02.ExploratoryDataAnalysis_files/figure-pdf/unnamed-chunk-22-1.pdf}}

It is very simple to get the barplot from the result of table(). But it
may need some improvement. As you may noticed, there are many bars have
rarely no values, and too crowd x axis labels makes some bar label can't
able to show. Therefore, we probably don't need to show all the parties,
but only the top 8 in terms of their winning constituencies.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#sorted tab by the frequency from highest to lowest, present the top 8 of the sorted tab }
\NormalTok{tab\_sorted }\OtherTok{\textless{}{-}} \FunctionTok{sort}\NormalTok{(tab,}\AttributeTok{decreasing =} \ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{barplot}\NormalTok{(}\FunctionTok{head}\NormalTok{(tab\_sorted,}\DecValTok{8}\NormalTok{),}\AttributeTok{las =} \DecValTok{2}\NormalTok{, }\AttributeTok{main =} \StringTok{"Top 8 of first party"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/02.ExploratoryDataAnalysis_files/figure-pdf/unnamed-chunk-23-1.pdf}}

In this code chunk, we first use sort() to reorder the tab ranking the
parties based on the counts from highest to lowest. You may ask R to
show how tab\_sorted looks like:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#show tab\_sorted}
\NormalTok{tab\_sorted}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

         Labour    Conservative        Lib Dems             SNP       Sinn Fein 
            411             121              72               9               7 
    Independent             DUP          Reform           Green     Plaid Cymru 
              6               5               5               4               4 
           SDLP        Alliance         Speaker Ulster Unionist  Unionist Voice 
              2               1               1               1               1 
\end{verbatim}

Then, using \texttt{barplot()}, we plot the top 8 rows of
\texttt{tab\_sorted}, with \texttt{las\ =\ 2} used to rotate the axis
labels so they are displayed vertically and remain readable.

\subsubsection{Categorical to categorical:
cross-tabulation}\label{categorical-to-categorical-cross-tabulation}

In EDA, it is also important to understand the relationship between
variables. Now it is the time to do the variable interactions. Let's
first start with interact one categorical variable to another
categorical variable. In many situations, it can be called
cross-tabulation.

The relationship between two sets of classes or categories can be
explored using correspondence tables created by
the~\texttt{table}~function. Here we can cross tabulate the two
categorical variables that we have already familiar with:
\texttt{first\_party} and \texttt{crime\_rate}:

If we want to examine how the distribution of crime-rate categories
varies for each first party. The question can be: for each political
party, how are its wins distributed across different crime-rate levels?

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# cross{-}tabulation first\_party vs.crime\_rate}

\FunctionTok{table}\NormalTok{(pc\_data}\SpecialCharTok{$}\NormalTok{first\_party, pc\_data}\SpecialCharTok{$}\NormalTok{crime\_rate)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
                 
                  Average Higher Lower Much higher Much lower
  Alliance              0      0     0           0          0
  Conservative         25      6    44           0         41
  DUP                   0      0     0           0          0
  Green                 1      0     0           1          2
  Independent           0      3     0           2          0
  Labour               79    101    47         115         32
  Lib Dems              6      2    20           0         38
  Plaid Cymru           0      0     3           0          1
  Reform                2      3     0           0          0
  SDLP                  0      0     0           0          0
  Sinn Fein             0      0     0           0          0
  SNP                   0      0     0           0          0
  Speaker               1      0     0           0          0
  Ulster Unionist       0      0     0           0          0
  Unionist Voice        0      0     0           0          0
\end{verbatim}

Conversely, we can also examine how the distribution of first parties
varies across different crime-rate categories.The question this time is:
for each crime-rate category, how are different parties distributed?

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# cross{-}tabulation crime\_rate vs first\_party}

\FunctionTok{table}\NormalTok{(pc\_data}\SpecialCharTok{$}\NormalTok{crime\_rate, pc\_data}\SpecialCharTok{$}\NormalTok{first\_party)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
             
              Alliance Conservative DUP Green Independent Labour Lib Dems
  Average            0           25   0     1           0     79        6
  Higher             0            6   0     0           3    101        2
  Lower              0           44   0     0           0     47       20
  Much higher        0            0   0     1           2    115        0
  Much lower         0           41   0     2           0     32       38
             
              Plaid Cymru Reform SDLP Sinn Fein SNP Speaker Ulster Unionist
  Average               0      2    0         0   0       1               0
  Higher                0      3    0         0   0       0               0
  Lower                 3      0    0         0   0       0               0
  Much higher           0      0    0         0   0       0               0
  Much lower            1      0    0         0   0       0               0
             
              Unionist Voice
  Average                  0
  Higher                   0
  Lower                    0
  Much higher              0
  Much lower               0
\end{verbatim}

What insights now you can learn from these cross-tabulation? We will
examine methods for determining whether the cross-tabulated counts and
their differences are significant (i.e.~would not be expected by chance)
in later weeks.

\subsubsection{Continuous to categorical: compare between
groups}\label{continuous-to-categorical-compare-between-groups}

We may also be interested in the exploring differences and similarities
in the continuous variables associated with for each categorical class.
This can be done using multiple boxplots.

If we want to make boxplots of each party by the value median house
price of the constituencies who vote for this party as their first
party:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#create boxplots by median\_house\_price for each first\_party}

\FunctionTok{par}\NormalTok{(}\AttributeTok{mar =} \FunctionTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{2}\NormalTok{))  }\CommentTok{\# increase the margin of the chart for each side: bottom, left, top, right}

\FunctionTok{boxplot}\NormalTok{(median\_house\_price }\SpecialCharTok{\textasciitilde{}}\NormalTok{ first\_party, }
        \AttributeTok{data =}\NormalTok{ pc\_data, }
        \AttributeTok{las =} \DecValTok{2}\NormalTok{, }\CommentTok{\#vertical present item label}
        \AttributeTok{xlab=}\StringTok{""}\NormalTok{, }\CommentTok{\#no x axis label}
        \AttributeTok{ylab=}\StringTok{""}\NormalTok{, }\CommentTok{\#no y axis label,}
        \AttributeTok{main=}\StringTok{"Compare constituency median house price vs. first party"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/02.ExploratoryDataAnalysis_files/figure-pdf/unnamed-chunk-27-1.pdf}}

If we want to explore the \% of White British in the constituencies and
compare the distribution between different MP genders. The code below
shows that, compared with constituencies represented by male MPs, those
with female MPs generally have a lower proportion of White British
population. This distribution also exhibits clear skewness towards lower
percentages of White British residents.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{boxplot}\NormalTok{(pct\_White\_British }\SpecialCharTok{\textasciitilde{}}\NormalTok{ mp\_gender, }
        \AttributeTok{data =}\NormalTok{ pc\_data,}\AttributeTok{col=}\FunctionTok{c}\NormalTok{(}\StringTok{"red"}\NormalTok{, }\StringTok{"yellow3"}\NormalTok{), }\CommentTok{\#specify bar colors}
        \AttributeTok{horizontal =} \ConstantTok{TRUE}\NormalTok{) }\CommentTok{\#horizonal the boxplot}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/02.ExploratoryDataAnalysis_files/figure-pdf/unnamed-chunk-28-1.pdf}}

We can do this numerically as well, but it is a bit more convoluted
using the~\texttt{with}~and~\texttt{aggregate}~functions:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{with}\NormalTok{(pc\_data, }\FunctionTok{aggregate}\NormalTok{(pct\_White\_British, }\AttributeTok{by=}\FunctionTok{list}\NormalTok{(mp\_gender) , }\AttributeTok{FUN=}\NormalTok{summary))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  Group.1    x.Min. x.1st Qu.  x.Median    x.Mean x.3rd Qu.    x.Max.
1  Female 15.587153 65.775762 84.276710 75.207471 92.374361 98.663686
2    Male  8.936846 74.343213 87.344901 79.907108 93.326348 98.652616
\end{verbatim}

\section{Make your own map for the election
result}\label{make-your-own-map-for-the-election-result}

Having established how many MPs and votes each party got, it is time to
look at the geography of the election outcome. To do this we need to
link a set of digital boundaries for Parliamentary Constituencies with
our pc\_data dataset.

\subsection{Read in Parliamentary Constituency
Boundaries}\label{read-in-parliamentary-constituency-boundaries}

Digital boundaries for the Parliamentary Constituencies used in the 2024
General Election can be found in the files
\textbf{\emph{uk\_constituencies\_2024.gpkg}} from the Cavans module
page. Download and save it in the Week 2 folder as well.

As Week 1, we use \texttt{st\_read()} function from \texttt{library(sf)}
to read in this geographical boundary dataset.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#read the boundaries as a spatial dataset}

\NormalTok{pc\_map }\OtherTok{\textless{}{-}} \FunctionTok{st\_read}\NormalTok{(}\StringTok{"uk\_constituencies\_2024.gpkg"}\NormalTok{)  }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Reading layer `uk_constituencies_2024' from data source 
  `C:\Users\jsmith\OneDrive - George Mason University - O365 Production\Documents\quant\labs\uk_constituencies_2024.gpkg' 
  using driver `GPKG'
Simple feature collection with 650 features and 9 fields
Geometry type: MULTIPOLYGON
Dimension:     XY
Bounding box:  xmin: 191.9359 ymin: 7423.9 xmax: 655599.6 ymax: 1218591
Projected CRS: OSGB36 / British National Grid
\end{verbatim}

\subsection{Inspect the spatial
dataset}\label{inspect-the-spatial-dataset}

Use the \texttt{names()} or \texttt{str()} to know the contents, or as
above use \texttt{View()} to open and check. Check by yourself the
number of rows and columns of the map data:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{str}\NormalTok{(pc\_map)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{View}\NormalTok{(pc\_map)}
\end{Highlighting}
\end{Shaded}

The \emph{pc\_map} dataset contains the standard set of Parliamentary
Constituency boundaries:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#make a map of constituency }
\FunctionTok{tm\_shape}\NormalTok{(pc\_map) }\SpecialCharTok{+} \CommentTok{\#map a spatial data}
  \FunctionTok{tm\_polygons}\NormalTok{() }\CommentTok{\#map it as polygons}
\end{Highlighting}
\end{Shaded}

or we can make a colorful map by using different color for different
regions:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#make a map of constituency and color each polygon based on "region\_name", using different color from palette "Set3" for each "region\_name"}

\FunctionTok{tm\_shape}\NormalTok{(pc\_map) }\SpecialCharTok{+} \CommentTok{\#map a spatial data}
  \FunctionTok{tm\_polygons}\NormalTok{(}\StringTok{"region\_name"}\NormalTok{,}
              \AttributeTok{palette=}\StringTok{"Set3"}\NormalTok{)  }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
\end{verbatim}

\begin{verbatim}
-- tmap v3 code detected -------------------------------------------------------
\end{verbatim}

\begin{verbatim}
[v3->v4] `tm_tm_polygons()`: migrate the argument(s) related to the scale of
the visual variable `fill` namely 'palette' (rename to 'values') to fill.scale
= tm_scale(<HERE>).
[cols4all] color palettes: use palettes from the R package cols4all. Run
`cols4all::c4a_gui()` to explore them. The old palette name "Set3" is named
"brewer.set3"
Multiple palettes called "set3" found: "brewer.set3", "hcl.set3". The first one, "brewer.set3", is returned.
\end{verbatim}

\pandocbounded{\includegraphics[keepaspectratio]{labs/02.ExploratoryDataAnalysis_files/figure-pdf/unnamed-chunk-34-1.pdf}}

\subsection{Link boundaries to
pc\_data}\label{link-boundaries-to-pc_data}

In order to map the election results contained in the \texttt{pc\_data}
dataset, we need to join it to a set of digital boundaries using the
\texttt{left\_join(\ )} command - you should have already familiar with
this from Week 1.

In your inspection of the \texttt{pc\_data} and \texttt{pc\_map}
datasets, you may have noticed that they all have two variables in
common. The first is a unique identifier for each Parliamentary
Constituency: \texttt{gss\_code}. The second is the name of the
constituency: \texttt{pc\_name}.

We can use these two variables to first link the \texttt{pc\_data}
dataset to the standard map:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#left join pc\_data to pc\_map, joining when gss\_code from pc\_map equals to pc\_name in pc\_data}

\NormalTok{pc\_map\_new }\OtherTok{\textless{}{-}} \FunctionTok{left\_join}\NormalTok{(pc\_map, pc\_data, }\AttributeTok{by =} \FunctionTok{c}\NormalTok{(}\StringTok{"gss\_code"}\NormalTok{, }\StringTok{"pc\_name"}\NormalTok{)) }
\end{Highlighting}
\end{Shaded}

As ever, having created a new dataset, use
the~\texttt{dim(\ )},~\texttt{str(\ )},~\texttt{names(\ )}~and~\texttt{View(\ )}~commands
to check its contents are as you would expect.

\subsection{Map the election result}\label{map-the-election-result}

Having joined the~\texttt{pc\_data}~dataset with a set of digital
boundaries, it becomes a simple matter to map the election results using
the mapping skills covered in Week 1:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#make a map for the pc\_map\_new, fill the colors for each polygon based on "first\_party", using colors from palette "Paired"}

\FunctionTok{tm\_shape}\NormalTok{(pc\_map\_new) }\SpecialCharTok{+} \CommentTok{\#map a spatial data}
  \FunctionTok{tm\_polygons}\NormalTok{(}\AttributeTok{fill =} \StringTok{"first\_party"}\NormalTok{, }
              \AttributeTok{fill.scale =} \FunctionTok{tm\_scale}\NormalTok{(}\AttributeTok{values=}\StringTok{"Paired"}\NormalTok{))  }\CommentTok{\#map it as polygons, use different colors by first\_party}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/02.ExploratoryDataAnalysis_files/figure-pdf/unnamed-chunk-36-1.pdf}}

This time, let's change the mode of tmap by using \texttt{tmap\_mode()}
from default ``plot'' to ``view'' for an interactive map:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# make the map interactive}
\FunctionTok{tmap\_mode}\NormalTok{(}\StringTok{"view"}\NormalTok{)}
\FunctionTok{tm\_shape}\NormalTok{(pc\_map\_new) }\SpecialCharTok{+} 
  \FunctionTok{tm\_polygons}\NormalTok{(}\StringTok{"first\_party"}\NormalTok{)  }
\end{Highlighting}
\end{Shaded}

This time, in your right-bottom pane, the map should be plotted in
Viewer tab as an interactive map. You can zoom in/out to explore your
map, for a better view, you can click the
\pandocbounded{\includegraphics[keepaspectratio]{labs/images/clipboard-3717496441.png}}
to open a webpage.

You may need to switch \texttt{tmap\_mode()} back to ``plot'' for a
static map making:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#switch back to plot static mode for later use}

\FunctionTok{tmap\_mode}\NormalTok{(}\StringTok{"plot"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
i tmap modes "plot" - "view"
i toggle with `tmap::ttm()`
\end{verbatim}

Now what pattern you can observe from the interactive map you just made?

\section{Formative tasks}\label{formative-tasks-1}

\textbf{Task 1} Write code to get how many columns and rows in the UK
constituency boundary dataset \texttt{pc\_map}?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pc\_map }\OtherTok{\textless{}{-}} \FunctionTok{st\_read}\NormalTok{(}\StringTok{"uk\_constituencies\_2024.gpkg"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Reading layer `uk_constituencies_2024' from data source 
  `C:\Users\jsmith\OneDrive - George Mason University - O365 Production\Documents\quant\labs\uk_constituencies_2024.gpkg' 
  using driver `GPKG'
Simple feature collection with 650 features and 9 fields
Geometry type: MULTIPOLYGON
Dimension:     XY
Bounding box:  xmin: 191.9359 ymin: 7423.9 xmax: 655599.6 ymax: 1218591
Projected CRS: OSGB36 / British National Grid
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ncol}\NormalTok{(pc\_map)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 10
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{nrow}\NormalTok{(pc\_map)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 650
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#both col and row}
\FunctionTok{dim}\NormalTok{(pc\_map)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 650  10
\end{verbatim}

\textbf{Task 2} Using the UK constituency boundary dataset
\texttt{pc\_map}, write code to get descriptive summary the area
(variable: \texttt{sq\_km}) of all the constituencies.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(pc\_map}\SpecialCharTok{$}\NormalTok{sq\_km)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
    6.80    33.65   106.45   375.01   351.98 11634.40 
\end{verbatim}

\textbf{Task 3} Write some codes to plot a histogram of
the~\texttt{pct\_invalid\_votes} variable in the constituency election
dataset, with lines showing the mean and the standard deviation around
the mean. Try add breaks into the function and change breaks from 10, 20
to 50 and see how the histogram changed.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pc\_data }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"uk\_constituencies\_2024.csv"}\NormalTok{,}\AttributeTok{stringsAsFactors =} \ConstantTok{TRUE}\NormalTok{)}

\CommentTok{\# histogram}
\FunctionTok{hist}\NormalTok{(pc\_data}\SpecialCharTok{$}\NormalTok{pct\_invalid\_votes, }\AttributeTok{col =} \StringTok{"thistle"}\NormalTok{, }\AttributeTok{main =} \StringTok{"Invalid votes in constituency"}\NormalTok{, }\AttributeTok{xlab =} \StringTok{"Percentage"}\NormalTok{, }\AttributeTok{breaks =} \DecValTok{50}\NormalTok{)}
\CommentTok{\# calculate and add the mean}
\NormalTok{mean\_val }\OtherTok{=} \FunctionTok{mean}\NormalTok{(pc\_data}\SpecialCharTok{$}\NormalTok{pct\_invalid\_votes, }\AttributeTok{na.rm =}\NormalTok{ T)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{v =}\NormalTok{ mean\_val, }\AttributeTok{col =} \StringTok{"purple"}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{3}\NormalTok{)}
\CommentTok{\# calculate and add the standard deviation lines around the mean}
\NormalTok{sdev }\OtherTok{=} \FunctionTok{sd}\NormalTok{(pc\_data}\SpecialCharTok{$}\NormalTok{pct\_invalid\_votes, }\AttributeTok{na.rm =}\NormalTok{ T)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{v =}\NormalTok{ mean\_val}\SpecialCharTok{{-}}\NormalTok{sdev, }\AttributeTok{col =} \StringTok{"tan"}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{3}\NormalTok{, }\AttributeTok{lty =} \DecValTok{2}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{v =}\NormalTok{ mean\_val}\SpecialCharTok{+}\NormalTok{sdev, }\AttributeTok{col =} \StringTok{"tan"}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{3}\NormalTok{, }\AttributeTok{lty =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/02.ExploratoryDataAnalysis_files/figure-pdf/unnamed-chunk-41-1.pdf}}

\textbf{Task 4} Write codes to create boxplots for
\texttt{pct\_in\_migration}, \texttt{pct\_UK\_born} and
\texttt{pct\_owned} (owning upright household):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{boxplot}\NormalTok{(pc\_data}\SpecialCharTok{$}\NormalTok{pct\_in\_migration,}\AttributeTok{horizontal=}\ConstantTok{TRUE}\NormalTok{, }\AttributeTok{main =} \StringTok{"In migration"}\NormalTok{, }\AttributeTok{xlab=}\StringTok{\textquotesingle{}Percentage\textquotesingle{}}\NormalTok{, }\AttributeTok{col =} \StringTok{"gold"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/02.ExploratoryDataAnalysis_files/figure-pdf/unnamed-chunk-42-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{boxplot}\NormalTok{(pc\_data}\SpecialCharTok{$}\NormalTok{pct\_UK\_born ,}\AttributeTok{horizontal=}\ConstantTok{TRUE}\NormalTok{, }\AttributeTok{main =} \StringTok{"UK born"}\NormalTok{, }\AttributeTok{xlab=}\StringTok{\textquotesingle{}Percentage\textquotesingle{}}\NormalTok{, }\AttributeTok{col =} \StringTok{"pink"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/02.ExploratoryDataAnalysis_files/figure-pdf/unnamed-chunk-42-2.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{boxplot}\NormalTok{(pc\_data}\SpecialCharTok{$}\NormalTok{pct\_owned,}\AttributeTok{horizontal=}\ConstantTok{TRUE}\NormalTok{, }\AttributeTok{main =} \StringTok{"Owning house upright"}\NormalTok{, }\AttributeTok{xlab=}\StringTok{\textquotesingle{}Percentage\textquotesingle{}}\NormalTok{, }\AttributeTok{col =} \StringTok{"lightblue"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/02.ExploratoryDataAnalysis_files/figure-pdf/unnamed-chunk-42-3.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#to compare them together}
\FunctionTok{boxplot}\NormalTok{(pc\_data[,}\FunctionTok{c}\NormalTok{(}\StringTok{"pct\_in\_migration"}\NormalTok{,}
                   \StringTok{"pct\_UK\_born"}\NormalTok{,}
                   \StringTok{"pct\_owned"}
\NormalTok{                   )],}
        \AttributeTok{horizontal=}\ConstantTok{TRUE}\NormalTok{, }
        \AttributeTok{main =} \StringTok{"Owning house upright"}\NormalTok{, }
        \AttributeTok{xlab=}\StringTok{\textquotesingle{}Percentage\textquotesingle{}}\NormalTok{, }
        \AttributeTok{col =} \FunctionTok{c}\NormalTok{(}\StringTok{"gold"}\NormalTok{,}\StringTok{"pink"}\NormalTok{,}\StringTok{"lightblue"}\NormalTok{)}
\NormalTok{        )}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/02.ExploratoryDataAnalysis_files/figure-pdf/unnamed-chunk-42-4.pdf}}

\textbf{Task 5} Write codes to summary the counts of MPs in each gender
(this is in the \texttt{mp\_gender}variable), presenting the table with
percentage and showing the barplot.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pc\_data }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{count}\NormalTok{(mp\_gender) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{pct =} \FunctionTok{round}\NormalTok{(n}\SpecialCharTok{/}\FunctionTok{sum}\NormalTok{(n)}\SpecialCharTok{*}\DecValTok{100}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  mp_gender   n  pct
1    Female 263 40.5
2      Male 387 59.5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tab }\OtherTok{=} \FunctionTok{table}\NormalTok{(pc\_data}\SpecialCharTok{$}\NormalTok{mp\_gender)}

\FunctionTok{barplot}\NormalTok{(tab,}\AttributeTok{main =} \StringTok{"MP gender in constituency"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/02.ExploratoryDataAnalysis_files/figure-pdf/unnamed-chunk-43-1.pdf}}

\textbf{Task 6} Cross tabulation \texttt{region\_name} to
\texttt{mp\_gender} by using the newly created \texttt{pc\_map\_new}
dataset, which joined by the constituency boundary and election dataset.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{table}\NormalTok{(pc\_map\_new}\SpecialCharTok{$}\NormalTok{region\_name, pc\_map\_new}\SpecialCharTok{$}\NormalTok{mp\_gender)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
                          
                           Female Male
  East Midlands                20   27
  East of England              16   45
  Greater London               38   37
  North East                   12   15
  North West                   31   42
  Northern Ireland              5   13
  Scotland                     20   37
  South East                   39   52
  South West                   19   39
  Wales                        15   17
  West Midlands                25   32
  Yorkshire and the Humber     23   31
\end{verbatim}

\textbf{Task 7} Compare between \texttt{crime\_rate} with the
\texttt{pct\_social\_rented} in constituency election dataset. What
pattern you can learn from your boxplot?

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{boxplot}\NormalTok{(pct\_social\_rented }\SpecialCharTok{\textasciitilde{}}\NormalTok{ crime\_rate , }\AttributeTok{data =}\NormalTok{ pc\_data)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/02.ExploratoryDataAnalysis_files/figure-pdf/unnamed-chunk-45-1.pdf}}

\bookmarksetup{startatroot}

\chapter{Lab: Introductory Statistics - Happiness around the
world}\label{lab-introductory-statistics---happiness-around-the-world}

\section{\texorpdfstring{\textbf{Overview}}{Overview}}\label{overview-3}

We have used Census data for the past two weeks. Census data aim to
collect detailed information about every person and household in the UK,
particularly on personal characteristics, household and housing, work
and education, health, migration, and so on. The aim of such collection
is to support plan public services and infrastructures.

Different from census (which counts the entire population), in many
cases, we need to use surveys to obtain timely, cost-effective and
probably more specific in-depth information from people. Therefore, this
week's practical session will draw upon two survey datasets:

\begin{itemize}
\item
  UK Family Resource Survey
\item
  World Value Survey
\end{itemize}

We will use these survey datasets to investigate the sample more
thoroughly and employ statistical approaches to determine its
representativeness of the population. We will use both numerical and
categorical variables to calculate the sample mean, Standard Error and
Confidence Intervals in different sample size.

You may wish to recap this week's lecture:
\href{https://canvas.liverpool.ac.uk/courses/85565/files/13687683?module_item_id=2553340}{Lecture
03}

\section{Prepare your working
environment}\label{prepare-your-working-environment}

\begin{itemize}
\item
  For this Week 3 session, create a sub-folder called~Week3~in
  your~ENVS162 folder on your M-Drive. This is exactly the step we did
  in Week 1 and 2 and we will do this every week to Week 5.
\item
  Download this week's practical datasets from Canvas Week 3:
  \textbf{\emph{family\_resource\_survey.csv, world\_value\_suvey.csv}}
  \textbf{and \emph{world\_map.geojson.}} Save all these three datasets
  in the Week 3 folder you just created.
\item
  Open RStudio
\item
  Open a new R Script for your Week 3 work, rename it as Week3.R and
  save it in your newly created Week 3 folder, under M drive
  -\textgreater{} ENVS162 folder.
\item
  Check whether there is any previous left dataframes in your RStudio in
  the upper-right side Environment pane. You can always use the to clear
  all the dataframes in your environment and make it all clean. For the
  same aim, you can click the icon
  \includegraphics[width=0.32292in,height=0.22917in]{labs/images/clipboard-2907453316.png},
  or you can run the below code:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rm}\NormalTok{(}\AttributeTok{list =} \FunctionTok{ls}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

This command and also the brush icon can both clear RStudio's memory,
removing any data objects that you have previously created.

\section{Load libraries and familiar with survey
data}\label{load-libraries-and-familiar-with-survey-data}

Exactly as what we have done for Week 1 and 2, before we start to do
anything in R, we first need to load the essential libraries as all the
functions/commands are packed in these libraries. For this week, we will
still rely on \texttt{tidyverse},~\texttt{tmap} and~\texttt{sf}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(sf)}
\FunctionTok{library}\NormalTok{(tmap)}
\end{Highlighting}
\end{Shaded}

Recall that the data can be loaded into RStudio using the
\texttt{read.csv} function:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# use read.csv to load a CSV file}
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"family\_resource\_survey.csv"}\NormalTok{,}\AttributeTok{stringsAsFactors =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The~\texttt{stringsAsFactors\ =\ TRUE}~parameter tells R to read any
character or text variables as classes or categories and not as just
text.

Recall what we should do to familiar ourselves with the dataset? We need
to now how many rows and columns of the dataset, what are the variables,
what types of these variables, and we may what to view the dataset for a
quick scan?

Therefore, we need these functions: \texttt{dim()} or \texttt{ncol()}
and \texttt{nrow()}, \texttt{names()}, \texttt{str()}, and
\texttt{View()}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# know how many rows and columns}
\FunctionTok{dim}\NormalTok{(df)}

\CommentTok{\# know the names of the variables}
\FunctionTok{names}\NormalTok{(df)}

\CommentTok{\# know types and examples of these variables}
\FunctionTok{str}\NormalTok{(df)}

\CommentTok{\# open a view window to scan the dataset}
\FunctionTok{View}\NormalTok{(df)}
\end{Highlighting}
\end{Shaded}

Question 1. How many people have been included in this survey?

In Week 2, we also know a simple way to help us get a quick look at the
descriptive summary of all the variables:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# summary all variables}
\FunctionTok{summary}\NormalTok{(df)}
\end{Highlighting}
\end{Shaded}

Okay, if for now you get yourself familiar with the dataset you are
going to work on, let's move on.

\section{Sampling of numerical
variables}\label{sampling-of-numerical-variables}

As discussed in the lecture, the \textbf{Standard Error (SE)} of the
sample mean indicates how much the estimated mean is expected to vary
from sample to sample. Together, the sample mean and SE help us assess
how accurately our sample reflects the true population mean. A smaller
SE indicates our sample estimate is likely closer to the actual
population value.

From the steps of familiaring with the dataset, you should already know
that there are 33,847 people included in this dataset. Recall our
lecture, these 33,847 people should be selected by some sampling methods
- random or stratified or multistaged - but in any case, they are a
sample of the entire world population.

\ul{Here, in this practical, let's assume that our survey data is about
a certain population. With such assumption, our population is the people
what completed the survey. Thus in this section, we are pretending that
the survey respondent are the population.}

We can test the mean and standard deviation of the
\texttt{hh\_income\_net} of the population using the functions
\texttt{mean()} and \texttt{sd()}. In Week 2, we have learnt that the
mean tells you the center of your numerical variable, and the standard
deviation reveals how spread out the variable are around the mean.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# calculate the mean value of the variable}
\FunctionTok{mean}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{hh\_income\_net)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 34485.51
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# calculate the standard deviation of the variable}
\FunctionTok{sd}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{hh\_income\_net)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 29379.1
\end{verbatim}

You can examine the income\_net distribution by creating a histogram as
using the code below (you should be very competent of this from Week 2):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# plot a histogram for the variable income\_net in df}
\FunctionTok{hist}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{hh\_income\_net, }\AttributeTok{breaks  =} \DecValTok{100}\NormalTok{, }
    \AttributeTok{main =} \StringTok{"Histogram of a population"}\NormalTok{, }
    \AttributeTok{xlab =} \StringTok{"Height"}\NormalTok{, }
    \AttributeTok{col =} \StringTok{"wheat"}\NormalTok{,}
    \AttributeTok{border =} \StringTok{"grey"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/03.IntroductoryStatistics_files/figure-pdf/unnamed-chunk-8-1.pdf}}

\subsection{Sample mean and Standard
Error}\label{sample-mean-and-standard-error}

In the example below, we will work with the \texttt{hh\_income\_net}
variable and an initial sample of 10 people (observations).

You can assess a sample of 10 observations (survey respondents) taken
from the population at random using the~\texttt{sample}~function.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create a sample of the population}
\NormalTok{sample\_10  }\OtherTok{\textless{}{-}} \FunctionTok{slice\_sample}\NormalTok{(df, }\AttributeTok{n=}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# sample mean value}
\FunctionTok{mean}\NormalTok{(sample\_10}\SpecialCharTok{$}\NormalTok{hh\_income\_net)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 34897.2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# sample standard deviation}
\FunctionTok{sd}\NormalTok{(sample\_10}\SpecialCharTok{$}\NormalTok{hh\_income\_net)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 22595.61
\end{verbatim}

You will get a different values for these to the ones your friends get
(and the ones created below), because you will have each extracted a
different~\textbf{sample}~from the population - this
is~\textbf{random}~sampling!

You should calculate the \textbf{Standard Error (SE)} of the sample mean
by:

\includegraphics[width=1.83333in,height=\textheight,keepaspectratio]{labs/images/clipboard-2205081754.png}

In R we run the code below:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# sample SE}
\FunctionTok{sd}\NormalTok{(sample\_10}\SpecialCharTok{$}\NormalTok{hh\_income\_net)}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(}\FunctionTok{length}\NormalTok{(sample\_10}\SpecialCharTok{$}\NormalTok{hh\_income\_net))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 7145.36
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# or}
\FunctionTok{sd}\NormalTok{(sample\_10}\SpecialCharTok{$}\NormalTok{hh\_income\_net)}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(sample\_10))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 7145.36
\end{verbatim}

Question 2. Compare population mean, sample mean and SE mean from your
results?

Now,to see how using a larger sample improves the estimate, you will now
repeat the previous example, generating a sample, determining the sample
means and SEs, but using different sample sizes: 10, 50, 100, 200.

Complete the below table for the comparison:

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Random sample size & Sample mean & Stardard Error (SE) mean \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
10 & & \\
50 & & \\
100 & & \\
200 & & \\
\end{longtable}

The above should have given you the general idea that as sample size
increases, the sample estimate of a population mean becomes more
reliable. To show this clearly, the code below generates a trend line
plot showing the impact of sample size on Standard Errors. As the sample
gets larger the SE gets smaller as the sample more closely represents
the true population.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# create a vector of sample sizes}
\NormalTok{X }\OtherTok{=} \FunctionTok{seq}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{200}\NormalTok{, }\DecValTok{10}\NormalTok{)}
\CommentTok{\# check the result}
\NormalTok{X}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1]  10  20  30  40  50  60  70  80  90 100 110 120 130 140 150 160 170 180 190
[20] 200
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# create a vector of sample errors from these}
\CommentTok{\# an empty vector to be populated in the for loop below}
\NormalTok{SE }\OtherTok{=} \FunctionTok{vector}\NormalTok{()}
\CommentTok{\# now loop though each value in X}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in}\NormalTok{ X)\{}
  \CommentTok{\# create a sample for the ith value in X}
  \CommentTok{\# set the seed {-} see the Info box below}
  \FunctionTok{set.seed}\NormalTok{(}\DecValTok{12}\NormalTok{)}
\NormalTok{  sample.i }\OtherTok{=} \FunctionTok{slice\_sample}\NormalTok{(df, }\AttributeTok{n=}\NormalTok{i)}
  \CommentTok{\# calculate the SE}
\NormalTok{  se.i }\OtherTok{=} \FunctionTok{sd}\NormalTok{(sample.i}\SpecialCharTok{$}\NormalTok{hh\_income\_net)}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(}\FunctionTok{length}\NormalTok{(sample.i}\SpecialCharTok{$}\NormalTok{hh\_income\_net))}
  \CommentTok{\# add to the SE vector}
\NormalTok{  SE }\OtherTok{=} \FunctionTok{append}\NormalTok{(SE, se.i)}
\NormalTok{\}}
\CommentTok{\# check the result}
\NormalTok{SE}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] 11545.970  6139.880  4638.476  3893.327  3353.118  3067.783  2687.440
 [8]  2391.198  2261.770  2103.450  2114.780  1979.338  1915.625  1882.336
[15]  1979.165  1878.847  1810.918  1725.824  1776.093  1705.949
\end{verbatim}

You can then these plot these:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# plot the SEs}
\FunctionTok{plot}\NormalTok{(}\AttributeTok{x =}\NormalTok{ X, }\AttributeTok{y =}\NormalTok{ SE,}
     \AttributeTok{pch =} \DecValTok{19}\NormalTok{, }\AttributeTok{col =} \StringTok{"darkgreen"}\NormalTok{,}
     \AttributeTok{xlab =} \StringTok{"Sample Size"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Standard Error"}\NormalTok{, }
     \AttributeTok{main =} \StringTok{"Impact of sample size on Standard Error"}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(}\AttributeTok{x =}\NormalTok{ X, }\AttributeTok{y =}\NormalTok{ SE)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/03.IntroductoryStatistics_files/figure-pdf/unnamed-chunk-14-1.pdf}}

So\ldots as sample size increases, the sample estimate of a population
mean becomes more reliable. However, you should note that this was based
on one-off sample generation and looking at the SE. In the next section
you will apply confidence intervals to the sample in order to assess the
robustness of the sample.

\subsection{Confidence Intervals}\label{confidence-intervals}

The idea of a~\textbf{confidence interval}, CI, is a natural extension
of the standard error. It allows us to define a level of confidence in
our population parameter estimate gleaned from a sample:

\includegraphics[width=3.17708in,height=\textheight,keepaspectratio]{labs/images/clipboard-3668784640.png}

We can use the~\texttt{qnorm}~function. \texttt{qnorm(p)} gives the
value on the normal distribution such that the cumulative probability up
to that value equals \texttt{p}. It is used at here to calculate the
errors around the sample mean under an assumption of a normal
distribution of the population (hence the~\emph{norm}~bit
of~\texttt{qnorm}):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# you have already created the sample with}
\CommentTok{\# sample\_10  \textless{}{-} slice\_sample(df, n=10)}
\NormalTok{m }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(sample\_10}\SpecialCharTok{$}\NormalTok{hh\_income\_net)}
\NormalTok{m}
\NormalTok{std }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(sample\_10}\SpecialCharTok{$}\NormalTok{hh\_income\_net)}
\NormalTok{n }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(sample\_10}\SpecialCharTok{$}\NormalTok{hh\_income\_net)}

\NormalTok{error }\OtherTok{\textless{}{-}} \FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.975}\NormalTok{)}\SpecialCharTok{*}\NormalTok{std}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(n)}

\NormalTok{lower.bound }\OtherTok{\textless{}{-}}\NormalTok{ m}\SpecialCharTok{{-}}\NormalTok{error}
\NormalTok{upper.bound }\OtherTok{\textless{}{-}}\NormalTok{ m}\SpecialCharTok{+}\NormalTok{error}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# upper and lower bound}
\NormalTok{upper.bound}
\NormalTok{lower.bound}
\end{Highlighting}
\end{Shaded}

This is the 95\% confidence interval, for the rest 2.5\% in the lower
tail and 2.5\% in the upper tail. This is why you may find in the code,
we use \texttt{qnorm(0.975)} as that refers to the cutoff points in two
directions). Again, you may find your values subtly different due to
random sample. But in my case,~\textbf{the mean household net income is
42,110 pound, and} \textbf{we are 95\% confident that the mean household
net income is between 22,842 pound and 61,376 pound}. This can be a
really fuzzy estimates, and it is because we only use 10 respondents
from the survey and by using such as small sample size, the CI window
would be very fuzzy.

Let's change the above code to a sample size of 1000:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# change sample size from 10 to 1000 this time}
\NormalTok{sample\_1k  }\OtherTok{\textless{}{-}} \FunctionTok{slice\_sample}\NormalTok{(df, }\AttributeTok{n=}\DecValTok{1000}\NormalTok{)}
\NormalTok{m }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(sample\_1k}\SpecialCharTok{$}\NormalTok{hh\_income\_net)}
\NormalTok{m}
\NormalTok{std }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(sample\_1k}\SpecialCharTok{$}\NormalTok{hh\_income\_net)}
\NormalTok{n }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(sample\_1k}\SpecialCharTok{$}\NormalTok{hh\_income\_net)}

\NormalTok{error }\OtherTok{\textless{}{-}} \FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.975}\NormalTok{)}\SpecialCharTok{*}\NormalTok{std}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(n)}

\NormalTok{lower.bound }\OtherTok{\textless{}{-}}\NormalTok{ m}\SpecialCharTok{{-}}\NormalTok{error}
\NormalTok{upper.bound }\OtherTok{\textless{}{-}}\NormalTok{ m}\SpecialCharTok{+}\NormalTok{error}

\NormalTok{lower.bound}
\NormalTok{upper.bound}
\end{Highlighting}
\end{Shaded}

Now you see that the sample mean has changed to 36,680, which indicates
that \textbf{the mean household net income is 36,680 pound, and}
\textbf{we are 95\% confident that the mean household net income is
between 33,934 pound and 39,427 pound}. Therefore, with this sample size
as 1000 sample, the CI window is much narrow and the result is more
solid.

You may try out if we use all the respondents as the sample, what is the
result? In this case, we don't need to \texttt{slice\_sample()}, and the
n should be \texttt{n\ =\ nrow(df)}.

\section{Sampling of categorical
variable}\label{sampling-of-categorical-variable}

Now, we switch our focus to the categorical variable \texttt{happiness}
in the dataframe. Similar to what we have done in last week, we first
wish to have a descriptive summary of the categories and frequency of
categories for categorical variables. We can use \texttt{table()} here:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# categories and frequencies}
\FunctionTok{table}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{happiness)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

  Fairly happy Fairly unhappy     Very happy   Very unhappy 
          8346           1552          15548           1079 
\end{verbatim}

You may also remember how to create a table to display the frequency and
proportion of each category:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# use df to create a table, including frequency and percentage of each category}
\NormalTok{df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{count}\NormalTok{(happiness) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{pct =} \FunctionTok{round}\NormalTok{(n }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(n) }\SpecialCharTok{*} \DecValTok{100}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
       happiness     n  pct
1   Fairly happy  8346 31.5
2 Fairly unhappy  1552  5.9
3     Very happy 15548 58.6
4   Very unhappy  1079  4.1
\end{verbatim}

The \texttt{pct} in the table, is the percentage of respondents in our
Family Resource Survey sample who reported each level of happiness. In
other words, they are the \textbf{sample proportion} for variable
happiness in this dataset.

Meanwhile, recall from Week 2 lecture, there are two types of
categorical variables: \textbf{nominal} and \textbf{ordinal}. The key
difference between them is whether the categories have a nature
ordering. In this case, the happiness variable is \textbf{ordinal},
because its categories follow a meaningful order: \emph{Very unhappy},
\emph{Fairly unhappy}, \emph{Fairly happy}, and \emph{Very happy}.

Therefore, as we wish to display the variable with an order, we use R
function \texttt{factor()} to do so:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#set the ordering of categories}
\NormalTok{df}\SpecialCharTok{$}\NormalTok{happiness }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(}
\NormalTok{  df}\SpecialCharTok{$}\NormalTok{happiness,}
  \AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\StringTok{"Very unhappy"}\NormalTok{, }
             \StringTok{"Fairly unhappy"}\NormalTok{, }
             \StringTok{"Fairly happy"}\NormalTok{, }
             \StringTok{"Very happy"}\NormalTok{),}
  \AttributeTok{ordered =} \ConstantTok{TRUE}
\NormalTok{) }
\end{Highlighting}
\end{Shaded}

If we now re-run the code to generate the frequency table and
proportions, you will notice that the categories appear in a more
logical order, reflecting the ordinal structure of the variable.

This time, we label the proportion column as \textbf{p (p-hat)} to
emphasise that these values represent the \textbf{sample proportions}
for each happiness category.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{count}\NormalTok{(happiness) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{p\_hat =} \FunctionTok{round}\NormalTok{(n }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(n) }\SpecialCharTok{*} \DecValTok{100}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
       happiness     n p_hat
1   Very unhappy  1079   4.1
2 Fairly unhappy  1552   5.9
3   Fairly happy  8346  31.5
4     Very happy 15548  58.6
\end{verbatim}

We use \texttt{barplot()} from last week to present the happiness
variable distribution in the Family Resource Survey:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#use bar plot to visualise the distribution of categorical variable}
\NormalTok{tab}\OtherTok{=}\FunctionTok{table}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{happiness)}
\FunctionTok{barplot}\NormalTok{(tab)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/03.IntroductoryStatistics_files/figure-pdf/unnamed-chunk-22-1.pdf}}

Question 3. What pattern you can identify from the barplot about
happiness in this sample?

\subsection{Sample proportion and Standard Error of the
proportion}\label{sample-proportion-and-standard-error-of-the-proportion}

In this section, we will focus on the \textbf{Very happy} category, we
can check the sample mean of Very happy from the eariler work and the
\texttt{p\_hat} is 58.6\%. This can also be calculated by
\texttt{mean()}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#calculate sample mean}
\NormalTok{p\_hat }\OtherTok{=} \FunctionTok{mean}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{happiness }\SpecialCharTok{==} \StringTok{"Very happy"}\NormalTok{)}
\NormalTok{p\_hat}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.586164
\end{verbatim}

Now let's calculate the \textbf{Standard Error}. Recap the equation of
Standard Error for a proportion:

\includegraphics[width=1.94792in,height=\textheight,keepaspectratio]{labs/images/clipboard-1215912918.png}

So, we need the sample size \textbf{n} first and then use \textbf{n} and
\textbf{p\_hat} to calculate the \textbf{SE\_p}. If we select all the
respondents in the dataset as the sample, then the n is equal to the
\texttt{nrow()}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#calculate Standard Error}
\NormalTok{n }\OtherTok{=} \FunctionTok{nrow}\NormalTok{(df)}
\NormalTok{n}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 26525
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SE\_p }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(p\_hat }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ p\_hat) }\SpecialCharTok{/}\NormalTok{ n)}
\NormalTok{SE\_p}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.003024099
\end{verbatim}

Therefore, now we get the interpretation that the ``Very happy'' sample
proportion typically varies by about 0.003 or 0.30 percentage.

We can also test \textbf{n} from 10, 100, 1000 to all to plot the
\textbf{SE\_p} and see how sample size increased will reduce the
Standard Error of proportion:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X }\OtherTok{=} \FunctionTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{100}\NormalTok{, }\DecValTok{1000}\NormalTok{, }\DecValTok{2000}\NormalTok{, }\DecValTok{5000}\NormalTok{, }\DecValTok{10000}\NormalTok{, n)}
\NormalTok{SE\_p }\OtherTok{=} \FunctionTok{vector}\NormalTok{()}
\CommentTok{\# now loop though each value in X}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in}\NormalTok{ X)\{}
  \CommentTok{\# create a sample for the ith value in X}
  \CommentTok{\# set the seed {-} see the Info box below}
  \FunctionTok{set.seed}\NormalTok{(}\DecValTok{20}\NormalTok{)}
\NormalTok{  sample.i }\OtherTok{=} \FunctionTok{slice\_sample}\NormalTok{(df, }\AttributeTok{n=}\NormalTok{i)}
  \CommentTok{\# calculate the sample mean of proportion}
\NormalTok{  p\_hat }\OtherTok{=} \FunctionTok{mean}\NormalTok{(sample.i}\SpecialCharTok{$}\NormalTok{happiness }\SpecialCharTok{==} \StringTok{"Very happy"}\NormalTok{)}
  \CommentTok{\# calculate the SE of proportion}
\NormalTok{  se.i }\OtherTok{=} \FunctionTok{sqrt}\NormalTok{(p\_hat }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ p\_hat) }\SpecialCharTok{/}\NormalTok{ i)}
  \CommentTok{\# add to the SE vector}
\NormalTok{  SE\_p }\OtherTok{=} \FunctionTok{append}\NormalTok{(SE\_p, se.i)}
\NormalTok{\}}
\CommentTok{\# check the result}
\NormalTok{SE\_p}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.158113883 0.049355851 0.015409607 0.010928626 0.006966181 0.004908920
[7] 0.003024099
\end{verbatim}

We can then these plot these:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# plot the SEs}
\FunctionTok{plot}\NormalTok{(}\AttributeTok{x =}\NormalTok{ X, }\AttributeTok{y =}\NormalTok{ SE\_p,}
     \AttributeTok{pch =} \DecValTok{19}\NormalTok{, }\AttributeTok{col =} \StringTok{"coral"}\NormalTok{,}
     \AttributeTok{xlab =} \StringTok{"Sample Size"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Standard Error of proportion"}\NormalTok{, }
     \AttributeTok{main =} \StringTok{"Impact of sample size on Standard Error of the proportion Very happy"}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(}\AttributeTok{x =}\NormalTok{ X, }\AttributeTok{y =}\NormalTok{ SE\_p)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/03.IntroductoryStatistics_files/figure-pdf/unnamed-chunk-26-1.pdf}}

Again, we know that with the increase of sample size n, the Standard
Error decreases.

\subsection{Confidence Intervals for a proportion
(95\%)}\label{confidence-intervals-for-a-proportion-95}

We now calculate a \textbf{95\% confidence interval} for the proportion
of respondents who reported being \emph{Very happy} in our sample.

To do this, we use the full sample size \textbf{n}. Recall that for a
proportion, CI for a proportion (95\%) is

\includegraphics[width=3.97917in,height=\textheight,keepaspectratio]{labs/images/clipboard-3761172973.png}

The critical value is again the \texttt{qnorm(0.975)} as we did for the
numerical variable, if you \texttt{qnorm(0.975)} then you may find it is
1.96. The below R code help use to calculate the CI windows of sample
mean, when sample size is n.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#CI windows}
\NormalTok{p\_hat }\OtherTok{=} \FunctionTok{mean}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{happiness }\SpecialCharTok{==} \StringTok{"Very happy"}\NormalTok{)}
\NormalTok{p\_hat}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.586164
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(df)}
\NormalTok{SE\_p }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(p\_hat }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ p\_hat) }\SpecialCharTok{/}\NormalTok{ n)}
\NormalTok{error\_p }\OtherTok{\textless{}{-}} \FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.975}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ SE\_p}
\NormalTok{lower.bound }\OtherTok{\textless{}{-}}\NormalTok{ p\_hat }\SpecialCharTok{{-}}\NormalTok{ error\_p}
\NormalTok{upper.bound }\OtherTok{\textless{}{-}}\NormalTok{ p\_hat }\SpecialCharTok{+}\NormalTok{ error\_p}
\NormalTok{lower.bound}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.5802369
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{upper.bound}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.5920911
\end{verbatim}

Therefore, the confidence interval can be interpreted as follows: in the
current UK \emph{Family Resources Survey}, the sample proportion of
respondents reporting being \emph{Very happy} is 58.6\%. The 95\%
confidence interval indicates that we are 95\% confident that the true
population proportion lies between 58.0\% and 59.2\%.

\section{Compare to World Value
Survey}\label{compare-to-world-value-survey}

We know that when the sample changes, the survey results may also
differ. Now we turn to a different dataset --- the \emph{World Values
Survey} --- and repeat the same analytical process to examine how the
happiness results compare.

\subsection{Happiness in different survey
sample}\label{happiness-in-different-survey-sample}

As usual, we first load the World Value Survey data:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# use read.csv to load a CSV file}
\NormalTok{dat }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"world\_value\_suvey.csv"}\NormalTok{,}\AttributeTok{stringsAsFactors =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Again, we wish to treat the happiness variable with its natural
ordering:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#set ordering}
\NormalTok{dat}\SpecialCharTok{$}\NormalTok{happiness }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(}
\NormalTok{  dat}\SpecialCharTok{$}\NormalTok{happiness,}
  \AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\StringTok{"Very unhappy"}\NormalTok{, }
             \StringTok{"Fairly unhappy"}\NormalTok{, }
             \StringTok{"Fairly happy"}\NormalTok{, }
             \StringTok{"Very happy"}\NormalTok{),}
  \AttributeTok{ordered =} \ConstantTok{TRUE}
\NormalTok{) }
\end{Highlighting}
\end{Shaded}

We also want to have a descriptive summary of the count in each category
and compute the percentage distribution:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# descriptive summary table}
\NormalTok{dat }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{count}\NormalTok{(happiness) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{p\_hat2 =} \FunctionTok{round}\NormalTok{(n }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(n) }\SpecialCharTok{*} \DecValTok{100}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
       happiness     n p_hat2
1   Very unhappy  2517    1.6
2 Fairly unhappy 18032   11.8
3   Fairly happy 87342   57.1
4     Very happy 45118   29.5
\end{verbatim}

Not just as the table above, a barplot would better support the
descriptive summary visually:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# barplot visualise}
\NormalTok{tab }\OtherTok{=} \FunctionTok{table}\NormalTok{(dat}\SpecialCharTok{$}\NormalTok{happiness)}
\NormalTok{tab}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

  Very unhappy Fairly unhappy   Fairly happy     Very happy 
          2517          18032          87342          45118 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{barplot}\NormalTok{(tab)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/03.IntroductoryStatistics_files/figure-pdf/unnamed-chunk-31-1.pdf}}

As what we have done earlier, we want to focus on the Very happy
category so we first calculate the sample proportion of respondents who
are Very happy.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#sample proportion of Very happy}
\NormalTok{p\_hat2 }\OtherTok{=} \FunctionTok{mean}\NormalTok{(dat}\SpecialCharTok{$}\NormalTok{happiness }\SpecialCharTok{==} \StringTok{"Very happy"}\NormalTok{)}
\NormalTok{p\_hat2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.2948715
\end{verbatim}

To estimate the Standard Error, we use the same coding, but this time,
the sample size is called k and all the respondents are included:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#Standard Error for the proportion of Very happy}
\NormalTok{k }\OtherTok{=} \FunctionTok{nrow}\NormalTok{(dat)}
\NormalTok{k}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 153009
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SE\_p2 }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(p\_hat2 }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ p\_hat2) }\SpecialCharTok{/}\NormalTok{ k)}
\NormalTok{SE\_p2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.001165714
\end{verbatim}

The estimated proportion of respondents who are \emph{Very happy}
typically varies by about 0.0012 (or 0.12 percentage points) from sample
to sample due to random sampling variation.

And the Confidence Intervals:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p\_hat2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.2948715
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SE\_p2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.001165714
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{error\_p2 }\OtherTok{\textless{}{-}} \FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.975}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ SE\_p2}
\NormalTok{lower.bound2 }\OtherTok{\textless{}{-}}\NormalTok{ p\_hat2 }\SpecialCharTok{{-}}\NormalTok{ error\_p2}
\NormalTok{upper.bound2 }\OtherTok{\textless{}{-}}\NormalTok{ p\_hat2 }\SpecialCharTok{+}\NormalTok{ error\_p2}
\NormalTok{lower.bound2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.2925868
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{upper.bound2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.2971563
\end{verbatim}

The sample proportion of respondents who are \emph{Very happy} is
estimated to be around 29.5\%. The 95\% confidence interval suggests
that we are 95\% confident that the true population proportion lies
between 29.3\% and 29.7\%.

Compare to our earlier results by using UK Family Resource Survey, the
findings are quite lower. You may have your inference that this is
because earlier respondents are all from the UK but now it is from all
over the world. Therefore, let's filter only UK respondents from this
World Value Survey:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# filter UK respondents from the whole survey sample}
\NormalTok{dat\_uk }\OtherTok{=}\NormalTok{ dat }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(english\_short\_name }\SpecialCharTok{==} \StringTok{"United Kingdom"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#calculate sample mean proportion for UK sample only}
\NormalTok{dat\_uk }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{count}\NormalTok{(happiness) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{p\_hat3 =} \FunctionTok{round}\NormalTok{(n }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(n) }\SpecialCharTok{*} \DecValTok{100}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
       happiness    n p_hat3
1   Very unhappy   34    0.7
2 Fairly unhappy  335    7.1
3   Fairly happy 2572   54.6
4     Very happy 1772   37.6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p\_hat3 }\OtherTok{=} \FunctionTok{mean}\NormalTok{(dat\_uk}\SpecialCharTok{$}\NormalTok{happiness }\SpecialCharTok{==} \StringTok{"Very happy"}\NormalTok{)}
\NormalTok{p\_hat3}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.3759813
\end{verbatim}

Question 4. Compute the SE and CI for the UK sample only dataframe
dat\_uk. How you will interpret the results?

\subsection{Between regions and
countries}\label{between-regions-and-countries}

You may have noticed that, even within the World Values Survey, the
sample proportion of respondents reporting being Very happy in the UK is
higher than the overall sample proportion.

We can now continue to explore how happiness varies across different
regions and countries to see whether similar patterns emerge elsewhere.

To fulfill this task, we shall use the cross-tabulation method we did
last week, by using \texttt{table()} between \texttt{region\_name} and
\texttt{happiness}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#cross{-}tabulate region vs happiness}
\FunctionTok{table}\NormalTok{(dat}\SpecialCharTok{$}\NormalTok{region\_name, dat}\SpecialCharTok{$}\NormalTok{happiness)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
          
           Very unhappy Fairly unhappy Fairly happy Very happy
  Africa            421           1627         4829       2645
  Americas          287           2868        11541       9053
  Asia              866           5468        26994      14992
  Europe            927           7894        42287      17539
  Oceania            16            175         1691        889
\end{verbatim}

You may think, okay, but it is very hard to draw conclusions based on
the counts. You are right. Let's change the count table into a
proportion one by using function \texttt{prop.table()}.

To know the function, we can first ask R's help:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{?prop.table}
\end{Highlighting}
\end{Shaded}

On your RStudio's right-hand Help pane, we can learn that we can set
parameter margin in to 1 to indicate the division should be done by row
(each row sums up to as 1), and margin = 2 as the division by columns
(each column sums up to 1).

Let's try both margin=1 and margin=2:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#get the cross{-}tabulation result and present in proportion format, margin = 1}
\NormalTok{tab\_region\_happy }\OtherTok{=} \FunctionTok{table}\NormalTok{(dat}\SpecialCharTok{$}\NormalTok{region\_name, dat}\SpecialCharTok{$}\NormalTok{happiness)}
\FunctionTok{prop.table}\NormalTok{(tab\_region\_happy, }\AttributeTok{margin =} \DecValTok{1}\NormalTok{) }\SpecialCharTok{*} \DecValTok{100}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
          
           Very unhappy Fairly unhappy Fairly happy Very happy
  Africa      4.4213401     17.0867465   50.7141357 27.7777778
  Americas    1.2084719     12.0762979   48.5957303 38.1194998
  Asia        1.7922185     11.3162252   55.8650662 31.0264901
  Europe      1.3503868     11.4994100   61.6006526 25.5495506
  Oceania     0.5774089      6.3154096   61.0249008 32.0822808
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{round}\NormalTok{(}\FunctionTok{prop.table}\NormalTok{(tab\_region\_happy, }\AttributeTok{margin =} \DecValTok{1}\NormalTok{) }\SpecialCharTok{*} \DecValTok{100}\NormalTok{, }\DecValTok{2}\NormalTok{)  }\CommentTok{\#round(...,2) to keep only 2 digits for all the numbers}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
          
           Very unhappy Fairly unhappy Fairly happy Very happy
  Africa           4.42          17.09        50.71      27.78
  Americas         1.21          12.08        48.60      38.12
  Asia             1.79          11.32        55.87      31.03
  Europe           1.35          11.50        61.60      25.55
  Oceania          0.58           6.32        61.02      32.08
\end{verbatim}

A vague calculation you may notice that each row (region) sums to 100
(as in the above codes, we multipled the proportion by 100 to express
them as percentage). This means the table presents \textbf{row
percentages}: within each region, the percentages show how respondents
are distributed across the different levels of happiness. In other
words, the table allows us to compare how the distribution of happiness
varies across regions within the sample.

If we simply change \texttt{margin\ =\ 1} to \texttt{margin\ =\ 2}, the
results will be different because we are now calculating column
percentages instead of row percentages.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{round}\NormalTok{(}\FunctionTok{prop.table}\NormalTok{(tab\_region\_happy, }\AttributeTok{margin =} \DecValTok{2}\NormalTok{) }\SpecialCharTok{*} \DecValTok{100}\NormalTok{, }\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
          
           Very unhappy Fairly unhappy Fairly happy Very happy
  Africa          16.73           9.02         5.53       5.86
  Americas        11.40          15.91        13.21      20.07
  Asia            34.41          30.32        30.91      33.23
  Europe          36.83          43.78        48.42      38.87
  Oceania          0.64           0.97         1.94       1.97
\end{verbatim}

With \texttt{margin\ =\ 2}, each column sums to 100. This means we are
looking at the distribution of regions within each happiness category.In
other words, instead of asking: ``Within each region, how is happiness
distributed?'' we are now asking: ``Among respondents at each happiness
level, how are they distributed across regions?'' - This changes the
interpretation entirely.

Now it's the time to check out the comparison among countries. Here we
use variable \texttt{english\_short\_name} as the country to
cross-tabulate \texttt{happiness}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tab\_country\_happy }\OtherTok{=} \FunctionTok{table}\NormalTok{(dat}\SpecialCharTok{$}\NormalTok{english\_short\_name, dat}\SpecialCharTok{$}\NormalTok{happiness)}
\FunctionTok{round}\NormalTok{(}\FunctionTok{prop.table}\NormalTok{(tab\_country\_happy, }\AttributeTok{margin =} \DecValTok{1}\NormalTok{) }\SpecialCharTok{*} \DecValTok{100}\NormalTok{, }\DecValTok{1}\NormalTok{) }\CommentTok{\#round(...,1) to keep only 2 digits for all the numbers}
\end{Highlighting}
\end{Shaded}

Question 5. What conclusion you can draw from the findings? Change
margin from 1 to 2, what new information you can learn from the results?

Again, in the following section, we want focus on the proportion of very
happy in each country only, we can use two functions
\texttt{group\_by()\ \%\textgreater{}\%\ summarise()} to fulfill this
request:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#group dat by the country name, in each group, calculate the mean proportion of happiness reported as Very happy}
\NormalTok{df\_ctry\_very\_happy }\OtherTok{\textless{}{-}}\NormalTok{ dat }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{group\_by}\NormalTok{(english\_short\_name) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{p\_hat =} \FunctionTok{mean}\NormalTok{(happiness }\SpecialCharTok{==} \StringTok{"Very happy"}\NormalTok{, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{)) }\CommentTok{\#if any rows include NA value, remove them}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df\_ctry\_very\_happy}
\end{Highlighting}
\end{Shaded}

This produces one row per country, with the sample proportion of
respondents who are \emph{Very happy}.

We can get the top 1 country by using function \texttt{which.max()}.
This function returns the row number corresponding to the maximum value
of \texttt{p\_hat}. We can then use that row number to extract the full
row from the dataframe: to get the row number of that country, and then
ask R to return that row for us:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{which.max}\NormalTok{(df\_ctry\_very\_happy}\SpecialCharTok{$}\NormalTok{p\_hat)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 44
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df\_ctry\_very\_happy[}\FunctionTok{which.max}\NormalTok{(df\_ctry\_very\_happy}\SpecialCharTok{$}\NormalTok{p\_hat),]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 1 x 2
  english_short_name p_hat
  <fct>              <dbl>
1 Kyrgyz Republic    0.677
\end{verbatim}

To identify the top 10 happiest countries (based on the proportion of
respondents who are \emph{Very happy}), we can use \texttt{arrange()}
function to sort the \texttt{df\_ctry\_very\_happy} dataframe by
\texttt{p\_hat}.

If we place a minus sign \texttt{-} before \texttt{p\_hat}
(i.e.~\texttt{arrange(-p\_hat)}), the dataframe will be sorted in
\textbf{decreasing} \textbf{order}, from highest to lowest proportion.
Without the minus sign, the sorting will be in \textbf{ascending order},
from lowest to highest.

You can also type \texttt{?arrange} in RStudio to view the official
documentation and see additional details about how the function works.

Now, top 10 Very happy:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df\_ctry\_very\_happy }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{arrange}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{p\_hat) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{head}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 10 x 2
   english_short_name p_hat
   <fct>              <dbl>
 1 Kyrgyz Republic    0.677
 2 Tajikistan         0.626
 3 Ecuador            0.618
 4 Mexico             0.588
 5 Colombia           0.574
 6 Uzbekistan         0.519
 7 Guatemala          0.511
 8 Philippines        0.511
 9 Puerto Rico        0.510
10 Kenya              0.509
\end{verbatim}

bottom 10 Very happy:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df\_ctry\_very\_happy }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{arrange}\NormalTok{(p\_hat) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{head}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 10 x 2
   english_short_name  p_hat
   <fct>               <dbl>
 1 South Korea        0.0410
 2 Egypt              0.0644
 3 Lithuania          0.0918
 4 Hong Kong          0.111 
 5 Morocco            0.126 
 6 Latvia             0.132 
 7 Slovakia           0.133 
 8 Macao              0.145 
 9 Russia             0.149 
10 Greece             0.154 
\end{verbatim}

\subsection{Map happiness around the
world}\label{map-happiness-around-the-world}

As usual, let's finish today's practical by a map made by ourselves.

First, load the world map boundaries from your working folder. Before
producing the final map, we can generate a quick check map using
\texttt{qtm()} to ensure the spatial data has loaded correctly. We also
set \texttt{tmap} to interactive mode using \texttt{tmap\_mode("view")},
so the map can be explored dynamically (e.g., zooming and clicking on
countries) before creating the final visualisation.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#load the boundary dataset}
\NormalTok{world\_map }\OtherTok{\textless{}{-}} \FunctionTok{st\_read}\NormalTok{(}\StringTok{"world\_map.geojson"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Reading layer `world_map' from data source 
  `C:\Users\jsmith\OneDrive - George Mason University - O365 Production\Documents\quant\labs\world_map.geojson' 
  using driver `GeoJSON'
Simple feature collection with 203 features and 14 fields
Geometry type: MULTIPOLYGON
Dimension:     XY
Bounding box:  xmin: -180 ymin: -58.49861 xmax: 180 ymax: 83.6236
Geodetic CRS:  WGS 84
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#set as interactive map}
\FunctionTok{tmap\_mode}\NormalTok{(}\StringTok{"view"}\NormalTok{)}
\CommentTok{\#quick mapping}
\FunctionTok{qtm}\NormalTok{(world\_map)}
\end{Highlighting}
\end{Shaded}

Click on any country in the world map within the Viewer pane on the
right-hand side of RStudio. You will notice that the variable
\texttt{english\_short} contains the country name.

We can use this variable as the key to join the spatial map data with
our country-level happiness dataframe, since it corresponds to the
\texttt{english\_short\_name} variable in our survey dataset.

Before join them, let's first inspect the structure of both dataframe:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dim}\NormalTok{(world\_map)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 203  15
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dim}\NormalTok{(df\_ctry\_very\_happy)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 91  2
\end{verbatim}

We can learn that the world map has 203 countries, but our
\texttt{df\_ctry\_very\_happy} only have 91, this means that not all the
countries from the \texttt{world\_map} will be able to plot based on the
\texttt{p\_hat} from \texttt{df\_ctry\_very\_happy}. As a result, some
countries will have missing values (NA) for the happiness proportion and
therefore will not be coloured according to p\_hat in the final map.

However, this is perfectly acceptable --- those countries will simply
appear with the default missing-value styling, while the countries
included in our survey data will be shaded according to their estimated
proportion of respondents who are Very happy.

Let's use function \texttt{left\_join()} to join the two dataframes:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#join our newly created dataframe df\_ctry\_very\_happy to the world map by the shared columns}
\NormalTok{world\_happiness }\OtherTok{=} \FunctionTok{left\_join}\NormalTok{(world\_map, df\_ctry\_very\_happy, }\AttributeTok{by=}\FunctionTok{c}\NormalTok{(}\StringTok{"english\_short"}\OtherTok{=}\StringTok{"english\_short\_name"}\NormalTok{) )}
\end{Highlighting}
\end{Shaded}

A short code sentence would serve your first try on the new dataframe
\texttt{world\_happiness}. Don't forget to click the
\pandocbounded{\includegraphics[keepaspectratio]{labs/images/clipboard-1368566708.png}}
from your RStudio right-bottom Viewer pane for a full screen interactive
map in your explorer:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#View the map as an interview map}
\FunctionTok{tm\_shape}\NormalTok{(world\_happiness) }\SpecialCharTok{+}
  \FunctionTok{tm\_polygons}\NormalTok{(}\StringTok{"p\_hat"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

To make it looking better, let's change the color palette and breaks.
Click the
\pandocbounded{\includegraphics[keepaspectratio]{labs/images/clipboard-1368566708.png}}
from your RStudio right-bottom Viewer pane for a full screen interactive
map - browse the map and interact with it to find how UK compare to
other countries on this map? Any other findings interest you?

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#plot the map as a static map, with color palette as Yellow{-}Orange\_Red, with break styles as jenks into 6 classes}

\NormalTok{map }\OtherTok{=} \FunctionTok{tm\_shape}\NormalTok{(world\_happiness) }\SpecialCharTok{+}
  \FunctionTok{tm\_polygons}\NormalTok{(}\StringTok{"p\_hat"}\NormalTok{,}
              \AttributeTok{fill.scale =} \FunctionTok{tm\_scale}\NormalTok{(}\AttributeTok{values=}\StringTok{"YlOrRd"}\NormalTok{,}
                                \AttributeTok{style =} \StringTok{"jenks"}\NormalTok{,}\AttributeTok{n=}\DecValTok{6}\NormalTok{))}\SpecialCharTok{+}
   \FunctionTok{tm\_layout}\NormalTok{(}\AttributeTok{main.title =} \StringTok{"Mean proportion of Very happy in the World Value Survey"}\NormalTok{,}
            \AttributeTok{main.title.size=}\FloatTok{1.2}\NormalTok{,}
            \AttributeTok{frame =} \ConstantTok{FALSE}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{tm\_compass}\NormalTok{(}\AttributeTok{position =} \FunctionTok{c}\NormalTok{(}\StringTok{"right"}\NormalTok{, }\StringTok{"bottom"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{tm\_scalebar}\NormalTok{(}\AttributeTok{position =} \FunctionTok{c}\NormalTok{(}\StringTok{"right"}\NormalTok{, }\StringTok{"bottom"}\NormalTok{)) }
\NormalTok{map}
\end{Highlighting}
\end{Shaded}

At last, we can use \texttt{tmap\_mode("plot")} to change the
interactive map into a static one. Also we can save the map on your
disk:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tmap\_mode}\NormalTok{(}\StringTok{"plot"}\NormalTok{)}
\NormalTok{map}
\FunctionTok{tmap\_save}\NormalTok{(map,}\StringTok{"Week3 map.png"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/03.IntroductoryStatistics_files/figure-pdf/unnamed-chunk-54-1.pdf}}

Check in your folder and you shall find the map made by yourself.

\section{Formative Tasks}\label{formative-tasks-2}

\textbf{Task 1} Use the \texttt{income\_gross} variable from the UK
Family Resource Survey, compare how increase sample size from 5000 to
20000 would affect the sample mean, standard error and CI of the
\texttt{income\_gross}. How to interpret the results?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n1 }\OtherTok{=} \DecValTok{5000}
\NormalTok{n2 }\OtherTok{=} \DecValTok{20000}

\CommentTok{\# sample by size}
\NormalTok{sample\_5k }\OtherTok{=} \FunctionTok{slice\_sample}\NormalTok{(df, }\AttributeTok{n=}\NormalTok{n1)}
\NormalTok{sample\_20k }\OtherTok{=} \FunctionTok{slice\_sample}\NormalTok{(df, }\AttributeTok{n=}\NormalTok{n2)}

\CommentTok{\#mean}
\NormalTok{m}\FloatTok{.5}\NormalTok{k }\OtherTok{=} \FunctionTok{mean}\NormalTok{(sample\_5k}\SpecialCharTok{$}\NormalTok{income\_gross)}
\NormalTok{m}\FloatTok{.20}\NormalTok{k }\OtherTok{=} \FunctionTok{mean}\NormalTok{(sample\_20k}\SpecialCharTok{$}\NormalTok{income\_gross)}

\NormalTok{m}\FloatTok{.5}\NormalTok{k}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 22224.9
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m}\FloatTok{.20}\NormalTok{k}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 22076.63
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#standard deviation}
\NormalTok{std}\FloatTok{.5}\NormalTok{k }\OtherTok{=} \FunctionTok{sd}\NormalTok{(sample\_5k}\SpecialCharTok{$}\NormalTok{income\_gross)}
\NormalTok{std}\FloatTok{.20}\NormalTok{k }\OtherTok{=} \FunctionTok{sd}\NormalTok{(sample\_20k}\SpecialCharTok{$}\NormalTok{income\_gross)}

\CommentTok{\#standard error}
\NormalTok{se}\FloatTok{.5}\NormalTok{k }\OtherTok{=}\NormalTok{ std}\FloatTok{.5}\NormalTok{k}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(n1)}
\NormalTok{se}\FloatTok{.20}\NormalTok{k }\OtherTok{=}\NormalTok{ std}\FloatTok{.20}\NormalTok{k}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(n2)}

\NormalTok{se}\FloatTok{.5}\NormalTok{k}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 434.672
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{se}\FloatTok{.20}\NormalTok{k}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 174.1159
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#CI}
\NormalTok{error}\FloatTok{.5}\NormalTok{k }\OtherTok{\textless{}{-}} \FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.975}\NormalTok{)}\SpecialCharTok{*}\NormalTok{se}\FloatTok{.5}\NormalTok{k}
\NormalTok{error}\FloatTok{.20}\NormalTok{k }\OtherTok{\textless{}{-}} \FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.975}\NormalTok{)}\SpecialCharTok{*}\NormalTok{se}\FloatTok{.20}\NormalTok{k}

\NormalTok{lower.bound}\FloatTok{.5}\NormalTok{k }\OtherTok{\textless{}{-}}\NormalTok{ m}\FloatTok{.5}\NormalTok{k}\SpecialCharTok{{-}}\NormalTok{error}\FloatTok{.5}\NormalTok{k}
\NormalTok{upper.bound}\FloatTok{.5}\NormalTok{k }\OtherTok{\textless{}{-}}\NormalTok{ m}\FloatTok{.5}\NormalTok{k}\SpecialCharTok{+}\NormalTok{error}\FloatTok{.5}\NormalTok{k}

\NormalTok{lower.bound}\FloatTok{.20}\NormalTok{k }\OtherTok{\textless{}{-}}\NormalTok{ m}\FloatTok{.20}\NormalTok{k}\SpecialCharTok{{-}}\NormalTok{error}\FloatTok{.20}\NormalTok{k}
\NormalTok{upper.bound}\FloatTok{.20}\NormalTok{k }\OtherTok{\textless{}{-}}\NormalTok{ m}\FloatTok{.20}\NormalTok{k}\SpecialCharTok{+}\NormalTok{error}\FloatTok{.20}\NormalTok{k}

\NormalTok{lower.bound}\FloatTok{.5}\NormalTok{k}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 21372.96
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{upper.bound}\FloatTok{.5}\NormalTok{k}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 23076.85
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lower.bound}\FloatTok{.20}\NormalTok{k}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 21735.37
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{upper.bound}\FloatTok{.20}\NormalTok{k}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 22417.89
\end{verbatim}

\textbf{Task 2} Use the \texttt{health} variable from the UK Family
Resource Survey, what is the sample mean proportion of \textbf{Very
Good} health in the whole sample? The standard error and CI? How to
interpret the results?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n }\OtherTok{=} \FunctionTok{nrow}\NormalTok{(df)}
\NormalTok{p\_hat }\OtherTok{=} \FunctionTok{mean}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{health }\SpecialCharTok{==} \StringTok{"Very Good"}\NormalTok{)}
\NormalTok{p\_hat}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.2820358
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SE\_p }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(p\_hat }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ p\_hat) }\SpecialCharTok{/}\NormalTok{ n)}
\NormalTok{error\_p }\OtherTok{\textless{}{-}} \FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.975}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ SE\_p}
\NormalTok{lower.bound }\OtherTok{\textless{}{-}}\NormalTok{ p\_hat }\SpecialCharTok{{-}}\NormalTok{ error\_p}
\NormalTok{upper.bound }\OtherTok{\textless{}{-}}\NormalTok{ p\_hat }\SpecialCharTok{+}\NormalTok{ error\_p}
\NormalTok{lower.bound}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.2766205
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{upper.bound}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.2874511
\end{verbatim}

\textbf{Task 3} Use the \texttt{health} variable from the World Value
Survey, compare your the sample mean proportion of \textbf{Very good}
health with your findings in Task 2.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n }\OtherTok{=} \FunctionTok{nrow}\NormalTok{(dat)}
\NormalTok{p\_hat }\OtherTok{=} \FunctionTok{mean}\NormalTok{(dat}\SpecialCharTok{$}\NormalTok{health }\SpecialCharTok{==} \StringTok{"Very good"}\NormalTok{)}
\NormalTok{p\_hat}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.2204315
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SE\_p }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(p\_hat }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ p\_hat) }\SpecialCharTok{/}\NormalTok{ n)}
\NormalTok{error\_p }\OtherTok{\textless{}{-}} \FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.975}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ SE\_p}
\NormalTok{lower.bound }\OtherTok{\textless{}{-}}\NormalTok{ p\_hat }\SpecialCharTok{{-}}\NormalTok{ error\_p}
\NormalTok{upper.bound }\OtherTok{\textless{}{-}}\NormalTok{ p\_hat }\SpecialCharTok{+}\NormalTok{ error\_p}
\NormalTok{lower.bound}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.2183544
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{upper.bound}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.2225086
\end{verbatim}

\textbf{Task 4} Use the \texttt{trust\_strangers} variable from the
World Value Survey, compare between different regions (variable use
\texttt{sub\_region\_name}). Which region more likely to trust strangers
completely?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tab }\OtherTok{=} \FunctionTok{table}\NormalTok{(dat}\SpecialCharTok{$}\NormalTok{sub\_region\_name, dat}\SpecialCharTok{$}\NormalTok{trust\_strangers)}
\FunctionTok{round}\NormalTok{(}\FunctionTok{prop.table}\NormalTok{(tab, }\AttributeTok{margin =} \DecValTok{1}\NormalTok{) }\SpecialCharTok{*} \DecValTok{100}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
                                 
                                  Do not trust at all Do not trust much
  Australia and New Zealand                       8.2              36.5
  Central Asia                                   41.5              41.5
  Eastern Asia                                   19.0              60.6
  Eastern Europe                                 24.0              48.6
  Latin America and the Caribbean                48.1              35.3
  Northern Africa                                31.2              43.1
  Northern America                               11.6              42.2
  Northern Europe                                 8.7              32.7
  South-eastern Asia                             29.3              49.2
  Southern Asia                                  38.3              32.4
  Southern Europe                                27.6              46.1
  Sub-Saharan Africa                             33.9              34.7
  Western Asia                                   33.8              45.4
  Western Europe                                 10.8              38.1
                                 
                                  Trust completely Trust somewhat
  Australia and New Zealand                    1.2           54.1
  Central Asia                                 2.4           14.6
  Eastern Asia                                 1.8           18.7
  Eastern Europe                               2.5           24.9
  Latin America and the Caribbean              1.9           14.7
  Northern Africa                              2.3           23.4
  Northern America                             2.0           44.2
  Northern Europe                              5.2           53.5
  South-eastern Asia                           3.0           18.5
  Southern Asia                                5.5           23.7
  Southern Europe                              2.1           24.2
  Sub-Saharan Africa                           4.8           26.6
  Western Asia                                 2.3           18.4
  Western Europe                               3.1           48.0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{result }\OtherTok{=} \FunctionTok{round}\NormalTok{(}\FunctionTok{prop.table}\NormalTok{(tab, }\AttributeTok{margin =} \DecValTok{1}\NormalTok{) }\SpecialCharTok{*} \DecValTok{100}\NormalTok{, }\DecValTok{1}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{as.data.frame.matrix}\NormalTok{()}
\NormalTok{result}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
                                Do not trust at all Do not trust much
Australia and New Zealand                       8.2              36.5
Central Asia                                   41.5              41.5
Eastern Asia                                   19.0              60.6
Eastern Europe                                 24.0              48.6
Latin America and the Caribbean                48.1              35.3
Northern Africa                                31.2              43.1
Northern America                               11.6              42.2
Northern Europe                                 8.7              32.7
South-eastern Asia                             29.3              49.2
Southern Asia                                  38.3              32.4
Southern Europe                                27.6              46.1
Sub-Saharan Africa                             33.9              34.7
Western Asia                                   33.8              45.4
Western Europe                                 10.8              38.1
                                Trust completely Trust somewhat
Australia and New Zealand                    1.2           54.1
Central Asia                                 2.4           14.6
Eastern Asia                                 1.8           18.7
Eastern Europe                               2.5           24.9
Latin America and the Caribbean              1.9           14.7
Northern Africa                              2.3           23.4
Northern America                             2.0           44.2
Northern Europe                              5.2           53.5
South-eastern Asia                           3.0           18.5
Southern Asia                                5.5           23.7
Southern Europe                              2.1           24.2
Sub-Saharan Africa                           4.8           26.6
Western Asia                                 2.3           18.4
Western Europe                               3.1           48.0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{which.max}\NormalTok{(result}\SpecialCharTok{$}\StringTok{\textasciigrave{}}\AttributeTok{Trust completely}\StringTok{\textasciigrave{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 10
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{result[}\FunctionTok{which.max}\NormalTok{(result}\SpecialCharTok{$}\StringTok{\textasciigrave{}}\AttributeTok{Trust completely}\StringTok{\textasciigrave{}}\NormalTok{),]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
              Do not trust at all Do not trust much Trust completely
Southern Asia                38.3              32.4              5.5
              Trust somewhat
Southern Asia           23.7
\end{verbatim}

\textbf{Task 5} Use the \texttt{immigrant\_impact} variable from the
World Value Survey, create a new dataframe to include the sample mean
proportion of in each country/place (variable needed:
\texttt{english\_short\_name}) who holds \textbf{Very bad} attitude of
immigrant impact. Identify the five countries/places with the lowest
mean proportion in the sample.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df\_immigrant }\OtherTok{\textless{}{-}}\NormalTok{ dat }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{group\_by}\NormalTok{(english\_short\_name) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{p\_hat =} \FunctionTok{mean}\NormalTok{(immigrant\_impact }\SpecialCharTok{==} \StringTok{"Very bad"}\NormalTok{, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{)) }\CommentTok{\# NA value removed}

\NormalTok{df\_immigrant}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 91 x 2
   english_short_name   p_hat
   <fct>                <dbl>
 1 Albania            0.0320 
 2 Andorra            0.00402
 3 Argentina          0.0567 
 4 Armenia            0.0397 
 5 Australia          0.145  
 6 Austria            0.103  
 7 Azerbaijan         0.0643 
 8 Bangladesh         0.0387 
 9 Belarus            0.0293 
10 Bolivia            0.0724 
# i 81 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df\_immigrant }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{arrange}\NormalTok{(p\_hat) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{head}\NormalTok{(}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 5 x 2
  english_short_name   p_hat
  <fct>                <dbl>
1 Andorra            0.00402
2 South Korea        0.00884
3 Macao              0.00888
4 China              0.0108 
5 Peru               0.0110 
\end{verbatim}

\bookmarksetup{startatroot}

\chapter{Lab: Correlation, data reliability and the issue of scale -
Health}\label{lab-correlation-data-reliability-and-the-issue-of-scale---health}

\section{\texorpdfstring{\textbf{Overview}}{Overview}}\label{overview-4}

``No society can legitimately call itself civilised if a sick person is
denied medical aid because of lack of means.''\\
(Aneurin Bevan, 1952, \emph{In Place of Fear}, London: Heinemann.)

Health and wealth are closely connected.

\begin{itemize}
\tightlist
\item
  ``The greatest wealth is health.'' (Proverb)
\item
  ``The richer you are, the better your health.'' (Michael Marmot, 2015,
  \emph{The Guardian}, 11/09/2015.)
\item
  Poor national health reduces workforce participation, productivity and
  growth, while increasing demand for health, care and welfare services
  (Geoffrey Filkin et al., 2024, \emph{Health is Wealth}, London: The
  King's Fund).
\end{itemize}

This practical explores the \textbf{geography of health} and its
relationship to socio-economic conditions. It builds on skills developed
in previous weeks and introduces additional analytical techniques.

In particular, you will:

\begin{itemize}
\tightlist
\item
  Link data from two different datasets
\item
  Visualise the relationships between different types of variables
\item
  Calculate appropriate measures of correlation for different types of
  variables
\item
  Consider Modifiable Areal Unit Problem (MAUP)
\end{itemize}

\section{Prepare your working
environment}\label{prepare-your-working-environment-1}

\begin{itemize}
\item
  For this Week 4 session, create a sub-folder called~Week4~in
  your~ENVS162 folder on your M-Drive. This is exactly the step we did
  in Weeks 1, 2, and 3.
\item
  Download this week's practical datasets from Canvas Week 4:

  \begin{itemize}
  \tightlist
  \item
    LAD December 2021 EW BUC.geojson
  \item
    Census\_2021\_Districts.csv
  \item
    Census\_2021\_Regions.csv
  \item
    Census\_2021\_Counties.csv
  \item
    Census\_2021\_Wards.csv
  \item
    England\_Wales\_SAR.csv
  \end{itemize}
\item
  Open RStudio
\item
  Open a new R Script for your Week 4 work, rename it as Week4.R and
  save it in your newly created Week 4 folder, under M drive
  -\textgreater{} ENVS162 folder.
\item
  Check whether there are any previous left dataframes in your RStudio
  in the upper-right side Environment pane. You can always use the to
  clear all the dataframes in your environment and make it all clean.
  For the same aim, you can click the icon
  \includegraphics[width=0.32292in,height=0.22917in]{labs/images/clipboard-2907453316.png},
  or you can run the below code:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rm}\NormalTok{(}\AttributeTok{list =} \FunctionTok{ls}\NormalTok{())}
\end{Highlighting}
\end{Shaded}
\end{itemize}

This command and also the brush icon can both clear RStudio's memory,
removing any data objects that you have previously created.

\section{Load libraries}\label{load-libraries}

Exactly as what we have done for the previous weeks, before starting any
analysis in R, we first need to load the essential libraries as all the
functions/commands are packed in these libraries. For this week, we will
still rely on \texttt{tidyverse},~\texttt{tmap} and~\texttt{sf}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(sf)}
\FunctionTok{library}\NormalTok{(tmap)}
\end{Highlighting}
\end{Shaded}

\section{\texorpdfstring{\textbf{The Geography of Health
(area-level)}}{The Geography of Health (area-level)}}\label{the-geography-of-health-area-level}

\subsection{Viewing the district level
boundaries}\label{viewing-the-district-level-boundaries}

The \emph{districts} dataset is an area-level dataset, in which each row
represents one district. Let's view what this data looks like.

\subsubsection{Load the district boundaries
data}\label{load-the-district-boundaries-data}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#load the boundary dataset}
\NormalTok{district\_map }\OtherTok{\textless{}{-}} \FunctionTok{st\_read}\NormalTok{(}\StringTok{"LAD December 2021 EW BUC.geojson"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Reading layer `LAD December 2021 EW BUC.geojson' from data source 
  `C:\Users\jsmith\OneDrive - George Mason University - O365 Production\Documents\quant\labs\LAD December 2021 EW BUC.geojson' 
  using driver `GeoJSON'
Simple feature collection with 331 features and 1 field
Geometry type: MULTIPOLYGON
Dimension:     XY
Bounding box:  xmin: -6.360297 ymin: 49.88234 xmax: 1.763571 ymax: 55.8112
Geodetic CRS:  WGS 84
\end{verbatim}

\subsubsection{Display on a map}\label{display-on-a-map}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{qtm}\NormalTok{(district\_map)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/04.Health_files/figure-pdf/unnamed-chunk-4-1.pdf}}

These are just the boundaries of the districts across England.

\subsubsection{View socioeconomic data at the district
level}\label{view-socioeconomic-data-at-the-district-level}

This data is contained in the Census\_2021\_Districts.csv file. Let's
load this file and view it's contents.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{districts }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"Census\_2021\_Districts.csv"}\NormalTok{,}\AttributeTok{stringsAsFactors =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The census dataset contains information on each district in England and
Wales derived from the 2021 Census.

The dataset contains three sets of variables

\begin{itemize}
\item
  \emph{LAD21CD} to \emph{Country} - a set of \emph{geographic
  identifiers} relating to the location of each district {[}There is a
  variable in the \emph{district\_map}{]}
\item
  \emph{Density} and \emph{Mean\_Age} - two \emph{measures}: population
  density (per km\^{}2) and mean age (in years)
\item
  \emph{Age\_0\_to\_19} to \emph{Public\_Transport} - a set of variables
  measuring the \emph{percentage} of persons in each district that fall
  within the various the categories named by the variables. For example,
  the variable \emph{Age\_0\_to\_19} records the \% of persons aged 0 to
  19, whilst \emph{Public\_Transport} records the \% of persons who
  commute to work by public transport.
\end{itemize}

Recall what we should do to familiar ourselves with the dataset? We need
to now how many rows and columns of the dataset, what are the variables,
what types of these variables, and we may what to view the dataset for a
quick scan?

Therefore, we need these functions: \texttt{dim()} or \texttt{ncol()}
and \texttt{nrow()}, \texttt{names()}, \texttt{str()}, and
\texttt{View()}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# know how many rows and columns}
\FunctionTok{dim}\NormalTok{(districts)}
\CommentTok{\# know the names of the variables}
\FunctionTok{names}\NormalTok{(districts)}
\CommentTok{\# know types and examples of these variables}
\FunctionTok{str}\NormalTok{(districts)}
\CommentTok{\# open a view window to scan the dataset}
\FunctionTok{View}\NormalTok{(districts)}
\end{Highlighting}
\end{Shaded}

\textbf{QUESTION 1}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

How many rows does the districts data have?

Solution: 331

How many columns does the districts data have?

Solution: 56

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

The \emph{districts} dataset has a lot of data but it would be useful to
visualise this data on a map.

In order to map any of the variables contained in the \emph{districts}
dataset, we need to join them to the \emph{district\_map} dataset using
the \texttt{left\_join(\ )} command. We can link the two datasets using
the variable they share in common, \emph{LAD21CD}, which is the unique
identifier given by the Office for National Statistics to each district
captured in the 2021 Census.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{census\_map }\OtherTok{\textless{}{-}} \FunctionTok{left\_join}\NormalTok{(district\_map, districts, }\AttributeTok{by =} \StringTok{"LAD21CD"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Note that the dataset containing the map boundaries
(\emph{district\_map}) MUST be listed \emph{before} the dataset it is
being joined to (\emph{districts}), otherwise the
\texttt{left\_join(\ )} command will throw an error.

\textbf{QUESTION 2}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Write a line of code that tells you the number of columns in the
census\_map dataset.

Solution

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dim}\NormalTok{(census\_map)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 331  57
\end{verbatim}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection{\texorpdfstring{\textbf{The spatial distribution Poor
Health}}{The spatial distribution Poor Health}}\label{the-spatial-distribution-poor-health}

One of the variables contained in the \emph{district} dataset is
\emph{Poor\_Health}, which records the \% of persons in each district
who self-reported their health as being either `poor' or `very poor'.

\subsubsection{Examining skewness in the
data}\label{examining-skewness-in-the-data}

Let's now examine the distribution of this data. Recall from week 2 lab
that one way to do this is using a boxplot.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{boxplot}\NormalTok{(census\_map}\SpecialCharTok{$}\NormalTok{Poor\_Health,}
        \AttributeTok{horizontal=}\ConstantTok{TRUE}\NormalTok{, }
        \AttributeTok{main =} \StringTok{"Poor\_Health"}\NormalTok{, }
        \AttributeTok{xlab=}\StringTok{\textquotesingle{}Percentage\textquotesingle{}}\NormalTok{, }
        \AttributeTok{col =} \StringTok{"gold"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/04.Health_files/figure-pdf/unnamed-chunk-9-1.pdf}}

\textbf{QUESTION 3}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Return to the week 2 lab. Using the information provided, determine
whether \emph{Poor\_Health} is skewed or not.

Solution:

Poor\_Health is slightly skewed which is evident given that the median
line is towards the centre of the plot and the distribution of values
before an after this line seems almost identical.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsubsection{\texorpdfstring{Map the spatial distribution of
\emph{Poor\_Health}}{Map the spatial distribution of Poor\_Health}}\label{map-the-spatial-distribution-of-poor_health}

Use the \texttt{tm\_scale\_continuous()} option to make sure that areas
with the highest rates of poor health have the darkest shading.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Poor\_Health\_map }\OtherTok{\textless{}{-}} 
  \FunctionTok{tm\_shape}\NormalTok{(census\_map) }\SpecialCharTok{+}
  \FunctionTok{tm\_polygons}\NormalTok{(}
    \AttributeTok{fill =} \StringTok{"Poor\_Health"}\NormalTok{,}
    \AttributeTok{fill.scale =} \FunctionTok{tm\_scale\_continuous}\NormalTok{(}\AttributeTok{values =} \StringTok{"Blues"}\NormalTok{)}
\NormalTok{  )}

\NormalTok{Poor\_Health\_map}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/04.Health_files/figure-pdf/unnamed-chunk-10-1.pdf}}

Some areas have really high \emph{Poor\_Health} values. Let's now find
out which district have the highest percentage of people with poor
health.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{census\_map }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{slice}\NormalTok{(}\FunctionTok{which.max}\NormalTok{(Poor\_Health)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(}\StringTok{\textasciigrave{}}\AttributeTok{District}\StringTok{\textasciigrave{}}\NormalTok{, Poor\_Health)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Simple feature collection with 1 feature and 2 fields
Geometry type: MULTIPOLYGON
Dimension:     XY
Bounding box:  xmin: -0.3174608 ymin: 53.00112 xmax: 0.3556274 ymax: 53.52762
Geodetic CRS:  WGS 84
      District Poor_Health                       geometry
1 East Lindsey    26.40201 MULTIPOLYGON (((0.2409995 5...
\end{verbatim}

\subsubsection{Map the spatial distribution of
Age\_65\_plus}\label{map-the-spatial-distribution-of-age_65_plus}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Age\_65\_plus\_map }\OtherTok{\textless{}{-}} 
  \FunctionTok{tm\_shape}\NormalTok{(census\_map) }\SpecialCharTok{+}
  \FunctionTok{tm\_polygons}\NormalTok{(}
    \AttributeTok{fill =} \StringTok{"Age\_65\_plus"}\NormalTok{,}
    \AttributeTok{fill.scale =} \FunctionTok{tm\_scale\_continuous}\NormalTok{(}\AttributeTok{values =} \StringTok{"YlOrRd"}\NormalTok{)}
\NormalTok{  )}

\NormalTok{Age\_65\_plus\_map}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/04.Health_files/figure-pdf/unnamed-chunk-12-1.pdf}}

\textbf{QUESTION 3}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

What pattern(s) do you observe comparing the spatial distribution of
both variables?

Solution

There is a bit more healthy and younger people in southern places like
London and the surroundings compared to more northern areas; this
pattern reinforces the idea of the north-south divide.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection{\texorpdfstring{\textbf{Visualise associations with a
scatter
plot}}{Visualise associations with a scatter plot}}\label{visualise-associations-with-a-scatter-plot}

As we've seen in previous weeks, another way of visualising the
association between two continuous variables is through a scatter plot:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{census\_map }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ Age\_65\_plus, }\AttributeTok{y =}\NormalTok{ Poor\_Health), }\AttributeTok{colour =} \StringTok{"blue"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"\% Aged 65+"}\NormalTok{, }\AttributeTok{y =} \StringTok{"\% in Poor Health"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_classic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/04.Health_files/figure-pdf/unnamed-chunk-13-1.pdf}}

This graph reinforces the impression that older areas tend to have more
people in poor health. However, the question still remains, how strong
is the association/relationship between these two variables? Remember,
as discussed in class, if this was a `perfect' relationship between both
variables that those dots would form a straight line. This is not the
case but there still seems to be a relationship there. Discuss with your
colleague next to you how strong this relationship and see if you agree.

\section{\texorpdfstring{\textbf{Measuring the correlation of
\emph{continuous}
variables}}{Measuring the correlation of continuous variables}}\label{measuring-the-correlation-of-continuous-variables}

As covered in this week's lecture, we can quantify the amount of
association between two continuous variables by calculating their
correlation. The correct measure of correlation to use (Pearsons or
Spearmans) depends on the distribution of the two variables being
correlated.

\subsection{\texorpdfstring{\textbf{Check if both variables are
symmetrical}}{Check if both variables are symmetrical}}\label{check-if-both-variables-are-symmetrical}

If both variables are continuous and symmetrically distributed, then the
correct measure of correlation to use is Pearson's product moment
correlation coefficient. Alternatively, if one or both of the variables
are skewed, the correct measure to use is Spearman's Rank correlation
coefficient.

We can check whether or not \emph{Poor\_Health} and \emph{Age\_65\_plus}
are symmetrically distributed by visualising their distributions using
histograms, and by calculating their skew.

Histogram for \emph{Poor\_Health}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{census\_map }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ Poor\_Health), }\AttributeTok{fill =} \StringTok{"grey"}\NormalTok{, }\AttributeTok{bins =} \DecValTok{30}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/04.Health_files/figure-pdf/unnamed-chunk-14-1.pdf}}

Histogram for \emph{Age\_65\_plus}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{census\_map }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ Age\_65\_plus), }\AttributeTok{fill =} \StringTok{"grey"}\NormalTok{, }\AttributeTok{bins =} \DecValTok{30}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/04.Health_files/figure-pdf/unnamed-chunk-15-1.pdf}}

As we've seen previously we can use a boxplot to help us determine
whether a variable may be skewed or not. However, sometimes this can
prove challenging. In cases like this, we can compute a number that
tells us how skewed a vaiables is. In this case, we'll measure skew in
the range of -1 to +1, with values closer to 0 being less skewed, and
values closer to -1 or +1 being a lot more skewed.

Compute skew for \emph{Poor\_Health}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}}\NormalTok{ census\_map}\SpecialCharTok{$}\NormalTok{Poor\_Health}
\NormalTok{x }\OtherTok{\textless{}{-}}\NormalTok{ x[}\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(x)]}
\FunctionTok{mean}\NormalTok{((x }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(x))}\SpecialCharTok{\^{}}\DecValTok{3}\NormalTok{) }\SpecialCharTok{/} \FunctionTok{sd}\NormalTok{(x)}\SpecialCharTok{\^{}}\DecValTok{3}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.1277937
\end{verbatim}

Compute skew for \emph{Age\_65\_Plus}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}}\NormalTok{ census\_map}\SpecialCharTok{$}\NormalTok{Age\_65\_plus}
\NormalTok{x }\OtherTok{\textless{}{-}}\NormalTok{ x[}\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(x)]}

\FunctionTok{mean}\NormalTok{((x }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(x))}\SpecialCharTok{\^{}}\DecValTok{3}\NormalTok{) }\SpecialCharTok{/} \FunctionTok{sd}\NormalTok{(x)}\SpecialCharTok{\^{}}\DecValTok{3}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] -0.1794138
\end{verbatim}

From the above we can see that although neither variable is perfectly
symmetrically distributed (skew = 0), they are both approximately
symmetrical (skew in the range -0.5 to +0.5).

\subsection{\texorpdfstring{\textbf{Calculate appropriate measure of
correlation}}{Calculate appropriate measure of correlation}}\label{calculate-appropriate-measure-of-correlation}

Both \emph{Poor\_Health} and \emph{Age\_65\_plus} are approximately
symmetrically distributed. Therefore the appropriate measure of
correlation to use is Pearson's product moment correlation coefficient.
Let's calculate this correlation coefficient now between these two
variables.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cor}\NormalTok{(census\_map}\SpecialCharTok{$}\NormalTok{Poor\_Health,}
\NormalTok{    census\_map}\SpecialCharTok{$}\NormalTok{Age\_65\_plus,}
    \AttributeTok{method =} \StringTok{"pearson"}\NormalTok{,}
    \AttributeTok{use =} \StringTok{"complete.obs"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.4631554
\end{verbatim}

From the output above we can see that \emph{Poor\_Health} and
\emph{Age\_65\_plus} have a Pearsons's correlation of +0.46. The size of
the correlation (0.46) indicates that there is a moderate strength
association between the two variables. (A correlation 0 would indicate
no association, and a correlation of +1 or -1 would indicate a perfect
one-to-one association.) The sign of the correlation (+) indicates that
districts with more persons aged 65+ have more poor health.

If one or both variables had been skewed, then we would have needed to
calculate Spearman's correlation coefficient, which can be achieved
simply by changing the measure requested from \texttt{"pearson"} to
\texttt{"spearman".}

\subsubsection{Interpretation of Correlation (r)
values}\label{interpretation-of-correlation-r-values}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2267}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1467}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.4933}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Correlation (r)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strength
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Direction
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Interpretation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
+1.0 & Perfect & Positive & Variables increase together exactly \\
+0.7 to +0.9 & Strong & Positive & Strong increasing relationship \\
+0.4 to +0.6 & Moderate & Positive & Clear increasing trend \\
+0.1 to +0.3 & Weak & Positive & Slight increasing trend \\
0 & None & None & No linear relationship \\
0.1 to 0.3 & Weak & Negative & Slight decreasing trend \\
0.4 to 0.6 & Moderate & Negative & Clear decreasing trend \\
0.7 to 0.9 & Strong & Negative & Strong decreasing relationship \\
1.0 & Perfect & Negative & Variables decrease together exactly \\
\end{longtable}

\textbf{QUESTION 4}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Which statements are correct?

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Pearson's correlation is \ul{a linear correlation}.
\end{enumerate}

\begin{itemize}
\tightlist
\item
  a rank-based correlation
\item
  {a linear correlation}
\item
  a measure of spatial autocorrelation
\item
  a robust estimator of median association
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Spearman's correlation is \ul{a rank-based correlation}.
\end{enumerate}

\begin{itemize}
\tightlist
\item
  a rank-based correlation
\item
  {a linear correlation}
\item
  a measure of spatial autocorrelation
\item
  a robust estimator of median association
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  The correlation between Age\_65\_plus and Poor\_Health is +0.46. Does
  this mean ageing causes poor health? Explain.
\end{enumerate}

Solution

No, correlation does not imply causation. Additional studies would need
to be done to confirm this is the case.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection{\texorpdfstring{\textbf{Visualising the association between
categorical
variables}}{Visualising the association between categorical variables}}\label{visualising-the-association-between-categorical-variables}

To work with categorical variables we will be using the SAR dataset.
However, before you can use this data, you must pass the SAR Data Access
test on canvas located in Week 4. this should take no more than a minute
or so. After passing the test, you should be able to download the file
\emph{England and Wales SAR.csv} from the Week 4 folder on CANVAS and
save it to the same folder as your Week4.R script on your M drive.

Next we need to load the data,

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SAR }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"England\_Wales\_SAR.csv"}\NormalTok{,}\AttributeTok{stringsAsFactors =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The \emph{SAR} dataset contains information on an anonymised 5\% sample
of respondents to the 2021 Census. Anonymisation strategies range from
the obvious (name and address removed) to the less obvious (e.g.~the
removal of all geography below district-level; the regrouping of age
from single year of age to five-year age groups etc.).

The dataset contains a LOT of respondents!

Let's visualise the relationship between \emph{health} and one of the
variables that we think think helps explain variations in \emph{health},
such as \emph{age\_group}. This may take up to 30 seconds or so.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SAR }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_bar}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ age\_group, }\AttributeTok{fill =}\NormalTok{ health),}
           \AttributeTok{position =} \StringTok{"dodge"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_classic}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}
    \AttributeTok{axis.text.x =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{angle =} \DecValTok{45}\NormalTok{, }\AttributeTok{hjust =} \DecValTok{1}\NormalTok{)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/04.Health_files/figure-pdf/unnamed-chunk-20-1.pdf}}

The clear story told by this graph is that the number and proportion of
people in `Very Good' health declines with age.

We can also visualise this as a stacked barchart.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SAR }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_bar}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ age\_group, }\AttributeTok{fill =}\NormalTok{ health)) }\SpecialCharTok{+}
  \FunctionTok{theme\_classic}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}
    \AttributeTok{axis.text.x =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{angle =} \DecValTok{45}\NormalTok{, }\AttributeTok{hjust =} \DecValTok{1}\NormalTok{)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/04.Health_files/figure-pdf/unnamed-chunk-21-1.pdf}}

\section{\texorpdfstring{\textbf{Measuring the correlation of
categorical
variables}}{Measuring the correlation of categorical variables}}\label{measuring-the-correlation-of-categorical-variables}

Bar graphs can give us some clues, but to be sure we need to quantify
the amount of association each pair of categorical variables by
calculating their correlations.

When measuring the strength of association between two categorical
variables the correct measure of correlation to use Spearmans
correlation coefficient or Cramer's V. Which specific one depends on the
nature of the two variables being correlated.

To select the correct measure of correlation for a given pair of
categorical variables, you first need to decide whether each variable is
nominal or ordinal.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SAR }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{pull}\NormalTok{(health) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{levels}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "Bad"       "Fair"      "Good"      "Very Bad"  "Very Good"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SAR }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{pull}\NormalTok{(marital\_status) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{levels}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "Divorced/partnership dissolved"   "Legally partnered, but separated"
[3] "Married"                          "Never legally partnered"         
[5] "Registered Civil Partnership"     "Widowed"                         
\end{verbatim}

Since both \emph{health} and \emph{marital\_status} are not ordinal, it
is clear that Cramer's V should be used.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tab }\OtherTok{\textless{}{-}} \FunctionTok{table}\NormalTok{(SAR}\SpecialCharTok{$}\NormalTok{health, SAR}\SpecialCharTok{$}\NormalTok{marital\_status)}

\NormalTok{chisq }\OtherTok{\textless{}{-}} \FunctionTok{chisq.test}\NormalTok{(tab)}

\NormalTok{n }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(tab)}
\NormalTok{k }\OtherTok{\textless{}{-}} \FunctionTok{min}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(tab) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, }\FunctionTok{ncol}\NormalTok{(tab) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)}

\NormalTok{cramerv }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(chisq}\SpecialCharTok{$}\NormalTok{statistic }\SpecialCharTok{/}\NormalTok{ (n }\SpecialCharTok{*}\NormalTok{ k))}
\FunctionTok{cat}\NormalTok{(}\StringTok{"Cramr\textquotesingle{}s V ="}\NormalTok{, cramerv, }\StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Cramr's V = 0.1231071 
\end{verbatim}

Remember that unlike Pearson's product moment coefficient and Spearman's
rank, which have values in the range of -1 to +1, Cramer's V have values
between 0 and 1, with 0 representing no association and 1 being a very
strong association.

\textbf{QUESTION 5}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Which of the following correctly describes the strength of the above
association?

\begin{itemize}
\item
  None
\item
  Weak
\item
  Moderate
\item
  Strong
\end{itemize}

Solution

Weak

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{\texorpdfstring{\textbf{Area-level data analysis traps -
MAUP}}{Area-level data analysis traps - MAUP}}\label{area-level-data-analysis-traps---maup}

Recall that the \textbf{Modifiable Areal Unit Problem (MAUP) is} a
source of statistical bias in spatial analysis whereby results (e.g.,
correlations, regression coefficients, summary statistics) change when
the spatial units of aggregation are modified, either by altering their
\textbf{scale (size)} or their \textbf{zoning (boundary configuration)}.

Let's check this relationship for \emph{Poor\_Health} and
\emph{Age\_65\_plus} at the Ward, Counties, District, and Region levels

First we'll need to load the Wards, Counties, and Region data. No need
to load the District data because we've already done this before.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Load regions file}
\NormalTok{regions }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"Census\_2021\_Regions.csv"}\NormalTok{,}\AttributeTok{stringsAsFactors =} \ConstantTok{TRUE}\NormalTok{)}
\CommentTok{\# Load wards file}
\NormalTok{wards }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"Census\_2021\_Wards.csv"}\NormalTok{,}\AttributeTok{stringsAsFactors =} \ConstantTok{TRUE}\NormalTok{)}
\CommentTok{\# Load counties file}
\NormalTok{counties }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"Census\_2021\_Counties.csv"}\NormalTok{,}\AttributeTok{stringsAsFactors =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We'll use Spearman's rank correlation to quantify the association
between \emph{Poor\_Health} and \emph{Age\_65\_plus}

Regions.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cor}\NormalTok{(regions}\SpecialCharTok{$}\NormalTok{Poor\_Health,}
\NormalTok{    regions}\SpecialCharTok{$}\NormalTok{Age\_65\_plus,}
    \AttributeTok{method =} \StringTok{"spearman"}\NormalTok{,}
    \AttributeTok{use =} \StringTok{"complete.obs"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.3212121
\end{verbatim}

Counties

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cor}\NormalTok{(regions}\SpecialCharTok{$}\NormalTok{Poor\_Health,}
\NormalTok{    regions}\SpecialCharTok{$}\NormalTok{Age\_65\_plus,}
    \AttributeTok{method =} \StringTok{"spearman"}\NormalTok{,}
    \AttributeTok{use =} \StringTok{"complete.obs"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.3212121
\end{verbatim}

Districts

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cor}\NormalTok{(districts}\SpecialCharTok{$}\NormalTok{Poor\_Health,}
\NormalTok{    districts}\SpecialCharTok{$}\NormalTok{Age\_65\_plus,}
    \AttributeTok{method =} \StringTok{"spearman"}\NormalTok{,}
    \AttributeTok{use =} \StringTok{"complete.obs"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.4622558
\end{verbatim}

Wards

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cor}\NormalTok{(wards}\SpecialCharTok{$}\NormalTok{Poor\_Health,}
\NormalTok{    wards}\SpecialCharTok{$}\NormalTok{Age\_65\_plus,}
    \AttributeTok{method =} \StringTok{"spearman"}\NormalTok{,}
    \AttributeTok{use =} \StringTok{"complete.obs"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.2574719
\end{verbatim}

In summary, the results above show that the correlation of
\emph{Poor\_Health} with \emph{Age\_65\_plus} vary by scale as follows:

\begin{verbatim}
     Scale Spearman
1   Region     0.32
2   County     0.51
3 District     0.46
4     Ward     0.26
\end{verbatim}

The correlation is strongest at county level, and decreases with the
size of the spatial unit from county to ward. This suggests that at
smaller scales, such as wards, there is some process that weakens the
relationship between age and health. This process is likely to be some
kind of social sorting (e.g.~spatial segregation of the rich and poor)
which results in some wards containing an unusually high share of
healthy or unhealthy elderly. In contrast, there is less social sorting
between counties, as each tends to contain a wide variety of persons.
The weaker correlation at regional level is probably due in part to how
few regions there are, and in part to the stark health and economic
divide between regions in the South East of England and the rest of the
country.

\textbf{QUESTION 6}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Can you think of any other factors that may help explain the differences
in correlation values with scale?

Solution

More variation in local factors related to health such as deprivation,
access to adequate health care, types of jobs etc. at more local levels.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Formative tasks}\label{formative-tasks-3}

\textbf{Task 1}

Visualise the association between \texttt{Poor\_Health} and
\texttt{Density} in the \textbf{District} data for Liverpool

Solution

Step 1: Extract the liverpool data

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{liverpool }\OtherTok{\textless{}{-}} 
\NormalTok{  wards }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{( District }\SpecialCharTok{==} \StringTok{"Liverpool"}\NormalTok{ )}
\end{Highlighting}
\end{Shaded}

Step 2: Draw scatter plot

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{liverpool }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{( ) }\SpecialCharTok{+}
    \FunctionTok{geom\_point}\NormalTok{( }\FunctionTok{aes}\NormalTok{( }\AttributeTok{x =}\NormalTok{ Density, }\AttributeTok{y =}\NormalTok{ Poor\_Health ), }\AttributeTok{colour =} \StringTok{"blue"}\NormalTok{ ) }\SpecialCharTok{+}
    \FunctionTok{labs}\NormalTok{( }\AttributeTok{x =} \StringTok{" Population Density"}\NormalTok{,}
          \AttributeTok{y =} \StringTok{"\% in Poor Health"}\NormalTok{ ) }\SpecialCharTok{+}
    \FunctionTok{theme\_classic}\NormalTok{( )}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/04.Health_files/figure-pdf/unnamed-chunk-31-1.pdf}}

\textbf{Task 2}

Compute the right correlation measure to association between
\texttt{Poor\_Health} and \texttt{Density} in Liverpool. Interpret and
discuss what the results mean.

Solution

Remember that for numerical values, we need to first check the skewness
of each variables.

Step 1: Compute skewness

Poor\_Health

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}}\NormalTok{ liverpool}\SpecialCharTok{$}\NormalTok{Poor\_Health}
\NormalTok{x }\OtherTok{\textless{}{-}}\NormalTok{ x[}\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(x)]}

\FunctionTok{mean}\NormalTok{((x }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(x))}\SpecialCharTok{\^{}}\DecValTok{3}\NormalTok{) }\SpecialCharTok{/} \FunctionTok{sd}\NormalTok{(x)}\SpecialCharTok{\^{}}\DecValTok{3}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] -0.4132168
\end{verbatim}

Density

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}}\NormalTok{ liverpool}\SpecialCharTok{$}\NormalTok{Density}
\NormalTok{x }\OtherTok{\textless{}{-}}\NormalTok{ x[}\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(x)]}

\FunctionTok{mean}\NormalTok{((x }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(x))}\SpecialCharTok{\^{}}\DecValTok{3}\NormalTok{) }\SpecialCharTok{/} \FunctionTok{sd}\NormalTok{(x)}\SpecialCharTok{\^{}}\DecValTok{3}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.1234378
\end{verbatim}

The \emph{Poor\_Health} is skewed so Spearman's Rank should be used

Step 3: Compute Spearman's Rank

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cor}\NormalTok{(liverpool}\SpecialCharTok{$}\NormalTok{Poor\_Health,}
\NormalTok{    liverpool}\SpecialCharTok{$}\NormalTok{Density,}
    \AttributeTok{method =} \StringTok{"spearman"}\NormalTok{,}
    \AttributeTok{use =} \StringTok{"complete.obs"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] -0.07185762
\end{verbatim}

The Spearman's rank correlation coefficient indicates a weak association
between population density and levels of poor health in Liverpool wards.
This suggests that changes in density are only weakly related to changes
in poor health, and density alone is not a strong predictor of health
outcomes.

\textbf{Task 3}

Using the above correlation metric, determine whether MAUP is an issues
using all records the data for Wards, Counties, Districts, and Regions
for the same variables.

Solution

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cor}\NormalTok{(regions}\SpecialCharTok{$}\NormalTok{Poor\_Health,}
\NormalTok{    regions}\SpecialCharTok{$}\NormalTok{Density,}
    \AttributeTok{method =} \StringTok{"spearman"}\NormalTok{,}
    \AttributeTok{use =} \StringTok{"complete.obs"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] -0.4666667
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cor}\NormalTok{(districts}\SpecialCharTok{$}\NormalTok{Poor\_Health,}
\NormalTok{    districts}\SpecialCharTok{$}\NormalTok{Density,}
    \AttributeTok{method =} \StringTok{"spearman"}\NormalTok{,}
    \AttributeTok{use =} \StringTok{"complete.obs"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] -0.1887088
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cor}\NormalTok{(counties}\SpecialCharTok{$}\NormalTok{Poor\_Health,}
\NormalTok{    counties}\SpecialCharTok{$}\NormalTok{Density,}
    \AttributeTok{method =} \StringTok{"spearman"}\NormalTok{,}
    \AttributeTok{use =} \StringTok{"complete.obs"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] -0.2344274
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cor}\NormalTok{(wards}\SpecialCharTok{$}\NormalTok{Poor\_Health,}
\NormalTok{    wards}\SpecialCharTok{$}\NormalTok{Density,}
    \AttributeTok{method =} \StringTok{"spearman"}\NormalTok{,}
    \AttributeTok{use =} \StringTok{"complete.obs"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] -0.01063299
\end{verbatim}

The Spearman correlations differ across wards, districts, counties and
regions, demonstrating that the strength (and possibly direction) of the
association between population density and poor health depends on the
spatial scale of analysis. This variation indicates the presence of the
scale effect of the Modifiable Areal Unit Problem (MAUP), whereby
statistical relationships are sensitive to the level of spatial
aggregation.

\textbf{Task 4}

Compute the skewness between \texttt{Poor\_Health} for Districts for all
the data and for Liverpool only. Discuss what could be leading these
results

Solution

All districts

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}}\NormalTok{ districts}\SpecialCharTok{$}\NormalTok{Poor\_Health}
\NormalTok{x }\OtherTok{\textless{}{-}}\NormalTok{ x[}\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(x)]}

\FunctionTok{mean}\NormalTok{((x }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(x))}\SpecialCharTok{\^{}}\DecValTok{3}\NormalTok{) }\SpecialCharTok{/} \FunctionTok{sd}\NormalTok{(x)}\SpecialCharTok{\^{}}\DecValTok{3}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.1277937
\end{verbatim}

Liverpool

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}}\NormalTok{ liverpool}\SpecialCharTok{$}\NormalTok{Poor\_Health}
\NormalTok{x }\OtherTok{\textless{}{-}}\NormalTok{ x[}\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(x)]}

\FunctionTok{mean}\NormalTok{((x }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(x))}\SpecialCharTok{\^{}}\DecValTok{3}\NormalTok{) }\SpecialCharTok{/} \FunctionTok{sd}\NormalTok{(x)}\SpecialCharTok{\^{}}\DecValTok{3}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] -0.4132168
\end{verbatim}

The skewness for all districts is 0.128, which is close to zero,
indicating that the distribution of poor health across England and Wales
is approximately symmetrical. This suggests that most districts have
similar levels of poor health, with only a few districts having higher
values. In contrast, Liverpool has a skewness of 0.413, indicating a
moderate negative skew. This means that most areas in Liverpool have
relatively high levels of poor health, with a few areas having lower
levels. This reflects internal inequalities within Liverpool. These
results demonstrate how health patterns vary depending on spatial scale.

\textbf{Task 5}

Calculate the interquartile range (IQR) of \texttt{Poor\_Health} at the
Region, District, and Ward levels and discuss the results as they relate
to MAUP.

Remember:

\begin{itemize}
\tightlist
\item
  IQR measures the spread of the middle 50\% of values.
\item
  Larger IQR  greater inequality or heterogeneity.
\item
  Smaller IQR  greater smoothing through aggregation
\item
\end{itemize}

Solution

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{IQR}\NormalTok{(districts}\SpecialCharTok{$}\NormalTok{Poor\_Health, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 4.958409
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{IQR}\NormalTok{(regions}\SpecialCharTok{$}\NormalTok{Poor\_Health, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 2.191963
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{IQR}\NormalTok{(wards}\SpecialCharTok{$}\NormalTok{Poor\_Health, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{)  }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 6.021823
\end{verbatim}

The interquartile range increases as spatial units become smaller, from
2.19 at regional level to 6.02 at ward level. This demonstrates that
aggregation reduces observed variability in poor health. Larger spatial
units smooth internal differences, while smaller units reveal greater
socio-spatial inequality. This provides clear evidence of the scale
effect of the Modifiable Areal Unit Problem (MAUP), whereby statistical
properties of data depend on the level of spatial aggregation.

\bookmarksetup{startatroot}

\chapter{Lab: Can we trust our
results?}\label{lab-can-we-trust-our-results}

\section{Overview}\label{overview-5}

This week focuses on wealth, which strongly affects people's life
chances. Wealth can influence life expectancy, education, job
opportunities, and mental health. In Britain, social mobility is low,
meaning a person's future is closely linked to their family background,
education, and where they live. Reducing inequality and improving access
to education and opportunities benefits both individuals and the wider
economy.

The practical will explore the following questions:

\begin{itemize}
\tightlist
\item
  What does it mean to be `rich'?
\item
  Who is rich?
\item
  How reliable are the results?
\end{itemize}

To answer these questions, data from the Annual Population Survey (2021)
will be analysed. The practical also introduces the basic steps used in
quantitative research:

\begin{itemize}
\tightlist
\item
  Understanding the dataset
\item
  Identifying key outcome and explanatory variables
\item
  Exploring relationships between variables (correlation)
\item
  Understanding confidence in the relationship between variables
\end{itemize}

These skills are essential for future research projects, including
fieldwork and dissertations that use quantitative data.

\section{Prepare your working
environment}\label{prepare-your-working-environment-2}

\begin{itemize}
\item
  For this Week 5 session, create a sub-folder called~Week5~in
  your~ENVS162 folder on your M-Drive. This is exactly the step we did
  in Weeks 1, 2, 3, and 4.
\item
  Download this week's practical datasets from Canvas Week 5:

  \begin{itemize}
  \tightlist
  \item
    APS\_2021.csv
  \item
    UK\_regions\_map.geojson
  \end{itemize}
\item
  Check whether there are any previous left dataframes in your RStudio
  in the upper-right side Environment pane. You can always use the to
  clear all the dataframes in your environment and make it all clean.
  For the same aim, you can click the icon
  \includegraphics[width=0.32292in,height=0.22917in]{labs/images/clipboard-2907453316.png},
  or you can run the below code:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rm}\NormalTok{( }\AttributeTok{list =} \FunctionTok{ls}\NormalTok{( )  )}
\end{Highlighting}
\end{Shaded}
\end{itemize}

This command and also the brush icon can both clear RStudio's memory,
removing any data objects that you have previously created.

\section{Load libraries}\label{load-libraries-1}

Exactly as what we have done for the previous weeks, before starting any
analysis in R, we first need to load the essential libraries as all the
functions/commands are packed in these libraries. For this week, we will
still rely on \texttt{tidyverse},~\texttt{tmap} and~\texttt{sf}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(sf)}
\FunctionTok{library}\NormalTok{(tmap)}
\FunctionTok{library}\NormalTok{(dplyr)}
\FunctionTok{library}\NormalTok{ (}\StringTok{"ineq"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\section{Open the APS dataset}\label{open-the-aps-dataset}

This will open the APS\_2021 data file

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{APS }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"APS\_2021.csv"}\NormalTok{,}\AttributeTok{stringsAsFactors =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

This will result in the~\emph{APS}~dataset being added to your
Environment pane in RStudio as \emph{APS}. This dataset contains data on
all adult respondents (persons aged 16+) to the 2021 Annual Population
Survey.

\section{Dataset familiarisation}\label{dataset-familiarisation}

Use
\texttt{nrow(\ )},~\texttt{ncol(\ )},~\texttt{names(\ )}~and~\texttt{View(\ )}~commands
to give yourself an insight into the contents of the Annual Population
Survey.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{nrow}\NormalTok{(APS)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 209651
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ncol}\NormalTok{( APS)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 59
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{names}\NormalTok{( APS)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] "idref"              "Household_ID"       "Extended_Family_ID"
 [4] "Family_ID"          "Hhold_Head"         "Family_Head"       
 [7] "Age"                "Sex"                "Marital_Status"    
[10] "Hhold_Type"         "Family_Type"        "Age_Group"         
[13] "Address_Duration"   "Arrival_Year"       "Benefit_Carers"    
[16] "Benefit_Child"      "Benefit_Health"     "Benefit_Housing"   
[19] "Benefit_Income"     "Benefit_JSA"        "Benefit_Pension"   
[22] "Benefit_Tax"        "Benefit_UC"         "Birth_Country"     
[25] "Commute_Method"     "Commute_Time"       "Disabled"          
[28] "Educ_Age"           "Equiv_Net_Pay"      "Ethnicity"         
[31] "Family_Size"        "Family_Toddlers"    "Furnishings"       
[34] "Gross_Pay"          "Health"             "Hholds_at_Address" 
[37] "Hhold_Size"         "Highest_Qual"       "Industry"          
[40] "Job_Years"          "Merseyside"         "Nationality"       
[43] "Net_Pay"            "NS_SEC"             "Private_Sector"    
[46] "Region"             "Religion"           "SOC_Major"         
[49] "SOC_Sub_Major"      "SOC_Minor"          "Tenure"            
[52] "Under_employed"     "Unemp_Duration"     "Work_Home"         
[55] "Work_Hours"         "Work_Status"        "Work_Temporary"    
[58] "Youngest_Child"     "Weight_APS"        
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{View}\NormalTok{(APS )}
\end{Highlighting}
\end{Shaded}

To supplement these insights,~make sure you also read through the
information below.

Key points to note are that:

\begin{itemize}
\tightlist
\item
  Each row is a person
\item
  Instead of a nested geography (e.g.~which county and region a district
  is in) there is a nested household hierarchy (which household,
  extended family and family a person is living in).
\end{itemize}

The variables contained in the~\emph{APS}~cover the following broad
topics:

\begin{itemize}
\tightlist
\item
  \textbf{Household, Family and Person
  identifiers}:~\emph{idref},~\emph{Household\_ID},~\emph{Extended\_Family\_ID},~\emph{Family\_ID},~\emph{Hhold\_Head},~\emph{Family\_Head}
\item
  \textbf{Geographic
  information}:~\emph{Region},~\emph{District},~\emph{Merseyside}~(yes/no)
\item
  \textbf{Basic demographic
  information}:~\emph{Age},~\emph{Age\_Group},~\emph{Sex},~\emph{Marital\_Status}
\item
  \textbf{Cultural
  attributes}:~\emph{Ethnicity},~\emph{Nationality},~\emph{Religion},~\emph{Educ\_Age},~\emph{Highest\_Qual}
\item
  \textbf{Health}:~\emph{Disabled},~\emph{Health}
\item
  \textbf{Migration}:~\emph{Address\_Duration},~\emph{Arrival\_Year},~\emph{Birth\_Country}
\item
  \textbf{Household
  attributes}:~\emph{Family\_Size},~\emph{Family\_Toddlers},~\emph{Family\_Type}~(type
  of partnership and
  children),~\emph{Furnishings},~\emph{Hholds\_at\_Address},~\emph{Hhold\_Size}~(Persons),~\emph{Hhold\_Type}~(number
  of families; number and type of
  children),~\emph{Tenure},~\emph{Youngest\_Child}
\item
  \textbf{Work-related
  information}:~\emph{Commute\_Method},~\emph{Commute\_Time},~\emph{Industry},~\emph{Job\_Years},~\emph{NS\_SEC},~\emph{Private\_Sector},~\emph{SOC\_Major},~\emph{SOC\_Sub\_Major},~\emph{SOC\_Minor},~\emph{Under\_employed},~\emph{Unemp\_Duration},~\emph{Work\_Home},~\emph{Work\_Hours},~\emph{Work\_Status},~\emph{Work\_Temporary}
\item
  \textbf{Welfare benefits
  received}:~\emph{Benefit\_Carers}~to~\emph{Benefit\_UC}~(Universal
  Credit)
\item
  \textbf{Income}:~\emph{Equiv\_Net\_Pay},~\emph{Gross\_Pay},~\emph{Net\_Pay}
\end{itemize}

Many of the variables in the~\emph{APS}~dataset are similar to variables
we have met in previous datasets. Of the ones we haven't met before,
many are reasonably self-explanatory
(e.g.~\emph{Hhold\_Size},~\emph{Address\_Duration}~etc.). Others are a
little more obscure, most notable `\emph{Hhold\_Type}',
`\emph{Family\_Type}', `\emph{NS\_SEC}' and `\emph{SOC\_Major}'.

\emph{Hhold\_Type}~and~\emph{Family\_Type}~record the composition of the
people in each household and family captured in the APS. (A household
may contain more than one family.)

Let's see the type of information that \emph{Hhold\_Type} contains.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{APS }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{count}\NormalTok{(Hhold\_Type)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
                            Hhold_Type      n
1    1 family, dep and nondep children  10748
2               1 family, dep children  42791
3                1 family, no children 108471
4            1 family, nondep children  31321
5 2+ families, dep and nondep children   1274
6            2+ families, dep children   4159
7             2+ families, no children   8516
8         2+ families, nondep children   2371
\end{verbatim}

We can also sort the results using the following functions as previously
discussed in lab 2:

\begin{itemize}
\tightlist
\item
  \texttt{arrange(n)}  sorts in ascending order (smallest to largest)
\item
  \texttt{arrange(desc(n))}  sorts in descending order
\end{itemize}

Let's show the results in descending order

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{APS }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{count}\NormalTok{(Hhold\_Type) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{arrange}\NormalTok{(}\FunctionTok{desc}\NormalTok{(n))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
                            Hhold_Type      n
1                1 family, no children 108471
2               1 family, dep children  42791
3            1 family, nondep children  31321
4    1 family, dep and nondep children  10748
5             2+ families, no children   8516
6            2+ families, dep children   4159
7         2+ families, nondep children   2371
8 2+ families, dep and nondep children   1274
\end{verbatim}

\textbf{QUESTION 1}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Based on the above output, which is the most frequent household type?

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{QUESTION 2}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Write code below to determine the largest household size in the data.
HINT: this information can be found in the \emph{Hhold\_Size} variable

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# REPLACE THIS WITH YOUR CODE}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Understanding the outcome}\label{understanding-the-outcome}

Having familiarised ourselves with our dataset, the next steps in any
data analysis are to identify and explore the `outcome' variable(s) of
interest.

\subsection{Identifying the outcome(s) of
interest}\label{identifying-the-outcomes-of-interest}

The purpose of this practical is to explore the geography of wealth.

Ideally we would do this using a variable which captured the full extent
of each respondent's wealth, which rests upon not only their total
income (from earned income, state welfare payments, plus interest earned
on savings etc.), but also their total financial assets (i.e.~total
value of all possessions and financial assets owned, ranging from homes
and cars to stocks and shares).

However, the Annual Population Survey does not capture all of this
information, restricting itself to a focus on income, rather than on
financial assets. In addition, to protect respondent confidentiality the
version of the APS available for classroom use records only earned
income. Receipt of various state welfare payments is flagged
(e.g.~\emph{Benefit\_Carers},~\emph{Benefit\_Child}~etc), but without
reporting the amount received.

This means that our `geography of wealth' will of necessity become a
`geography of pay'.

In the APS there are three variables which capture aspects of pay.

\begin{itemize}
\tightlist
\item
  \emph{Gross\_Pay}, which records Gross annual pay from a person's main
  employer ()
\item
  \emph{Net\_Pay}, which records annual pay from a person's main
  employer () after deduction of all taxes
\item
  \emph{Equiv\_Net\_Pay}, which records the mean Net Pay of all members
  in a household
\end{itemize}

These three variables will form the focus of our study of the `geography
of wealth'. However, an alternative approach would be to use
the~\emph{Tenure}~variable, which flags whether or not someone owns
their own home; or to use one or more of the~\emph{Benefit\_X}~variables
that flag which survey respondents are sufficiently poor that they
qualify for state welfare support of one kind or another.

To gain familiarity with a chosen outcome variable we need to understand
its distribution, graphically (Section 5.2) and statistically (Section
5.3).

\subsection{Visualise the
distribution}\label{visualise-the-distribution}

The variable~\emph{Net\_Pay}~does not place people into income bands.
Instead it is a precise measure of income received.
Hence~\emph{Net\_Pay}~is a continuous variable.

As seen in previous weeks, to visualise the distribution of a continuous
variable we need to use a histogram:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{APS }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{( ) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{( }\FunctionTok{aes}\NormalTok{( }\AttributeTok{x =}\NormalTok{ Net\_Pay ), }\AttributeTok{bins =} \DecValTok{30}\NormalTok{ )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Warning: Removed 150997 rows containing non-finite outside the scale range
(`stat_bin()`).
\end{verbatim}

\pandocbounded{\includegraphics[keepaspectratio]{labs/05.Wealth_files/figure-pdf/unnamed-chunk-8-1.pdf}}

The warning message received means that ggplot dropped 150,997 rows
because the Net\_Pay variable used for the bins had values that were
\texttt{NA}. NA values mean ``Not Available''. They represent missing
data. We can check the number of NA values using the following code.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sum}\NormalTok{(}\FunctionTok{is.na}\NormalTok{(APS}\SpecialCharTok{$}\NormalTok{Net\_Pay))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 150997
\end{verbatim}

As can be seen, this is the same number reported in the warning message
before. While handling NA values is important, they are not the focus of
this lab and therefore will be ignored.

Getting back to the histogram\ldots{}

A point to notice from a histogram of the distribution
of~\emph{Net\_Pay}~is the `spike' in observations at the top of the
distribution, which seems to suggest that lots of people have an annual
net pay in the mid 40k range.

The reason for this apparent spike is that in the classroom version of
the APS the Office for National Statistics have `top-coded' the recorded
values of Net (and Gross) pay in order to protect respondent
confidentiality. In other words all values about a certain threshold
have been capped at a maximum value.

For~\emph{Net\_Pay}~this maximum value is:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{max}\NormalTok{( APS}\SpecialCharTok{$}\NormalTok{Net\_Pay, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{ )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 40976
\end{verbatim}

NOTE: If there were no NA values in the variables there would be no need
to include \emph{na.rm = TRUE} in the code.

As a result, if someone in the APS has a~\emph{Net\_Pay}~of 40,976, this
does NOT mean that they earn 40,976 a year. Instead, it means that they
ear 40,976~\emph{OR MORE}~per year (i.e.~40,976+). This equate to a
salary of 788+ per week, or 3415 per month.

Rerun the above code without removing the NA values

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{max}\NormalTok{( APS}\SpecialCharTok{$}\NormalTok{Net\_Pay)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] NA
\end{verbatim}

\textbf{QUESTION 3}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

The above code will give the incorrect results if we do not remove the
NA values, ensuring that NA values are removed.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# REPLACE THIS WITH YOUR CODE}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Income inequality}\label{income-inequality}

Income is the United Kingdom is clearly not shared equally between all
of its citizens. Some earn far more than others, even after taking into
account the fact that higher earners pay more tax.

Whilst there are many countries in the world with higher levels of
income inequality, by European standards income equality in the UK is
unusually high:

\begin{quote}
``All other European Union countries enjoy greater income equality
{[}than the UK{]}. Because of this their citizens are freer to live
where they wish, to mix equally, to go to school with each other rather
than segregate their children {[}into private fee-paying schools{]}, as
the majority of parents in the top 10 per cent of income distribution in
Britain feel compelled to do.'' Danny Dorling
(2018)~\href{https://www.dannydorling.org/wp-content/files/dannydorling_publication_id6678.pdf}{Peak
Inequality}~New Statesman, 4th July.
\end{quote}

We can visualise this inequality using a Lorenz Curve.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{( }\FunctionTok{Lc}\NormalTok{( APS}\SpecialCharTok{$}\NormalTok{Net\_Pay ) )}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/05.Wealth_files/figure-pdf/unnamed-chunk-13-1.pdf}}

In the graph above the horizontal axis measures the cumulative
percentage of APS respondents, whilst the vertical axis measures the
cumulative \% of all Net Pay. The straight diagonal line is known as the
`Line of equality'. This is what the distribution of income
(\emph{Net\_Pay}) in the UK would look like if it was equally shared
across all APS respondents. The thicker black line below this, known as
the Lorenz Curve, reflects the way income is actually shared. For
example, reading off the Lorenz Curve, 40\% of APS respondents
(represented by 0.4 on the x-axis) have access to only 20\% of the total
income available (the value on the on the y-axis). In contrast, if the
the income were equally shared, then 40\% of the population would have
access to 40\% of the income (reading off the line of equality).

The larger the area between the line of equality and the Lorenz Curve,
the less equally shared the income is. And the size of this area can be
summarised in one number by the Gini coefficient, which takes a value
between 0 (maximum equality) and 1 (p maximum inequality).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{Gini}\NormalTok{( APS}\SpecialCharTok{$}\NormalTok{Net\_Pay, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{ )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.279784
\end{verbatim}

Note that this Gini coefficient under-states the true level of
inequality in the UK, because the incomes of the top 9.87\% of earners
have been top-coded with a value of 40,976 per annum. This makes it
look like the top-earners collectively have a smaller share of total pay
than they actually do. It also makes it look like all persons at the top
end of the income distribution earn the same amount, which is also not
true.

Because the APS only covers the UK, we can't directly compare the income
inequality observed in the UK with the income inequality observed in
other European countries. However, we can use the APS to explore the
extent to which income inequality varies, if at all, between the
constituent regions of the UK.~Here is an example for the ``North West'

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{APS }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(Region }\SpecialCharTok{==} \StringTok{"North West"}\NormalTok{, }\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(Net\_Pay)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{pull}\NormalTok{(Net\_Pay) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{Lc}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{plot}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/05.Wealth_files/figure-pdf/unnamed-chunk-15-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{APS }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(Region }\SpecialCharTok{==} \StringTok{"North West"}\NormalTok{, }\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(Net\_Pay)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{pull}\NormalTok{(Net\_Pay) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{Gini}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.2726889
\end{verbatim}

Let's find out when it's 0.5 on the x-axis whats the y value.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{APS }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(Region }\SpecialCharTok{==} \StringTok{"North West"}\NormalTok{, }\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(Net\_Pay)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{pull}\NormalTok{(Net\_Pay) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{Lc}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  (\textbackslash{}(lc) }\FunctionTok{approx}\NormalTok{(lc}\SpecialCharTok{$}\NormalTok{p, lc}\SpecialCharTok{$}\NormalTok{L, }\AttributeTok{xout =} \FloatTok{0.5}\NormalTok{)}\SpecialCharTok{$}\NormalTok{y)()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.3065287
\end{verbatim}

\textbf{QUESTION 4}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

The computed gini values for all respondents in all regions is 0.28
whereas for the Northwest region it is 0.27. Interpret these results.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Let's now compare the gini value for each regions.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gini\_by\_region }\OtherTok{\textless{}{-}}\NormalTok{ APS }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(}\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(Net\_Pay)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(Region) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarise}\NormalTok{(}
    \AttributeTok{n =} \FunctionTok{n}\NormalTok{(),}
    \AttributeTok{Gini =} \FunctionTok{Gini}\NormalTok{(Net\_Pay),}
    \AttributeTok{.groups =} \StringTok{"drop"}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{arrange}\NormalTok{(}\FunctionTok{desc}\NormalTok{(Gini))}

\FunctionTok{print}\NormalTok{(gini\_by\_region)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 12 x 3
   Region                     n  Gini
   <fct>                  <int> <dbl>
 1 South West              5606 0.286
 2 South East              7587 0.284
 3 Eastern                 4298 0.281
 4 West Midlands           4181 0.280
 5 East Midlands           3328 0.278
 6 Yorkshire & Humberside  4853 0.278
 7 Wales                   5692 0.275
 8 North East              4118 0.274
 9 North West              6446 0.273
10 Scotland                5837 0.270
11 Northern Ireland        2432 0.267
12 London                  4276 0.245
\end{verbatim}

The results show that each region has inequalities in Net\_Pay but they
are on the moderate side. Interestingly, the values are very similar
with no evidence of extreme disparities.

\section{How much does it take to be
`Rich'?}\label{how-much-does-it-take-to-be-rich}

Having familiarised ourselves with the outcome variables available we
can now answer our first research question: How much does it take to be
rich? Or, more specifically, how much does a paid employee have earn per
annum to be regarded `rich' relative to other paid employees?

There is no one answer to this question, which is in many ways very
subjective:

\begin{quote}
``Some people would define rich as having more money than you''need'' to
live, but definition of ``needs'' vary dramatically.''\ldots{}``In his
book Richistan, Wall Street Journal reporter Robert Frank concluded that
`people's definition of rich is subjective and is usually twice their
current net worth'\,''. (BBC
(2011)~\href{https://www.bbc.co.uk/news/magazine-15822595}{The rich:
what exactly does the terminology mean?}, BBC News website, 24th
November.
\end{quote}

However, one common trope when writing about the rich is to refer to the
`top 1\%':

\begin{quote}
``{[}In the United States{]}, 1\% of the people take nearly a quarter of
the nation's income \ldots{} In terms of wealth rather than income, the
top 1\% control 40\% \ldots{} {[}as a result{]} the top 1\% have the
best houses, the best educations, the best doctors, and the best
lifestyles, but there is one thing that money doesn't seem to have
bought: an understanding that their fate is bound up with how the other
99\% live. Throughout history, this is something that the top 1\%
eventually do learn. Too late.'' Joseph Stiglitz
(2011)~\href{https://www.vanityfair.com/news/2011/05/top-one-percent-201105}{Of
the 1\%, by the 1\%, for the 1\%},~\emph{Vanity Fair}, May 2011.
\end{quote}

Unfortunately, one knock on consequence of the top-coding used for the
pay variables in the APS means that we can't identify how much money you
have to earn to fall into the top 1\% of the income distribution. This
means that we will necessary have to adopt a lower threshold definition
of what it means to be `rich'. We can use is `in the top 10\% of the
income distribution'.

\subsection{Top 10\% of Net Pay}\label{top-10-of-net-pay}

This can be operationalised as follows:

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Find the income of person at 90th percentile of the income
  distribution using the~\texttt{quantile()}function, and asking for the
  value of the 90th percentile using the~\texttt{prob\ =\ 0.9}~option:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{APS }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{( Net\_Pay ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{quantile}\NormalTok{( }\AttributeTok{prob =} \FloatTok{0.9}\NormalTok{, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{ )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  90% 
40820 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{max}\NormalTok{(APS}\SpecialCharTok{$}\NormalTok{Net\_Pay, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 40976
\end{verbatim}

This tells us that 90\% of APS respondents have net pay of 40,820 or
less. The remaining 10\% therefore have net incomes of 40,821 or higher
(with the highest person(s) having a net salary of 40,976).

\textbf{QUESTION 5}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Write code to determine what the minimum person being paid? What could
be responsible for this value.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# REPLACE THIS WITH YOUR CODE}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{The Geography of Pay}\label{the-geography-of-pay}

Being geographers, one key task in the familiarisation process remains,
which is to check whether or not there is a geography to our outcome.
The approach we need to adopt depends on whether we want to explore the
geography of the continuous or categorical version of our outcome
variable.

\subsection{Spatially aggregating a continuous
variable}\label{spatially-aggregating-a-continuous-variable}

Before we can map geographical variations in pay, we first need to:

\begin{itemize}
\tightlist
\item
  identify what geography, if any, exists in the APS
\item
  read in a suitable set of digital boundaries for this geography
\item
  create an area-level dataset containing a summary measure
  of~\emph{Net\_Pay}~for each area
\item
  join the resulting area-level dataset to the set of digital boundaries
\end{itemize}

The first task is relatively straightforward. There are only two
geographic identifiers available in the
APS:~\emph{Region}~and~\emph{Merseyside}. Since
the~\emph{Merseyside}~variable simply distinguishes between those who do
and do not live in Merseyside, a better exploration of the geography
of~\emph{Net\_Pay}~will be provided using~\emph{Region,}which divides
the UK into 12 distinct regions.

The second task is also relatively straightforward. Simply download the
file~\emph{UK Regions.geojson}~from the Week 5 folder on CANVAS,~save it
to the same folder as your Week 5 folder, then read it in using
the~\texttt{read\_sf(\ )}~command, saving the boundaries that are read
in to a dataset called~\emph{UK\_regions\_map}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{UK\_regions\_map }\OtherTok{\textless{}{-}} \FunctionTok{read\_sf}\NormalTok{( }\StringTok{"UK Regions.geojson"}\NormalTok{ )}
\end{Highlighting}
\end{Shaded}

calculate the median value for each region simply involves adding
the~\texttt{.by\ =\ Region}~option:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{region\_medians }\OtherTok{\textless{}{-}}
\NormalTok{  APS }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarise}\NormalTok{( }\AttributeTok{Median\_Net\_Pay =} \FunctionTok{median}\NormalTok{( Net\_Pay, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{ ),}
             \AttributeTok{.by =}\NormalTok{ Region )}
\NormalTok{region\_medians}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
                   Region Median_Net_Pay
1              South West          19422
2              South East          22204
3                  London          26988
4                 Eastern          21580
5           West Midlands          19344
6           East Midlands          19188
7              North West          19812
8  Yorkshire & Humberside          19188
9              North East          18720
10       Northern Ireland          19448
11                  Wales          18616
12               Scotland          20384
\end{verbatim}

We can then join
the~\emph{UK\_regions\_map}~and~\emph{region\_medians}~datasets together
and then show the results on a map.

Perform the join between both datasets

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{join\_map }\OtherTok{\textless{}{-}} \FunctionTok{left\_join}\NormalTok{(UK\_regions\_map, region\_medians, }\AttributeTok{by =} \StringTok{"Region"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Show results on a map.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Regions\_medians\_map }\OtherTok{\textless{}{-}} 
  \FunctionTok{tm\_shape}\NormalTok{(join\_map) }\SpecialCharTok{+}
  \FunctionTok{tm\_polygons}\NormalTok{(}
    \AttributeTok{fill =} \StringTok{"Median\_Net\_Pay"}\NormalTok{,}
    \AttributeTok{fill.scale =} \FunctionTok{tm\_scale\_continuous}\NormalTok{(}\AttributeTok{values =} \StringTok{"Blues"}\NormalTok{)}
\NormalTok{  )}

\NormalTok{Regions\_medians\_map}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{labs/05.Wealth_files/figure-pdf/unnamed-chunk-25-1.pdf}}

\textbf{QUESTION 6}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Is there an obvious geography to the distribution of pay levels across
the UK? To what extent would you say there is a North-South divide, or a
South East vs.the Rest divide, or even a London vs the rest divide?

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{What factors influence being
rich?}\label{what-factors-influence-being-rich}

To answer this question. we will compute the correlation between
Net\_Pay and every other variable.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# PART 1: Input your variable of interest and correlation method}
\CommentTok{\# The variable that you want as your main achor}
\NormalTok{variable\_of\_interest }\OtherTok{=} \StringTok{"Net\_Pay"}
\CommentTok{\# The data table}
\NormalTok{data }\OtherTok{=}\NormalTok{ APS}
\CommentTok{\# This is the correlation method that will be used}
\NormalTok{correlation\_method }\OtherTok{=} \StringTok{"spearman"}  \CommentTok{\# or use "pearson" to compute the Pearson correlation coefficient.}

\CommentTok{\# This is the correlation method that will be used}
\NormalTok{correlation\_method }\OtherTok{=} \StringTok{"spearman"}  \CommentTok{\# or use "pearson" to compute the Pearson correlation coefficient.}

\CommentTok{\#{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\CommentTok{\# PART 2; Compute correlations {-} NO NEED TO EDIT THE CODE IN THIS PART}
\NormalTok{correlations }\OtherTok{\textless{}{-}}
\NormalTok{data }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(}\FunctionTok{where}\NormalTok{(is.numeric)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{drop\_na}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{cor}\NormalTok{(}\AttributeTok{method =} \StringTok{"spearman"}\NormalTok{, }\AttributeTok{use =} \StringTok{"complete.obs"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{as.data.frame}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  (\textbackslash{}(x) }\FunctionTok{data.frame}\NormalTok{(}
    \AttributeTok{Variable =} \FunctionTok{rownames}\NormalTok{(x),}
    \AttributeTok{variable\_of\_interest =}\NormalTok{ x[, }\StringTok{"Net\_Pay"}\NormalTok{],}
    \AttributeTok{row.names =} \ConstantTok{NULL}
\NormalTok{  ))() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{arrange}\NormalTok{(}\FunctionTok{desc}\NormalTok{(}\FunctionTok{abs}\NormalTok{(variable\_of\_interest)))}

\FunctionTok{View}\NormalTok{(correlations)}
\end{Highlighting}
\end{Shaded}

\textbf{QUESTION 7}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Based on the above values, which variable has the most influence on
Net\_Pay? Does this make sense? State why.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Statistical significance of
correlations}\label{statistical-significance-of-correlations}

So far we have been treating all of our analysis results as wholly
reliable. But, as explained in this week's lecture, any result based on
the analysis of survey data is subject to the uncertainty inherent in
the process taking a random sample from a wider population. The sample
taken~\emph{might}~be representative of the population it was drawn
from. But then again, it might not. As a result, the correlation we find
between two variables in the APS~\emph{might}~reflect the presence of a
relationship between these two variables in the wider population the
sample was drawn from. Or it might simply be an artefact of the random
sampling process, suggesting a relationship which does not actually
exist in the wider population.

To check whether a relationship is significant we can examine their p
value and significance value. In the code below there is no need to
understand what's happening in PART 2, just as long as you enter the
correct information on PART 1.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# PART 1: }
\CommentTok{\# The variable that you want as your main achor}
\NormalTok{variable\_of\_interest }\OtherTok{=} \StringTok{"Net\_Pay"}

\CommentTok{\# This is the correlation method that will be used}
\NormalTok{correlation\_method }\OtherTok{=} \StringTok{"spearman"}  \CommentTok{\# or use "pearson" to compute the Pearson correlation coefficient.}

\CommentTok{\# The data table}
\NormalTok{data }\OtherTok{=}\NormalTok{ APS}

\CommentTok{\#{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}

\CommentTok{\# PART 2 {-} Compute correlation and p{-}value {-} NO NEED TO EDIT CODE HERE}
\CommentTok{\# This other part of the code takes the variable of interest and correlation method and does the computation.}
\NormalTok{correlations\_with\_pvalue }\OtherTok{\textless{}{-}}
\NormalTok{data }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(}\FunctionTok{where}\NormalTok{(is.numeric)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{pivot\_longer}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{Net\_Pay, }\AttributeTok{names\_to =} \StringTok{"Variable"}\NormalTok{, }\AttributeTok{values\_to =} \StringTok{"x"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(Variable) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarise}\NormalTok{(}
    \AttributeTok{rho =} \FunctionTok{cor}\NormalTok{(x, Net\_Pay, }\AttributeTok{method =}\NormalTok{ correlation\_method, }\AttributeTok{use =} \StringTok{"pairwise.complete.obs"}\NormalTok{),}
    \AttributeTok{p\_value =} \FunctionTok{cor.test}\NormalTok{(}
\NormalTok{      x, Net\_Pay,}
      \AttributeTok{method =}\NormalTok{ correlation\_method,}
      \AttributeTok{exact =} \ConstantTok{FALSE}
\NormalTok{    )}\SpecialCharTok{$}\NormalTok{p.value,}
    \AttributeTok{sig =}\NormalTok{ p\_value }\SpecialCharTok{\textless{}=} \FloatTok{0.05}\NormalTok{,}
    \AttributeTok{.groups =} \StringTok{"drop"}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(Variable }\SpecialCharTok{!=}\NormalTok{ variable\_of\_interest) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{arrange}\NormalTok{(}\FunctionTok{desc}\NormalTok{(}\FunctionTok{abs}\NormalTok{(rho))) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{rho =} \FunctionTok{round}\NormalTok{(rho, }\DecValTok{2}\NormalTok{),}
    \AttributeTok{p\_value =} \FunctionTok{round}\NormalTok{(p\_value, }\DecValTok{4}\NormalTok{)}
\NormalTok{  )}

\FunctionTok{View}\NormalTok{(correlations\_with\_pvalue)}
\end{Highlighting}
\end{Shaded}

\textbf{NOTE: rho or  in the outputted table is referring to the
spearman correlation value.}

In the results returned, two additional columns are provided: p\_value
and sig. The p\_value represents the probability of observing a
correlation as strong as the one found in the APS data if, in reality,
there were no relationship between the two variables in the population
from which the survey was drawn.

A p\_value of 0.05 indicates a 5\% probability of observing such a
correlation purely by chance, assuming no true relationship exists in
the population. By convention in social science, a p\_value of 0.05 or
less is considered statistically significant, meaning the observed
relationship is unlikely to have arisen due to chance alone.

The sig column indicates whether each correlation is statistically
significant at the 5\% level. A value of TRUE means the correlation is
statistically significant (p  0.05), while FALSE indicates that it is
not statistically significant. In these results, Gross\_Pay,
Equiv\_Net\_Pay, Work\_Hours, Job\_Years, Commute\_Time,
Family\_Toddlers, Weight\_APS, Youngest\_Child, and Family\_Size show
statistically significant correlations with Net\_Pay. In contrast,
Hhold\_Size, Hholds\_at\_Address, Age, and Arrival\_Year are not
statistically significant, indicating no reliable relationship with
Net\_Pay in the wider population.

It is important to note that a p\_value of 0.0000 does not mean zero
probability. Rather, it means the true p\_value is extremely small and
has been rounded to four decimal places, indicating very strong
statistical evidence of a relationship.

However, statistical significance does not imply practical importance.
For example, although Family\_Toddlers ( = 0.05), Weight\_APS ( =
0.04), and Youngest\_Child ( = 0.04) are statistically significant,
their correlations are extremely weak. This suggests that these
variables have negligible practical influence on Net\_Pay, despite being
statistically significant due to the large sample size.

Interpretation should focus primarily on the size and direction of
correlations, rather than statistical significance alone.

Applying this to the results:

\begin{itemize}
\item
  There is a very strong positive relationship between Net\_Pay and
  Gross\_Pay ( = 0.95), which is expected since net pay is directly
  derived from gross pay.
\item
  There is a moderately strong positive relationship between Net\_Pay
  and Equiv\_Net\_Pay ( = 0.57) and Work\_Hours ( = 0.50), indicating
  that individuals who work more hours and have higher adjusted
  household income tend to earn higher net pay.
\item
  There is a weak positive relationship between Net\_Pay and Job\_Years
  ( = 0.15) and Commute\_Time ( = 0.10), suggesting modest
  associations with job experience and commuting.
\item
  All other variables show very weak or negligible relationships, and
  several---such as Hhold\_Size, Hholds\_at\_Address, Age, and
  Arrival\_Year---are not statistically significant, indicating no
  meaningful or reliable relationship with Net\_Pay.
\end{itemize}

Overall, the key determinants of Net\_Pay are Gross\_Pay,
Equiv\_Net\_Pay, and Work\_Hours, while most other demographic and
household variables have little or no meaningful influence.

\section{Confidence intervals}\label{confidence-intervals-1}

Statistical significance is a fairly blunt way of attempting to gauge
the uncertainty associated with a given correlation. All it tells us
that how unlikely the result is, assuming that there is no correlation
between the variables concerned in the wider population. It says nothing
about the range within which the population correlation is likely to
fall. To find this out, we need to calculate each correlation's
confidence interval.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# PART 1: Input your variable of interest and correlation method}
\CommentTok{\# The variable that you want as your main achor}
\NormalTok{variable\_of\_interest }\OtherTok{=} \StringTok{"Net\_Pay"}

\CommentTok{\# This is the correlation method that will be used}
\NormalTok{correlation\_method }\OtherTok{=} \StringTok{"spearman"}  \CommentTok{\# or use "pearson" to compute the Pearson correlation coefficient.}

\CommentTok{\# The data table}
\NormalTok{data }\OtherTok{=}\NormalTok{ APS}

\CommentTok{\#{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}

\CommentTok{\# PART 2: Compute the correlation coefficients and associated p{-}values {-} NO NEED TO EDIT CODE HERE}
\CommentTok{\# This other part of the code takes the variable of interest and correlation method and does the computation.}
\CommentTok{\# Ensure anchor exists and is numeric}

\NormalTok{anchor }\OtherTok{\textless{}{-}}\NormalTok{ data[[variable\_of\_interest]]}

\NormalTok{correlations\_with\_pvalue\_ci }\OtherTok{\textless{}{-}}
\NormalTok{  data }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(}\FunctionTok{where}\NormalTok{(is.numeric)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{pivot\_longer}\NormalTok{(}
    \AttributeTok{cols =} \SpecialCharTok{{-}}\FunctionTok{all\_of}\NormalTok{(variable\_of\_interest),}
    \AttributeTok{names\_to =} \StringTok{"Variable"}\NormalTok{,}
    \AttributeTok{values\_to =} \StringTok{"x"}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarise}\NormalTok{(}
    \AttributeTok{n =} \FunctionTok{sum}\NormalTok{(}\FunctionTok{is.finite}\NormalTok{(x) }\SpecialCharTok{\&} \FunctionTok{is.finite}\NormalTok{(anchor)),}
    \AttributeTok{r =} \FunctionTok{suppressWarnings}\NormalTok{(}\FunctionTok{cor}\NormalTok{(x, anchor, }\AttributeTok{method =}\NormalTok{ correlation\_method, }\AttributeTok{use =} \StringTok{"pairwise.complete.obs"}\NormalTok{)),}
    \AttributeTok{p\_value =} \FunctionTok{suppressWarnings}\NormalTok{(}\FunctionTok{cor.test}\NormalTok{(x, anchor, }\AttributeTok{method =}\NormalTok{ correlation\_method, }\AttributeTok{exact =} \ConstantTok{FALSE}\NormalTok{)}\SpecialCharTok{$}\NormalTok{p.value),}
    \CommentTok{\# Fisher z CI (exact for Pearson; common approximation otherwise)}
    \AttributeTok{conf\_low  =} \FunctionTok{tanh}\NormalTok{(}\FunctionTok{atanh}\NormalTok{(r) }\SpecialCharTok{{-}} \FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.975}\NormalTok{) }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(n }\SpecialCharTok{{-}} \DecValTok{3}\NormalTok{)),}
    \AttributeTok{conf\_high =} \FunctionTok{tanh}\NormalTok{(}\FunctionTok{atanh}\NormalTok{(r) }\SpecialCharTok{+} \FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.975}\NormalTok{) }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(n }\SpecialCharTok{{-}} \DecValTok{3}\NormalTok{)),}
    \AttributeTok{.by =}\NormalTok{ Variable}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(Variable }\SpecialCharTok{!=}\NormalTok{ variable\_of\_interest) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{sig =}\NormalTok{ p\_value }\SpecialCharTok{\textless{}=} \FloatTok{0.05}\NormalTok{,}
    \AttributeTok{r =} \FunctionTok{round}\NormalTok{(r, }\DecValTok{2}\NormalTok{),}
    \AttributeTok{p\_value =} \FunctionTok{round}\NormalTok{(p\_value, }\DecValTok{4}\NormalTok{),}
    \AttributeTok{conf\_low =} \FunctionTok{round}\NormalTok{(conf\_low, }\DecValTok{2}\NormalTok{),}
    \AttributeTok{conf\_high =} \FunctionTok{round}\NormalTok{(conf\_high, }\DecValTok{2}\NormalTok{)}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{arrange}\NormalTok{(}\FunctionTok{desc}\NormalTok{(}\FunctionTok{abs}\NormalTok{(r)))}

\FunctionTok{View}\NormalTok{(correlations\_with\_pvalue\_ci)}
\end{Highlighting}
\end{Shaded}

In the resulting output, two additional columns are provided: conf\_low
and conf\_high, which represent the lower and upper bounds of the 95\%
confidence interval for each correlation. For example, the 95\%
confidence interval for the correlation between Net\_Pay and Work\_Hours
is 0.49 to 0.50. This means that if repeated random samples of the same
size were drawn from the population, the correlation would be expected
to fall within this range in 95\% of cases. In other words, there is
95\% confidence that the true population correlation between Net\_Pay
and Work\_Hours lies between 0.49 and 0.50.

Confidence intervals also help assess the reliability and direction of
relationships. When a confidence interval includes the value 0, it
indicates uncertainty about whether the true correlation in the
population is positive or negative. For example, the correlations
between Net\_Pay and Hhold\_Size (0.01 to 0.00), Hholds\_at\_Address
(0.00 to 0.01), Age (0.01 to 0.01), and Arrival\_Year (0.02 to 0.02)
all include zero. This indicates that there is no reliable evidence of a
meaningful relationship between these variables and Net\_Pay in the
wider population.

By contrast, when the confidence interval does not include 0, the
direction of the relationship can be interpreted with confidence. For
example, Gross\_Pay has a confidence interval of 0.95 to 0.95,
confirming a very strong positive relationship with Net\_Pay. Similarly,
Equiv\_Net\_Pay (0.56 to 0.57) and Work\_Hours (0.49 to 0.50) show clear
positive relationships. Even variables with weaker correlations, such as
Job\_Years (0.14 to 0.16) and Commute\_Time (0.10 to 0.11), have
confidence intervals entirely above zero, indicating reliably positive
relationships, although the strength of these relationships is modest.

Overall, the narrow confidence intervals observed---particularly for
variables such as Gross\_Pay, Equiv\_Net\_Pay, and Work\_Hours---reflect
the large APS sample size and indicate that the estimated correlations
are precise and reliable.

\section{Formative tasks}\label{formative-tasks-4}

\textbf{Task 1}

Extract the data for Merseyside and create a histogram for the variable
Net\_Pay. HINT: Values of `Merseyside' in the variable \emph{Merseyside}
indicate this location.Task 2

\textbf{Task 2}

Derive the Lorenz curve and and it's associated gini value. Discuss
these results.

\textbf{Task 3}

Compute the correlation for Net\_Pay for Merseyside with the other
numeric values in the dataset. What is the most influential factor
influencing Net\_Pay in Merseyside?

\textbf{Task 4}

Compute associated p values and significant values and discuss the
results.

\textbf{Task 5}

Further compute the confidence intervals and discuss the results.\\




\end{document}
