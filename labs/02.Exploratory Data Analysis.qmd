---
title: "02.Exploratory Data Analysis"
format: html
editor: visual
---

# **Overview**

> “Democracy is the worst form of Government except for all those other forms that have been tried from time to time.” (Winston Churchill, 1947, House of Commons Speech)

> “The present system has clearly broken down. The results produced are not fair to any party, nor to any section of the community. In many cases they do not secure majority representation, nor do they secure an intelligent representation of minorities. All they secure is fluke representation, freak representation, capricious representation.” (Winston Churchill, 1909)

> “Never discuss religion or politics in polite company” (*Proverb*)

Exploring the geography of politics will draw upon the mapping and graphing skills learnt in Week 1, plus the data tabulation and regrouping skills we learning in Week 2. It will also require the following additional skills:

-   Creating new variables using basic mathematical operations (add, subtract, divide, multiply)

-   Distinguishing between skewed and symmetrical continuous variables

-   Distinguishing between nominal and ordinal categorical variables

-   Using graphs to visualise distributions

-   Calculating appropriate measures of average and spread

As ever, the first few sections of this practical walk you through the process of getting ready to analyse some data. A set of constituency-level data is then used to explore two concepts. First, the geography of the ‘wasted vote’ (based on calculations undertaken using the data provided). Second, what the typical constituency looks like (drawing on measures of average and spread). The British Election Study, a person-level dataset, is then used to explore what the typical supporter of a given political party looks like (again drawing upon measures of average and spread).

# 1. Clear the decks

-   Open RStudio

-   Close any existing Quarto Documents

-   If you are working on a University PC Teaching Centre computer, make the changes outlined in Sections 1.3 and 1.4 of the Week 1 practical. (If you are working on your own computer these changes will already be in place.)

-   Open a new Quarto Document for your Week 2 work

-   Save this new Quarto Document into \*\*the same folder you are using to save all of your other ENVS162 course work\*\*

-   Insert a first code chunk in your Week 2 Quarto Document and run the following line of code:

```{r}
rm(list = ls())
```

This command will clear RStudio’s memory, removing any data objects that you have previously created. Doing this ensures that any data objects referred to in your Week 3 Quarto Document will be ones that were created using code in the Week 3 Quarto document, helping to avoid confusion.

# 2. Install packages

The `scales` package provies the command `label_comma( )` which we use this week to make some output easier to read.

If you are using a University PC Teaching Centre computer the `scales` package should come pre-instealled.

However, if you are using your own computer you will need to install this package (once only) by running the following line of code in the *Console* window in RStudio:

```{r}
#| eval: false
#| include: false
install.packages("scales")
```

# 3. Open libraries

As ever, when you start a new session in RStudio, you need to load the packages you wish to use into memory. In addition to the `tidyverse`, `gdslStats` and `sf` packages we used last week, this week you will also be using the `scales` package.

```{r}
#| message: false
#| warning: false
library(tidyverse)
library(sf)
library(scales)
library(broom)
library(tmap)
```

# 4. Parliamentary Constituency Data

In 2024 the UK held a general election. The file *uk_constituencies_2024.Rdata* captures a range of information relating to this election, and to the nature of each parliamentary constituency, stored in a dataset called *pc_data* (short for Parliamentary Constituency data).

The *pc_data* dataset has been assembled by combining information from the following sources:

-   *HoC-GE2024-results-by-constituency.xlsx*

    *Source*: Cracknell et al (2024) General election 2024 results, *Research Briefing*, House of Commons Library. https://commonslibrary.parliament.uk/research-briefings/cbp-10009/

-   *Demographic-data-for-new-parliamentary-constituencies-May-2024.xlsx*

    *Source*: House of Commons Demographic data for Constituencies https://commonslibrary.parliament.uk/data-for-new-parliamentary-constituencies/

-   *NatCen Constituency Data_20 June 2024.xlsx*

    *Source*: National Centre for Social Research (2024) Parliamentary constituency look-up, https://natcen.ac.uk/constituency-look-up (date accessed: 07-02-2025)

-   *nomis_2025_01_14_101749.xlsx*

    *Source*: Income data from Annual Survey of Hours and Earnings (ASHE), collecgted by the Office for National Statistics. https://www.nomisweb.co.uk/datasets/asher

## 4.1 Load the pc_data dataset

Read in the csv file uk_constituencies_2024.csv in the data folder: insert a code chunk and use it to run the following command:

```{r}
#| include: false
pc_data <- read.csv("data/uk_constituencies_2024.csv")
```

The pc_data dataset should appear in your RStudio Environment Pane on the upper right part, indicating that it has now been loaded into memory, and is available for analysis.

## 4.2 Dataset familiarisation

In the *pc_data* dataset each row represents a different UK Parliamentary Constituency.

Use the `nrow( )` command to find out how many Parliamentary Constituencies (and therefore MPs) there are in the UK.

The *pc_data* dataset contains three basic sets of information about each Parliamentary Constituency:

-   **constituency identifiers** - *gss_code* and *pc_name*

-   **population information** for each constituency, ranging from the total population and number of households through to the % in various categories to information about local house prices, salaries and crime rates

-   **2024 election results** ranging from the winning MP and party through to the size of the electorate and vote turnout, and the share of votes received by each party

Use the `View()` command to familiarise yourself with the variables contained in the dataset.

```{r}
#| eval: false
#| include: false
nrow(pc_data)
```

```{r}
#| eval: false
#| include: false
View(pc_data)
```

## 4.3 Headline election results

You can use the *pc_data* dataset to extract some headline results from the 2024 General Election.

First, use the `table()` command to find the number of MPs elected to each Party. \[Hint: use the *first_party* variable\].

```{r}
table(pc_data$first_party)
```

However, if we not only care about the count of MPs but also the proportion? Then we can make a good use of our tidyverse library to run the following code line. Here you are using two very useful functions in the library tidyverse. First the `count()` calculate the frequency of different categories in the first_party column - it actually do the same thing as above code, but better in presenting as a table; Second, the `mutate()` function to assist use create a new columnand fill in the value by the calculation `pct = n / sum(n) * 100`. Therefore, when you run the code, you will see a table showing as three column: first part name, a new column automatically named as *n* by R after the `count()` function, and count of the party MPs, and a new column called *pct* and with values calculated by `n / sum(n) * 100`.

```{r}
pc_data %>%
  count(first_party) %>%
  mutate(pct = n / sum(n) * 100)
```

We can also improve the code to make a better table presentation. You may find the comment text after each code line would be useful to understand what R has done to the *pc_data*.

```{r}
pc_data %>%
  count(first_party) %>%
  mutate(pct = percent(n / sum(n), accuracy = 0.1)) %>% #use the percent() function in library scales, with only 1 digit percentage
  arrange(desc(n)) %>%   #sort the table by number of MPs from more to less
  setNames(c("First Party", "Number of MPs", "% of MPs"))  #rename table column names
  
```

It is also possible to use the information in the *pc_data* dataset to calculate the total number and % share of votes received by each party, plus the number of votes each party required in order to get one MP elected.

```{r}
pc_data %>%
  group_by(first_party) %>% #group votes by the first part results
  summarise(n_votes = sum(first_party_votes )) %>% #calculation the total number of votes for each part
  mutate(pct = percent(n_votes / sum(n_votes), accuracy = 0.1)) %>% #calculate the % of Votes
  arrange(desc(n_votes)) %>% #sorted
  setNames(c("First Party", "Number of Votes", "% of Votes")) %>%  #rename table column names
  show()
```

What the table above shows us is that a party’s % share of the national vote, and its % share of the total number of MPs bear little relation to one another. This is because some political parties, notably Reform UK and the Green Party, require far more votes to get an MP elected than others (most notably Labour and Sinn Fein).

## 4.4 Calculate votes per MP

Dividing the total votes cast in the UK by the number of Parliamentary Constituencies shows the number of votes it would have taken to get one MP elected:

```{r}
sum(pc_data$valid_votes) / nrow(pc_data)
```

In the code above the `sum()` command is used to find the total number of valid votes, whist the `nrow( )` command is used to find the total number of constituencies and, hence, MPs. The / symbol is the R-version of the normal division symbol. The variable valid_votes is referenced using the dataset\$variable format.

# 5. Wasted votes

The UK General Election is held under a ‘First-past-the-post’ (FPTP) electoral system. In other words, the candidate with the most votes in a constituency wins. As a result, many votes are ‘wasted’, as they have no influence on how many MPs each party gets.

A ‘wasted vote’ can be defined as a vote cast for:

-   a candidate who loses (because none of these losing votes add to the number of MPs that the losing candidate’s party ends up with)

-   any any votes cast for the winning candidate in excess of those needed to win (because these ‘surplus’ votes don’t add to the number of MPs the winning candidate’s party gets)

-   votes for the Speaker of the House (because the MP who acts as Speaker of the House is not allowed to vote, and therefore cannot influence government policy)

We can use the *pc_data* dataset to calculate how many wasted votes there were in the 2024 General Election.

## 5.1 Losing votes

In each constituency the number of votes cast for all losing candidates is equal to the total number of votes cast in that constituency, less the number of votes cast for the winning candidate:

```{r}
pc_data$losing_votes <-
  pc_data$valid_votes - pc_data$first_party_votes
```

In the code above each variable is referred to using the `dataset$variable_name` format. The result of subtracting the *first_party_votes* from the *valid_vote* is saved to the new variable *losing_votes*.

Using `View()` you can visually check that this calculation has worked correctly. For a constituency of your choice, use `View()` to find the total number of votes cast (*valid_votes*), the number votes cast for the party that won (*first_party_votes*) and then check that the *losing_votes* (which should have been added to the right-hand end of the dataset) equals the difference between the *valid_votes* and *first_party_votes*.

To find the total number of losing votes in the General Election as a whole, we simply need to add together (sum) the *losing_votes* from each constituency:

```{r}
sum(pc_data$losing_votes)
```

````{=html}
<!-- ## 5.2 Surplus votes

In a General Election the winning majority is the number of votes the winning candidate got in excess of those received by the second-placed candidate.

Under the First-past-the-post system a candidate only needs a majority of 1 to win an election.

Therefore the number of surplus votes in each constituency is simply one less than the size of their winning candidate’s majority. For example, if a candidate wins with a majority of 500, their ‘surplus’ vote is 499.

Based on this definition, we can calculate the number of surplus vote in each constituency as follows:

```{r}
pc_data$surplus_votes <- pc_data$majority - 1
```

Use `View()` to check that you are happy with the results.

As for *losing_votes*, we can use `sum()` to find the total number of surplus votes across the country as a whole:

```{r}
sum(pc_data$surplus_votes) 
```

## 5.3 Votes for the Speaker - comment out the rest of Section 

The *surplus_votes* cast for the Speaker have already been included in the sum of *surplus_votes* calculated above. What we have not yet counted is the number of votes required to elect the speaker, which is the number of votes cast for the speaker less their surplus votes.

We can use the `filter()` command to extract only the row of data associated with the Speaker, saving the result to a new dataset called *speaker_data*:

```{r}

speaker_data <-
  pc_data %>%
  filter(first_party == "Speaker")
```

Using the `speaker_data` dataset we can then take the number of surplus_votes for the Speaker away from the total number of votes they received (first_party_votes).

```{r}

speaker_data$first_party_votes - speaker_data$surplus_votes 
```

## 5.4 Total wasted votes

Based on our calculations above, the total wasted votes is

```{r}

sum(pc_data$losing_votes) + sum(pc_data$surplus_votes) + (speaker_data$first_party_votes - speaker_data$surplus_votes)
```

We can express these wasted votes (numerator) as a percentage of the total number of people who voted (denominator) using the formula percentage = numerator / denominator x 100.

```{r}
21232959 / sum(pc_data$valid_votes) * 100
```

In other words almost three out of every four votes cast (74%) make no difference to the number MPs that each party ends up with.

This means that the political composition of the Houses of Parliament reflect the views of only 26% (one in four) of those who voted.

Worse than that, the percentage of those eligible to vote who actually did was only:

```{r}

sum(pc_data$valid_votes) / sum(pc_data$electorate) * 100
```

i.e. 60%.

Therefore the political composition of the Houses of Parliament only reflects the political opinions of 0.6 x 26% = 15.8%, or about one in six, of those eligible to vote. The views of the other five in six are left unrepresented.

```{r}
0.5970453 * (100 - 73.68546)
```

Perhaps it is no wonder that so many people are disaffected with the current political status quo!

::: {#Task 1} Task 1 Calculate the % of all votes cast in the UK (valid_votes) that were for a winning MP (first_party_votes) To do this you will need to find the dataset total of each variable using the sum( ) command, then calculate the required percentage making use of the mathematical operators / and \*. :::

 -->
````

# 6. Mapping the election results

Having established how many MPs and votes each party got, it is time to look at the geography of the election outcome. To do this we need to link a set of digital boundaries for Parliamentary Constituencies with our pc_data dataset.

## 6.1 Read in Parliamentary Constituency Boundaries

Digital boundaries for the Parliamentary Constituencies used in the 2024 General Election can be found in the files *uk_constituencies_2024.geojson*. Both of these boundary datasets were sourced from https://automaticknowledge.org/wpc-hex/, and them simplified to make them quicker to plot.

Download the two digital boundary files from the Week 3 folder in CANVAS and save them to the same folder as your Week 3 Quarto document.

```{r}
pc_map <- st_read("uk_constituencies_2024.geojson") #read the boundaries as a spatial dataset by using the st_read() command from library(sf)
```

## 6.2 Inspect the spatial dataset

Use the `dim()` command to check the number of rows and columns of the map data:

```{r}
dim(pc_map)
```

Use the `names()` to know the contents, or as above use `View()` to open and check:

```{r}
names(pc_map)
```

```{r}
View(pc_map)
```

The *pc_map* dataset contains the standard set of Parliamentary Constituency boundaries:

```{r}
tm_shape(pc_map) + #map a spatial data
  tm_polygons() #map it as polygons
```

or we can make a colorful map by using different color for different regions:

```{r}
tm_shape(pc_map) + #map a spatial data
  tm_polygons("region_name")  #map it as polygons, use different colors by region
  
```

## 6.3 Link boundaries to pc_data dataset

In order to map the election results contained in the *pc_data* dataset, we need to join it to a set of digital boundaries using the `full_join( )` command.

In your inspection of the *pc_data* and *pc_map* / *pc_hex_map* datasets, you may have noticed that they all have TWO variables in common. The first is a unique identifier for each Parliamentary Constituency: *gss_code*. The second is the name of the constituency: *pc_name*.

We can use these two variables to first link the *pc_data* dataset to the standard map:

```{r}
pc_map_new <- left_join(pc_map, pc_data, by = c("gss_code", "pc_name")) #left join pc_data to pc_map, joining when gss_code from pc_map equals to pc_name in pc_data
```

As ever, having created a new dataset, use the `nrow( )`, `ncol( )`, `names( )` and `View( )` commands to check its contents are as you would expect.

# 6.4 Map the election results

Having joined the *pc_data* dataset with a set of digital boundaries, it becomes a simple matter to map the election results using the mapping skills covered in previous weeks, first using the standard map, and then the hex map:

```{r}
tm_shape(pc_map_new) + #map a spatial data
  tm_polygons("first_party")  #map it as polygons, use different colors by first_party
```

Note how the Labour party appears far more dominant in the hex map, reflecting the large number of MPs it secured. In the standard map the Labour party appears far less dominant, because many of its MPs represent densely populated urban constituencies, whilst many of the other parties represent less densely populated rural areas.

## 6.5 The geography of electoral change

According to press coverage at the time, the 2024 General Election saw the Labour win a ‘landslide victory’, ‘radically changing the electoral map of the UK’.

But is this true?

**Task 2** Check this claim by mapping the constituencies which did, and did not, change parties as a result of the election, using the variable *hold_gain*, where a ‘hold’ is a seat that did NOT change party and a ‘gain’ is a seat that DID change party.

As this map should show, quite a few constituencies did NOT change hands (i.e. were ‘holds’).

Task 3 Use the tab( ) command to find out how many constituencies did/did not change hands \[dataset: pc_data; variable: hold_gain.\]

Task 4 Use the tab( ) command to find out what percentage of constituencies did/did not change hands \[dataset: pc_data; variable: hold_gain.\]

# 7. What does the typical constituency look like?

Whenever analysing a new dataset, a good starting point is to look at the distribution, average and spread of each variable you are interested ins. Applying this approach to our election dataset will enable us to get a sense of what the typical UK constituency looks like.

Looking at the distribution, average and spread of a variable involves a number of steps, which we will work through in turn in this section of the practical.

# 7.1 Identify the variable type

Whenever we analyse a variable, the first question to ask ourselves is: “is it *continuous* or *categorical* ?”

Continuous variables are numeric measures of some quantity, such as a count or percentage or a precise value. E.g. number of valid votes; % of persons unemployed etc.

In contrast, categorical variables simply group observations into categories or ranges. E.g. name of the winning party; age group etc.

A quick inspection of the *pc_map_2* dataset should persuade you that almost all of the variables in the dataset are *continuous* variables.

To get a quick summary of the distribution of continuous variable, we can use the `fivenum()` command.

If this is your first time run into this command, or any other command, remember, you can always also R to explain to you by using ? as help:

```{r}
?fivenum
```

Okay! Now on your lower-right panel of R Studio, R should present you the explanation of fivenum() command in your Help tab. We see `fivenum()` is actually a quick way to return "five number summary (minimum, lower-hinge, median, upper-hinge, maximum) for the input data". It can be much easier to run `max()`, `min()`, etc., one by one for five times.

Now first let us try some columns from of pc_data:

```{r}
fivenum(pc_data$population)
```

So for all the constituencies, the one with the least population only has 26,100 people, but the largest one has 152,000 people lives in. The median population of a constituency is 101,000. Now you may ask, what is the average/mean value of the population in constituency? The fivenum() only return the median rather than mean. This is because statistically, median is always a better value than mean as it can avoid any extremely large or small value to skew the whole values. But whenever we need mean value, R can do it easily by using:

```{r}
mean(pc_data$population)
```

Now you see, there is another advantage of median value as it would return you a population number with digits. But still, we can take 102,977 as the mean value of all the constituency population.

You can try out `fivenum()` and `mean()` on other variables as what I have done to the population.

# 7.2 Visualise the distribution of a continuous variable

There are many ways to visualise the distribution of a *continuous* variable, but we will focus on two:

-   density curves

-   histograms

-   box-plots

First, let’s visualise the distribution of the variable *electorate* (i.e. the number of eligible voters per constituency). This will enable us to check the extent to which constituencies vary in size.

```{r}
plot(pc_data$electorate)
```

```{r}
plot(density(pc_data$electorate))
```

```{r}
hist(pc_data$electorate)
```

The logic under-pinning a histogram is that a continuous variable (in this case *electorate*) is temporarily regrouped into categories, using an equal-interval approach. The number of observations (in this case, constituencies) that fall into each equal-interval category then determine the height of each column in the histogram.

To make a better presentation, we can do some improvement:

```{r}
hist(pc_data$electorate,
     breaks = 50, col = "pink", border = "purple",
     main = "Histogram: Number of eligible voters per constituency",
     xlab = "Number of division: 50",
     ylab = "Frequency of constituency")
```

Interpretation of the histogram

Alternatively, the distribution of a continuous variable can be visualised using a box-plot:

```{r}
boxplot(pc_data$electorate)
```

for a better presentation, we can improve it by

```{r}
boxplot(pc_data$electorate,
        horizontal = T,#make the plot horizontal
        main = "Boxplot: Number of eligible voters per constituency",#add a proper title name
        xlab = "pc_data$electorate",#provide a x-axis label
        col = "orange") #change color
```

Note the need in the code above to include `x=""` within the `aes( )` and `labs( )` commands.

In this box-plot:

-   The thick horizontal line within the box represents the median (50th percentile) of the distribution. In the graph above the line is at a height of about 75,000 on the y-axis, indicating that the median Parliamentary Constituency contains an electorate of about 75,000.

-   The top of the box represents the 75% percentile of the distribution

-   The bottom of the box represents the 25% percentile of the distribution

-   The ‘box’ in the graph contains the middle 50% of all observations.

-   The difference between the top and the bottom of the box is the Inter-Quartile Range (IQR)

-   The two ‘whiskers’ are each 1.5 times the length of the Inter-Quartile Range

-   The small black circles represent ‘outliers’ - observations that fall more than 1.5 IQR beyond the middle 50% of the distribution

What both the histogram and box-plot show us is that:

\(a\) the great majority of constituencies have an electorate in the range 70,000 to 80,000, making them roughly comparable in size.

\(b\) the are a number of outliers to the distribution, most of which involve constituencies with unusually small electorates

::: {#Task 5} **Task 5** Visually inspect the distribution of another variable of your choice from the pc_data dataset, such as the percentage of people from each constituency voting for a given party. :::

## **7.4 Identify the *continuous* variable sub-type**

We can further divide *continuous* variables into two sub-types: *skewed* and *symmetrical*.

A truly symmetrically distribution would have a skew of zero - something we are unlikely to encounter in a real world dataset. However, as a rule-of-thumb a variable with a skew in the range -0.5 to +0.5 can still be treated as ‘symmetrical’.

To calculate the skew of a variable, we need to use the `skew( )` command, including the `na.rm = TRUE` option if we want any missing values to be ignored.

Our visualisation of the distribution of the *electorate* by constituency looked like it had strong negative skewed - something which the associated skew value confirms:

```{r}
skew(pc_data$electorate,na.rm=TRUE) #calculate the skewness of electorate variable in the pc_data; if any NA in the dataframe, remove it
```

::: {#Task 7} **Task 7**

Which of the following variables from the *pc_data* dataset are might best be described as skewed?

-   *pct_White_British*

-   *pct_age_65_plus*

-   *pct_Reform*

-   *pct_Green* :::

:::: {#Task 8}

<div>

**Task 8** Confirm your result via an appropriate visualisation

</div>

::::
